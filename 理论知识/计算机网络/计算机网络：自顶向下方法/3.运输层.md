- [3. 运输层](#3-运输层)
	- [3.1 概述和运输层服务](#31-概述和运输层服务)
		- [3.1.1 运输层和网络层的关系](#311-运输层和网络层的关系)
		- [3.1.2 因特网运输层概述](#312-因特网运输层概述)
	- [3.2 多路复用和多路分解](#32-多路复用和多路分解)
	- [3.3 无连接运输：UDP](#33-无连接运输udp)
		- [3.3.1 UDP报文段结构](#331-udp报文段结构)
		- [3.3.2 UDP校验和](#332-udp校验和)
	- [3.4 可靠数据运输原理](#34-可靠数据运输原理)
		- [3.4.1 构造可靠数据传输协](#341-构造可靠数据传输协)
		- [3.4.2 流水线可靠数据传输协议](#342-流水线可靠数据传输协议)
		- [3.4.3 回退N步(GBN)](#343-回退n步gbn)
		- [3.4.4 选择重传(SR)](#344-选择重传sr)
	- [3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)
		- [3.5.1 TCP连接](#351-tcp连接)
		- [3.5.2 TCP报文段结构](#352-tcp报文段结构)
		- [3.5.3 往返时间的估计与超时](#353-往返时间的估计与超时)
		- [3.5.4 可靠数据传输](#354-可靠数据传输)
		- [3.5.5 流量控制](#355-流量控制)
		- [3.5.6 TCP连接管理](#356-tcp连接管理)
	- [3.6 拥塞控制原理](#36-拥塞控制原理)
		- [3.6.1 拥塞原因与代价](#361-拥塞原因与代价)
		- [3.6.2 拥塞控制方法](#362-拥塞控制方法)
	- [3.7 TCP拥塞控制](#37-tcp拥塞控制)
		- [3.7.1 公平性](#371-公平性)
		- [3.7.2 明确拥塞通告：网络辅助拥塞控制](#372-明确拥塞通告网络辅助拥塞控制)
	- [3.8 小结](#38-小结)

# 3. 运输层

运输层位于应用层和网络层之间，是分层的网络体系结构的重要部分。该层为运行在不同主机上的应用进程提供直接的通信服务起着至关重要的作用

## 3.1 概述和运输层服务

运输层协议为运行在不同主机上的应用进程之间提供了**逻辑通信**功能。从应用程序的角度看，通过逻辑通信，运行不同进程的主机好像直接相连一样；应用进程使用运输层提供的逻辑通信功能彼此发送报文，而无须考虑承载这些报文的物理基础设施的细节

运输层协议是在端系统中而不是在路由器中实现的。在发送端，运输层将从发送应用程序进程接收到的报文转换成运输层分组，用因特网术语来讲该分组称为运输层**报文段(segment)**。实现的方法(可能)是将应用报文划分为较小的块，并为每块加上一个运输层首部以生成运输层报文段。然后，在发送端系统中，运输层将这些报文段传递给网络层，网路层将其封装成网络层分组(即**数据报(datagram)**)并向目的地发送。注意到下列事实是重要的：网络路由器仅作用于该数据报的网络层字段；即它们不检查封装在该数据报的运输层报文段的字段。在接收端，网络层从数据报中提取运输层报文段，并将该报文段向上交给运输层。运输层则处理接收到的报文段，使该报文段中的数据为接收应用进程使用

网络应用程序可以使用多种的运输层协议。例如，因特网有两种协议，即TCP和UDP。每种协议都能为调用的应用程序提供一组不同的运输层服务

### 3.1.1 运输层和网络层的关系

在协议栈中，运输层刚好位于网络层之上。网络层提供了主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供了逻辑通信。这种差别虽然细微但很重要

在端系统中，运输层协议将来自应用进程的报文移动到网络边缘(即网络层)，反过来也是一样，但对有关这些报文在网络核心如何移动并不作任何规定。事实上，中间路由器既不处理也不识别运输层加在应用层报文的任何信息。

计算机网络中可以安排多种运输层协议，每种协议为应用程序提供不同的服务模型

运输协议能够提供的服务常常受制于底层网络层协议的服务模型。如果网络层协议无法为主机之间发送的运输层报文段提供时延或带宽保证的话，运输层协议也就无法为进程之间发送的应用程序报文提供时延或带宽保证

然而，即使底层网络协议不能在网络层提供相应的服务，运输层协议也能提供某些服务。例如，如我们将在本章所见，即使底层网络协议是不可靠的，也就是说网络层协议会使分组丢失、篡改和冗余，运输协议也能为应用程序提供可靠的数据传输服务。另一个例子是(我们在[第8章 计算机网络中的安全](8.计算机网络中的安全.md)讨论网络安全时将会研究到)，即使网络层不能保证运输层报文段的机密性，运输协议也能使用加密来确保应用程序报文不被入侵者读取

### 3.1.2 因特网运输层概述

因特网为应用层提供了两种截然不同的可用运输层协议。这些协议一种是UDP(用户数据报协议)，它为调用它的应用程序提供了一种不可靠、无连接的服务。另一种是TCP(传输控制协议)，它为调用它的应用程序提供了一种可靠的、面向连接的服务

在对UDP和TCP进行简要介绍之前，简单介绍一下因特网的网络层(我们将在[第4章 网络层：数据平面](4.网络层：数据平面.md)和[第5章 网络层：控制平面](5.网络层：控制平面.md)中详细地学习网络层)是有用的。因特网网络层协议有一个名字叫IP，即网际协议。IP为主机之间提供了逻辑通信。IP的服务模型是**尽力而为交付服务**。这意味着IP尽它"最大的努力"在通信的主机之间交付报文段，但它并不做任何确保。特别是，它不确保报文段的交付，不保证报文段的按序交付，不保证报文段中数据的完整性。由于这些原因，IP被称为**不可靠服务**。在此还要指出的是，每台主机至少有一个网络层地址，即所谓的IP地址

在对IP服务模型有了初步了解后，我们总结一下UDP和TCP所提供的服务模型。UDP和TCP最基本的责任是，将两个端系统间IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务。将主机间交付扩展到进程间交付被称为运输层的**多路复用**与**多路分解**。我们将在[3.2 多路复用和多路分解](#32-多路复用和多路分解)讨论运输层的多路复用与多路分解。UDP和TCP还可以通过在其报文段首部中包括差错检查字段而提供完整性检查。进程到进程的数据交付和差错检查是两种最低限度的运输层服务，也是UDP所能提供的仅有的两种服务。特别是，与IP—样，UDP也是一种不可靠的服务，即不能保证一个进程所发送的数据能够完整无缺地(或全部)到达目的进程。在[3.3 无连接运输：UDP](#33-无连接运输udp)中将更详细地讨论UDP

另一方面，TCP为应用程序提供了几种附加服务。首先，它提供**可靠数据传输**。通过使用流量控制、序号、确认和定时器(本章将详细介绍这些技术)，TCP确保正确地、按序地将数据从发送进程交付给接收进程。这样，TCP就将两个端系统间的不可靠IP服务转换成了一种进程间的可靠数据传输服务。TCP还提供**拥塞控制**。拥塞控制与其说是一种提供给调用它的应用程序的服务，不如说是一种提供给整个因特网的服务，这是一种带来通用好处的服务。不太严格地说，TCP拥塞控制防止任何一条TCP连接用过多流量来淹没通信主机之间的链路和交换设备。TCP力求为每个通过一条拥塞网络链路的连接平等地共享网络链路带宽。这可以通过调节TCP连接的发送端发送进网络的流量速率来做到。在另一方面，UDP流量是不可调节的。使用UDP传输的应用程序可以根据其需要以其愿意的任何速率发送数据

## 3.2 多路复用和多路分解

在本节中，我们讨论运输层的多路复用与多路分解，也就是将由网络层提供的主机到主机交付服务延伸到为运行在主机上的应用程序提供进程到进程的交付服务。为了使讨论具体起见，我们将在因特网环境中讨论这种基本的运输层服务。然而，需要强调的是，多路复用与多路分解服务是所有计算机网络都需要的

在目的主机，运输层从紧邻其下的网络层接收报文段。运输层负责将这些报文段中的数据交付给在主机上运行的适当应用程序进程。一个进程(作为网络应用的一部分)有一个或多个**套接字(socket)**，它相当于从网络向进程传递数据和从进程向网络传递数据的门户。因此，在接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交给了一个中间的套接字。由于在任一时刻，在接收主机上可能有不止一个套接字，所以每个套接字都有唯一的标识符。标识符的格式取决于它是UDP还是TCP套接字，我们将很快对它们进行讨论

现在我们考虑接收主机怎样将一个到达的运输层报文段定向到适当的套接字。为此目的，每个运输层报文段中具有几个字段。在接收端，运输层检查这些字段，标识出接收套接字，进而将报文段定向到该套接字。将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解**。在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络层，所有这些工作称为**多路复用**。尽管我们在因特网运输层协议的环境下引入了多路复用和多路分解，认识到下列事实是重要的：它们与在某层(在运输层或别处)的单一协议何时被位于接下来的较高层的多个协议使用有关

通过上述讨论，我们知道运输层多路复用要求：1.套接字有唯一标识符；2.每个报文段有特殊字段来指示该报文段所要交付到的套接字。这些特殊字段是**源端口号字段**和**目的端口号字段**(UDP报文段和TCP报文段还有其他的一些字段，这些将在本章后继几节中进行讨论)。端口号是一个16比特的数，其大小在0~65535之间。0~1023范围的端口号称为**周知端口号**，是受限制的，这是指它们保留给诸如HTTP(它使用端口号80)和FTP(它使用端口号21)之类的周知应用层协议来使用。当我们开发一个新的应用程序时，必须为其分配一个端口号

现在应该清楚运输层是怎样能够实现分解服务的了：在主机上的每个套接字能够分配一个端口号，当报文段到达主机时，运输层检査报文段中的目的端口号，并将其定向到相应的套接字。然后报文段中的数据通过套接字进入其所连接的进程。UDP大体上是这样做的，然而TCP中的多路复用与多路分解更为复杂

1. 无连接的多路复用与多路分解

假定在主机A中的一个进程具有UDP端口19157，它要发送一个应用程序数据块给位于主机B中的另一进程，该进程具有UDP端口46428。主机A中的运输层创建一个运输层报文段，其中包括应用程序数据、源端口号(19157)、目的端口号(46428)和两个其他值(将在后面讨论，它对当前的讨论并不重要)。然后，运输层将得到的报文段传递到网络层。网络层将该报文段封装到一个IP数据报中，并尽力而为地将报文段交付给接收主机。如果该报文段到达接收主机B，接收主机运输层就检查该报文段中的目的端口号(46428)并将该报文段交付给端口号46428所标识的套接字。值得注意的是，主机B能够运行多个进程，每个进程有自己的UDP套接字及相应的端口号。当UDP报文段从网络到达时，主机B通过检查该报文段中的目的端口号，将每个报文段定向(分解)到相应的套接字

一个UDP套接字是由一个二元组全面标识的，该二元组包含一个目的IP地址和一个目的端口号。因此，如果两个UDP报文段有不同的源IP地址和/或源端口号，但具有相同的目的IP地址和目的端口号，那么这两个报文段将通过相同的目的套接字被定向到相同的目的进程

源端口号的用途为在A到B的报文段中，源端口号用作"返回地址"的一部分，即当B需要回发一个报文段给A时，B到A的报文段中的目的端口号便从A到B的报文段中的源端口号中取值(完整的返回地址是A的IP地址和源端口号)

2. 面向连接的多路复用与多路分解

TCP套接字和UDP套接字之间的一个细微差别是，TCP套接字是由一个四元组(源IP地址，源端口号，目的IP地址，目的端口号)来标识的。因此，当一个TCP报文段从网络到达一台主机时，该主机使用全部4个值来将报文段定向(分解)到相应的套接字。特别与UDP不同的是，两个具有不同源IP地址或源端口号的到达TCP报文段将被定向到两个不同的套接字，除非TCP报文段携带了初始创建连接的请求

服务器主机可以支持很多并行的TCP套接字，每个套接字与一个进程相联系，并由其四元组来标识每个套接字。当一个TCP报文段到达主机时，所有4个字段(源IP地址，源端口，目的IP地址，目的端口)被用来将报文段定向(分解)到相应的套接字

3. Web服务器与TCP

考虑一台运行Web服务器的主机，例如在端口80上运行一个Apache Web服务器。当客户(如浏览器)向该服务器发送报文段时，所有报文段的目的端口都将为80。特别是，初始连接建立报文段和承载HTTP请求的报文段都有80的目的端口。如我们刚才描述的那样，该服务器能够根据源IP地址和源端口号来区分来自不同客户的报文段

一台Web服务器为每条连接生成一个新进程。每个这样的进程都有自己的连接套接字，通过这些套接字可以收到HTTP请求和发送HTTP响应然而，我们要提及的是，连接套接字与进程之间并非总是有着一一对应的关系。事实上，当今的高性能Web服务器通常只使用一个进程，但是为每个新的客户连接创建一个具有新连接套接字的新线程(线程可被看作是一个轻量级的子进程)。对于这样一台服务器，在任意给定的时间内都可能有(具有不同标识的)许多连接套接字连接到相同的进程

如果客户与服务器使用持续HTTP，则在整条连接持续期间，客户与服务器之间经由同一个服务器套接字交换HTTP报文。然而，如果客户与服务器使用非持续HTTP，则对每一对请求/响应都创建一个新的TCP连接并在随后关闭，因此对每一对请求/响应创建一个新的套接字并在随后关闭。这种套接字的频繁创建和关闭会严重地影响一个繁忙的Web服务器的性能(尽管有许多操作系统技巧可用来减轻这个问题的影响)

## 3.3 无连接运输：UDP

运输层最低限度必须提供一种复用/分解服务，以便在网络层与正确的应用级进程之间传递数据。UDP只是做了运输协议能够做的最少工作，除了复用/分解功能及少量的差错检测外，它几乎没有对IP增加别的东西。实际上，如果应用程序开发人员选择UDP而不是TCP，则该应用程序差不多就是直接与IP打交道。UDP从应用进程得到数据，附加上用于多路复用/分解服务的源和目的端口号字段，以及两个其他的小字段，然后将形成的报文段交给网络层。网络层将该运输层报文段封装到一个IP数据报中，然后尽力而为地尝试将此报文段交付给接收主机。如果该报文段到达接收主机，UDP使用目的端口号将报文段中的数据交付给正确的应用进程。值得注意的是，使用UDP时，在发送报文段之前，发送方和接收方的运输层实体之间没有握手。正因为如此，UDP被称为是无连接的

DNS是一个通常使用UDP的应用层协议的例子。当一台主机中的DNS应用程序想要进行一次查询时，它构造了一个DNS查询报文并将其交给UDP。无须执行任何与运行在目的端系统中的UDP实体之间的握手，主机端的UDP为此报文添加首部字段，然后将形成的报文段交给网络层。网络层将此UDP报文段封装进一个IP数据报中，然后将其发送给一个名字服务器。在查询主机中的DNS应用程序则等待对该查询的响应。如果它没有收到响应(可能是由于底层网络丢失了查询或响应)，则要么试图向另一个名字服务器发送该査询，要么通知调用的应用程序它不能获得响应

* UDP优点：

	1. **关于发送什么数据以及何时发送的应用层控制更为精细**：采用UDP时，只要应用进程将数据传递给UDP， UDP就会将此数据打包进UDP报文段并立即将其传递给网络层。在另一方面，TCP有一个拥塞控制机制，以便当源和目的主机间的一条或多条链路变得极度拥塞时来遏制运输层TCP发送方。TCP仍将继续重新发送数据报文段直到目的主机收到此报文并加以确认，而不管可靠交付需要用多长时间。因为实时应用通常要求最小的发送速率，不希望过分地延迟报文段的传送，且能容忍一些数据丢失，TCP服务模型并不是特别适合这些应用的需要。如后面所讨论的，这些应用可以使用UDP，并作为应用的一部分来实现所需的、超出UDP的不提供不必要的报文段交付服务之外的额外功能

	2. **无须连接建立**：TCP在开始数据传输之前要经过三次握手。UDP却不需要任何准备即可进行数据传输。因此UDP不会引入建立连接的时延。这可能是DNS运行在UDP之上而不是运行在TCP之上的主要原因(如果运行在TCP上，则DNS会慢得多)。HTTP使用TCP而不是UDP，因为对于具有文本数据的Web网页来说，可靠性是至关重要的。但是，如在[2.2 Web和HTTP](#22-web和http)中简要讨论的那样，HTTP中的TCP连接建立时延对于与下载Web文档相关的时延来说是一个重要因素。用于谷歌的Chrome浏览器中的QU1C协议(快速UDP因特网连接)将UDP作为其支撑运输协议并在UDP之上的应用层协议中实现可靠性

	3. **无连接状态**：TCP需要在端系统中维护连接状态。此连接状态包括接收和发送缓存、拥塞控制参数以及序号与确认号的参数。我们将在[3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)看到，要实现TCP的可靠数据传输服务并提供拥塞控制，这些状态信息是必要的。另一方面，UDP不维护连接状态，也不跟踪这些参数。因此，某些专门用于某种特定应用的服务器当应用程序运行在UDP之上而不是运行在TCP上时，一般都能支持更多的活跃客户

	4. **分组首部开销小**：每个TCP报文段都有20字节的首部开销，而UDP仅有8字节的开销

使用UDP的应用是可能实现可靠数据传输的。这可通过在应用程序自身中建立可靠性机制来完成(例如，可通过增加确认与重传机制来实现，如采用我们将在下一节学习的一些机制)。我们前面讲过在谷歌的Chrome浏览器中所使用的QUIC协议在UDP之上的应用层协议中实现了可靠性。但这并不是无足轻重的任务，它会使应用开发人员长时间地忙于调试。无论如何，将可靠性直接构建于应用程序中可以使其"左右逢源"。也就是说应用进程可以进行可靠通信，而无须受制于由TCP拥塞控制机制强加的传输速率限制。

### 3.3.1 UDP报文段结构

UDP报文段结构如下表所示↓：

|每行为32比特|
|:-:|
|源端口号，目的端口号|
|长度，校验和|
|应用数据(报文)|

应用层数据占用UDP报文段的数据字段

UDP首部只有4个字段，每个字段由两个字节组成。通过端口号可以使目的主机将应用数据交给运行在目的端系统中的相应进程(即执行分解功能)。长度字段指示了在UDP报文段中的字节数(首部加数据)，因为数据字段的长度在一个UDP段中不同于在另一个段中，故需要一个明确的长度。接收方使用检验和来检查在该报文段中是否出现了差错。实际上，计算检验和时，除了UDP报文段以外还包括了IP首部的一些字段。但是我们忽略这些细节，以便能从整体上看问题

### 3.3.2 UDP校验和

UDP检验和提供了差错检测功能。这就是说，检验和用于确定当UDP报文段从源到达目的地移动时，其中的比特是否发生了改变(例如，由于链路中的噪声干扰或者存储在路由器中时引入问题)。发送方的UDP对报文段中的所有16比特字的和进行反码运算，求和时遇到的任何溢出都被回卷。得到的结果被放在UDP报文段中的检验和字段。在接收方，全部的4个16比特字(包括检验和)加在一起。如果该分组中没有引入差错，则显然在接收方处该和将全为1，如果这些比特之一是0，那么我们就知道该分组中已经出现了差错

为什么UDP首先提供了检验和，就像许多链路层协议也提供了差错检测那样。其原因是不能保证源和目的之间的所有链路都提供差错检测；这就是说，也许这些链路中的一条可能使用没有差错检测的协议。此外，即使报文段经链路正确地传输，当报文段存储在某台路由器的内存中时，也可能引入比特差错。在既无法确保逐链路的可靠性，又无法确保内存中的差错检测的情况下，如果端到端数据传输服务要提供差错检测，UDP就必须在端到端基础上在运输层提供差错检测。这是一个在系统设计中被称颂的**端到端原则**的例子，该原则表述为因为某种功能(在此时为差错检测)必须基于端到端实现："与在较高级别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余的或几乎没有价值的。"

因为假定IP是可以运行在任何第二层协议之上的，运输层提供差错检测作为一种保险措施是非常有用的。虽然UDP提供差错检测，但它对差错恢复无能为力。UDP的某种实现只是丢弃受损的报文段；其他实现是将受损的报文段交给应用程序并给出警告

## 3.4 可靠数据运输原理

可靠数据传输的实现问题不仅在运输层出现，也会在链路层以及应用层出现

可靠数据传输的框架为上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。借助于可靠信道，传输数据比特就不会受到损坏(由0变为1，或者相反)或丢失，而且所有数据都是按照其发送顺序进行交付。这恰好就是TCP向调用它的因特网应用所提供的服务模型

实现这种服务抽象是可靠数据传输协议的责任。由于可靠数据传输协议的下层协议也许是不可靠的，因此这是一项困难的任务。例如，TCP是在不可靠的(IP)端到端网络层之上实现的可靠数据传输协议。更一般的情况是，两个可靠通信端点的下层可能是由一条物理链路(如在链路级数据传输协议的场合下)组成或是由一个全球互联网络(如在运输级协议的场合下)组成。然而，就我们的目的而言，我们可将较低层直接视为不可靠的点对点信道

在本节中，我们仅考虑**单向数据传输**的情况，即数据传输是从发送端到接收端的。可靠的**双向数据传输**(即全双工数据传输)情况从概念上讲不会更难，但解释起来更为单调乏味。虽然我们只考虑单向数据传输，注意到下列事实是重要的，我们的协议也需要在发送端和接收端两个方向上传输分组。我们很快会看到，除了交换含有待传送的数据的分组之外，rdt的发送端和接收端还需往返交换控制分组。rdt的发送端和接收端都要通过调用udt_send()发送分组给对方(其中udt表示不可靠数据传输，rdt表示可靠数据传输)

### 3.4.1 构造可靠数据传输协

1. 经完全可靠信道的可靠数据传输：rdt1.0

首先，我们考虑最简单的情况，即底层信道是完全可靠的。我们称该协议为rdt1.0，该协议本身是简单的。rdt1.0发送方和接收方的**有限状态机(FSM**)的定义如下所示

rdt的发送端只通过rdt_send(data)事件接受来自较高层的数据，产生一个包含该数据的分组(经由make-pkt(data)动作)，并将分组发送到信道中。实际上，rdt_send(data)事件是由较高层应用的过程调用产生的(例如，rdt_send())

在接收端，rdt通过rdt_rcv(packet)事件从底层信道接收一个分组，从分组中取岀数据(经由extract(packet，data)动作)，并将数据上传给较高层(通过deliver_data(data)动作)。实际上，rdt_rcv(packet)事件是由较低层协议的过程调用产生的(例如，rdt_rcv())

在这个简单的协议中，一个单元数据与一个分组没差别。而且，所有分组是从发送方流向接收方；有了完全可靠的信道，接收端就不需要提供任何反馈信息给发送方，因为不必担心出现差错！注意到我们也已经假定了接收方接收数据的速率能够与发送方发送数据的速率一样快。因此，接收方没有必要请求发送方慢一点

2. 经具有比特差错信道的可靠数据传输：rdt2.0

底层信道更为实际的模型是分组中的比特可能受损的模型。在分组的传输、传播或缓存的过程中，这种比特差错通常会岀现在网络的物理部件中。我们眼下还将继续假定所有发送的分组(虽然有些比特可能受损)将按其发送的顺序被接收

在计算机网络环境中，基于**肯定确认**和**否定确认**这样的重传机制的可靠数据传输协议称为**自动重传请求(ARQ**)协议

* ARQ协议中还需要另外三种协议功能来处理存在比特差错的情况

	1. **差错检测**：首先，需要一种机制以使接收方检测到何时出现了比特差错。前一节讲到，UDP使用因特网检验和字段正是为了这个目的。在[第5章 网络层：控制平面](5.网络层：控制平面.md)中，我们将更详细地学习差错检测和纠错技术。这些技术使接收方可以检测并可能纠正分组中的比特差错。此刻，我们只需知道这些技术要求有额外的比特(除了待发送的初始数据比特之外的比特)从发送方发送到接收方；这些比特将被汇集在rdt2.0数据分组的分组检验和字段中

	2. **接收方反馈**：因为发送方和接收方通常在不同端系统上执行，发送方要了解接收方情况(此时为分组是否被正确接收)的唯一途径就是让接收方提供明确的反馈信息给发送方。rdt2.0协议将从接收方向发送方回送ACK(肯定确认)与NAK(否定确认)分组。理论上，这些分组只需要一个比特长；如用0表示NAK，用1表示ACK

	3. **重传**：接收方收到有差错的分组时，发送方将重传该分组

采用了差错检测、肯定确认与否定确认的rdt2.0的FSM如下所述：

rdt2.0的发送端有两个状态。在等待来自上层的调用的状态中，发送端协议正等待来自上层传下来的数据。当rdt_send(data)事件岀现时，发送方将产生一个包含待发送数据的分组(sndpkt)，带有检验和，然后经由udt_send(sndpkt)操作发送该分组。在等待ACK或NAK的状态中，发送方协议等待来自接收方的ACK或NAK分组。如果收到一个ACK分组，则发送方知道最近发送的分组已被正确接收，因此协议返回到等待来自上层的数据的状态。如果收到一个NAK分组，该协议重传上一个分组并等待接收方为响应重传分组而回送的ACK和NAK。注意到下列事实很重要：当发送方处于等待ACK或NAK的状态时，它不能从上层获得更多的数据；这就是说，rdt_send()事件不可能岀现；仅当接收到ACK并离开该状态时才能发生这样的事件。因此，发送方将不会发送一块新数据，除非发送方确信接收方已正确接收当前分组。由于这种行为，rdt2.0这样的协议被称为**停等**协议

rdt2.0接收方的FSM仍然只有单一状态。当分组到达时，接收方要么回答一个ACK，要么回答一个NAK，这取决于收到的分组是否受损

rdt2.0协议看起来似乎可以运行了，但遗憾的是，它存在一个致命的缺陷。尤其是我们没有考虑到ACK或NAK分组受损的可能性! 遗憾的是，我们细小的疏忽并非像它看起来那么无关紧要。至少，我们需要在ACK/NAK分组中添加检验和比特以检测这样的差错。更难的问题是协议应该怎样纠正ACK或NAK分组中的差错。这里的难点在于，如果一个ACK或NAK分组受损，发送方无法知道接收方是否正确接收了上一块发送的数据

解决这个新问题的一个简单方法(几乎所有现有的数据传输协议中，包括TCP，都采用了这种方法)是在数据分组中添加一新字段，让发送方对其数据分组编号，即将发送数据分组的**序号**放在该字段。于是，接收方只需要检查序号即可确定收到的分组是否一次重传。对于停等协议这种简单情况，1比特序号就足够了，因为它可让接收方知道发送方是否正在重传前一个发送分组(接收到的分组序号与最近收到的分组序号相同)，或是一个新分组(序号变化了，用模2运算"前向"移动)。因为目前我们假定信道不丢分组，ACK和NAK分组本身不需要指明它们要确认的分组序号。发送方知道所接收到的ACK和NAK分组(无论是否是含糊不清的)是为响应其最近发送的数据分组而生成的

rdt2.1的FSM是rdt2.0的修订版，rdt2.1的发送方和接收方FSM的状态数都是以前的两倍。这是因为协议状态此时必须反映出目前(由发送方)正发送的分组或(在接收方)希望接收的分组的序号是0还是1。值得注意的是，发送或期望接收0号分组的状态中的动作与发送或期望接收1号分组的状态中的动作是相似的；唯一的不同是序号处理的方法不同

协议rdt2.1使用了从接收方到发送方的肯定确认和否定确认。当接收到失序的分组时，接收方对所接收的分组发送一个肯定确认。如果收到受损的分组，则接收方将发送一个否定确认。如果不发送NAK，而是对上次正确接收的分组发送一个ACK，我们也能实现与NAK—样的效果。发送方接收到对同一个分组的两个ACK(即接收**冗余ACK**)后，就知道接收方没有正确接收到跟在被确认两次的分组后面的分组

3. 经具有比特差错的丢包信道的可靠数据传输：rdt3.0

现在假定除了比特受损外，底层信道还会丢包，这在今天的计算机网络(包括因特网)中并不罕见。协议现在必须处理另外两个关注的问题：怎样检测丢包以及发生丢包后该做些什么。在rdt2.1中已经研发的技术，如使用检验和、序号、ACK分组和重传等，使我们能给出后一个问题的答案。为解决第一个关注的问题，还需增加一种新的协议机制

有很多可能的方法用于解决丢包问题。这里，我们让发送方负责检测和恢复丢包工作。假定发送方传输一个数据分组，该分组或者接收方对该分组的ACK发生了丢失。在这两种情况下，发送方都收不到应当到来的接收方的响应。如果发送方愿意等待足够长的时间以便确定分组已丢失，则它只需重传该数据分组即可。你应该相信该协议确实有效

但是发送方需要等待多久才能确定已丢失了某些东西呢？很明显发送方至少需要等待这样长的时间：即发送方与接收方之间的一个往返时延(可能会包括在中间路由器的缓冲时延)加上接收方处理一个分组所需的时间。在很多网络中，最坏情况下的最大时延是很难估算的，确定的因素非常少。此外，理想的协议应尽可能快地从丢包中恢复出来；等待一个最坏情况的时延可能意味着要等待一段较长的时间，直到启动差错恢复为止。因此实践中采取的方法是发送方明智地选择一个时间值，以判定可能发生了丢包(尽管不能确保)。如果在这个时间内没有收到ACK，则重传该分组。注意到如果一个分组经历了一个特别大的时延，发送方可能会重传该分组，即使该数据分组及其ACK都没有丢失。这就在发送方到接收方的信道中引入了**冗余数据分组**的可能性。幸运的是，rdt2.1协议已经有足够的功能(即序号)来处理冗余分组情况

从发送方的观点来看，重传是一种万能灵药。发送方不知道是一个数据分组丢失，还是一个ACK丢失，或者只是该分组或ACK过度延时。在所有这些情况下，动作是同样的：重传。为了实现基于时间的重传机制，需要一个**倒计数定时器**，在一个给定的时间量过期后，可中断发送方。因此，发送方需要能做到：1.每次发送一个分组(包括第一次分组和重传分组)时，便启动一个定时器；2.响应定时器中断(采取适当的动作)；3.终止定时器

因为分组序号在0和1之间交替，因此rdt3.0有时被称为**比特交替协议**

现在我们归纳一下数据传输协议的要点。在检验和、序号、定时器、肯定和否定确认分组这些技术中，每种机制都在协议的运行中起到了必不可少的作用。至此，我们得到了一个可靠数据传输协议

### 3.4.2 流水线可靠数据传输协议

rdt3.0性能问题的核心在于它是一个停等协议。定义发送方(或信道)的利用率为：发送方实际忙于将发送比特送进信道的那部分时间与发送时间之比$U_{sender}=\frac{L/R}{RTT+L/R}$，其中L为分组字节长度，R为信道发送速率，RTT为往返传播时延，并且上式还忽略了在发送方和接收方的底层协议处理时间，以及可能岀现在发送方与接收方之间的任何中间路由器上的处理与排队时延

这种特殊的性能问题的一个简单解决方法是：不以停等方式运行，允许发送方发送多个分组而无须等待确认。因为许多从发送方向接收方输送的分组可以被看成是填充到一条流水线中，故这种技术被称为**流水线**。流水线技术对可靠数据传输协议可带来如下影响：

* 必须增加序号范围，因为每个输送中的分组(不计算重传的)必须有一个唯一的序号，而且也许有多个在输送中的未确认报文

* 协议的发送方和接收方两端也许不得不缓存多个分组。发送方最低限度应当能缓冲那些已发送但没有确认的分组。如下面讨论的那样，接收方或许也需要缓存那些已正确接收的分组

* 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。解决流水线的差错恢复有两种基本方法是：**回退N步(GBN**)和**选择重传(SR)**

### 3.4.3 回退N步(GBN)

在回退N步(GBN)协议中，允许发送方发送多个分组(当有多个分组可用时)而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数/V

发送方看到的GBN协议的序号范围中，如果我们将**基序号(base**)定义为最早未确认分组的序号，将**下一个序号(nextseqnum**)定义为最小的未使用序号(即下一个待发分组的序号)，则可将序号范围分割成4段。在［0，base-1］段内的序号对应于已经发送并被确认的分组。［base，nextseqnum-1］段内对应已经发送但未被确认的分组。［nextseqnum，base+N-1］段内的序号能用于那些要被立即发送的分组，如果有数据来自上层的话。最后，大于或等于base+N的序号是不能使用的，直到当前流水线中未被确认的分组(特别是序号为base的分组)已得到确认为止

那些已被发送但还未被确认的分组的许可序号范围可以被看成是一个在序号范围内长度为N的窗口。随着协议的运行，该窗口在序号空间向前滑动。因此，N常被称为**窗口长度**，GBN协议也常被称为**滑动窗口协议**。你也许想知道，我们为什么先要限制这些被发送的、未被确认的分组的数目为N呢？为什么不允许这些分组为无限制的数目呢？我们将在[3.5.5 流量控制](#355-流量控制)节看到，流量控制是对发送方施加限制的原因之一。我们将在[3.7 TCP拥塞控制](#37-tcp拥塞控制)节学习TCP拥塞控制时分析另一个原因。

我们将在[3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)节看到，TCP有一个32比特的序号字段，其中的TCP序号是按字节流中的字节进行计数的，而不是按分组计数

* GBN发送方必须响应三种类型的事件

	* **上层的调用**：当上层调用rdt_send()时，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送，并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。然后上层可能会过一会儿再试。在实际实现中，发送方更可能缓存(并不立刻发送)这些数据，或者使用同步机制(如一个信号量或标志)允许上层在仅当窗口不满时才调用rdt_send()

	* **收到一个ACK**：在GBN协议中，对序号为几的分组的确认采取**累积确认**的方式，表明接收方已正确接收到序号为n的以前且包括n在内的所有分组。稍后讨论GBN接收方一端时，我们将再次研究这个主题

	* **超时事件**：协议的名字"回退N步"来源于出现丢失和时延过长分组时发送方的行为。就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。如果出现超时，发送方重传所有已发送但还未被确认过的分组。如果收到一个ACK，但仍有已发送但未被确认的分组，则定时器被重新启动。如果没有已发送但未被确认的分组，停止该定时器

* 在GBN中，接收方的动作也很简单。如果一个序号为n的分组被正确接收到，并且按序(即上次交付给上层的数据是序号为n-1的分组)，则接收方为分组n发送一个ACK，并将该分组中的数据部分交付到上层。在所有其他情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK。注意到因为一次交付给上层一个分组，如果分组k已接收并交付，则所有序号比k小的分组也已经交付。因此，使用累积确认是GBN一个自然的选择

在GBN协议中，接收方丢弃所有失序分组。尽管丢弃一个正确接收(但失序)的分组有点愚蠢和浪费，但这样做是有理由的。前面讲过，接收方必须按序将数据交付给上层。假定现在期望接收分组n而分组n+1却到了。因为数据必须按序交付，接收方可能缓存(保存)分组n+1，然后，在它收到并交付分组n后，再将该分组交付到上层。然而，如果分组n丢失，则该分组及分组n+1最终将在发送方根据GBN重传规则而被重传。因此，接收方只需丢弃分组n+1即可。不需要缓存任何失序分组。因此，虽然发送方必须维护窗口的上下边界及nextseqnum在该窗口中的位置，但是接收方需要维护的唯一信息就是下一个按序接收的分组的序号。该值保存在expectedseqnum变量中.当然，丢弃一个正确接收的分组的缺点是随后对该分组的重传也许会丢失或出错，因此甚至需要更多的重传

该实现也可能是以各种过程形式出现，每个过程实现了在响应各种可能岀现的事件时要采取的动作。在这种**基于事件的编程**方式中，这些过程要么被协议栈中的其他过程调用，要么作为一次中断的结果。在发送方，这些事件包括：1.来自上层实体的调用去调用rdt_send()；2.定时器中断；3.报文到达时，来自下层的调用去调用rdt_rcv()

GBN协议中综合了我们将在[3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)中学习TCP可靠数据传输构件时遇到的所有技术。这些技术包括使用序号、累积确认、检验和以及超时/重传操作

### 3.4.4 选择重传(SR)

GBN协议潜在地允许发送方用多个分组"填充流水线"，因此避免了停等协议中所提到的信道利用率问题。然而，GBN本身也有一些情况存在着性能问题。尤其是当窗口长度和带宽时延都很大时，在流水线中会有很多分组更是如此。单个分组的差错就能够引起GBN重传大量分组，许多分组根本没有必要重传。随着信道差错率的增加，流水线可能会被这些不必要重传的分组所充斥

选择重传(SR)协议通过让发送方仅重传那些它怀疑在接收方出错(即丢失或受损)的分组而避免了不必要的重传。这种个别的、按需的重传要求接收方逐个地确认正确接收的分组。再次用窗口长度N来限制流水线中未完成、未被确认的分组数。然而，与GBN不同的是，发送方已经收到了对窗口中某些分组的ACK

SR接收方将确认一个正确接收的分组而不管其是否按序。失序的分组将被缓存直到所有丢失分组(即序号更小的分组)皆被收到为止，这时才可以将一批分组按序交付给上层

* SR发送方的事件与动作

	* **从上层收到数据**：当从上层接收到数据后，SR发送方检查下一个可用于该分组的序号。如果序号位于发送方的窗口内，则将数据打包并发送；否则就像在GBN中一样，要么将数据缓存，要么将其返回给上层以便以后传输

	* **超时**：定时器再次被用来防止丢失分组。然而，现在每个分组必须拥有其自己的逻辑定时器，因为超时发生后只能发送一个分组。可以使用单个硬件定时器模拟多个逻辑定时器的操作

	* **收到ACK**：如果收到ACK，倘若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。如果该分组的序号等于send_base，则窗口基序号向前移动到具有最小序号的未确认分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组

* SR接收方的事件与动作

	* **序号在［rcv_base，rcv_base+N-1］内的分组被正确接收**：在此情况下，收到的分组落在接收方的窗口内，一个选择ACK被回送给发送方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号(rcv_base)，则该分组以及以前缓存的序号连续的(起始于rcv_base的)分组交付给上层。然后.接收窗口按向前移动分组的编号向上交付这些分组

	* 序号在［rcv_base-N，rcv_base-1］内的分组被正确收到。在此情况下，必须产生一个ACK，
即使该分组是接收方以前已确认过的分组

	* 其他情况。忽略该分组

	* 注意到第二种情况下，接收方重新确认(而不是忽略)已收到过的那些序号小于当前窗口基序号的分组。这种重新确认确实是需要的。例如，如果分组send_base的ACK没有从接收方传播回发送方，则发送方最终将重传分组send_base，即使显然(对我们而不是对发送方来说)接收方已经收到了该分组。如果接收方不确认该分组，则发送方窗口将永远不能向前滑动！这个例子说明了SR协议(和很多其他协议一样)的一个重要方面。对于哪些分组已经被正确接收，哪些没有，发送方和接收方并不总是能看到相同的结果。对SR协议而言，这就意味着发送方和接收方的窗口并不总是一致


* 可靠数据传输机制及其用途的总结

	* 校验和：用于检测在一个传输分组中的比特错误

	* 定时器：用于超时/重传一个分组，可能因为该分组(或其ACK)在信道中丢失了。由于当一个分组延时但未丢失(过早超时)，或当一个分组已被接收方收到但从接收方到发送方的ACK丢失时，可能产生超时事件，所以接收方可能会收到一个分组的多个冗余副本

	* 序号：用于为从发送方流向接收方的数据分组按顺序编号。所接收分组的序号间的空隙可使接收方检测出丢失的分组。具有相同序号的分组可使接收方检测岀一个分组的冗余副本

	* 确认：接收方用于告诉发送方一个分组或一组分组已被正确地接收到了。确认报文通常携带着被确认的分组或多个分组的序号。确认可以是逐个的或累积的，这取决于协议

	* 否定确认：接收方用于告诉发送方某个分组未被正确地接收。否定确认报文通常携带着未被正确接收的分组的序号

	* 窗口、流水线：发送方也许被限制仅发送那些序号落在一个指定范围内的分组。通过允许一次发送多个分组但未被确认，发送方的利用率可在停等操作模式的基础上得到增加。我们很快将会看到，窗口长度可根据接收方接收和缓存报文的能力、网络中的拥塞程度或两者情况来进行设置

我们曾假定分组在发送方与接收方之间的信道中不能被重新排序。这在发送方与接收方由单段物理线路相连的情况下，通常是一个合理的假设。然而，当连接两端的"信道"是一个网络时，分组重新排序是可能会发生的。分组重新排序的一个表现就是，一个具有序号或确认号x的分组的旧副本可能会出现，即使发送方或接收方的窗口中都没有包含x。对于分组重新排序，信道可被看成基本上是在缓存分组，并在将来任意时刻自然地释放岀这些分组。由于序号可以被重新使用，那么必须小心，以免出现这样的冗余分组。实际应用中采用的方法是，确保一个序号不被重新使用，直到发送方"确信"任何先前发送的序号为n的分组都不再在网络中为止。通过假定一个分组在网络中的"存活"时间不会超过某个固定最大时间量来做到这一点。在高速网络的TCP扩展中，最长的分组寿命被假定为大约3分钟

## 3.5 面向连接的运输：TCP

TCP是因特网运输层的面向连接的可靠的运输协议。我们在本节中将看到，为了提供可靠数据传输，TCP依赖于前一节所讨论的许多基本原理，其中包括差错检测、重传、累积确认、定时器以及用于序号和确认号的首部字段

### 3.5.1 TCP连接

TCP被称为是面向连接的(connection.oriented)，这是因为在一个应用进程可以开始向另一个应用进程发送数据之前，这两个进程必须先相互"握手"，即它们必须相互发送某些预备报文段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都将初始化与TCP连接相关的许多TCP状态变量(其中的许多状态变量将在本节和[3.7 TCP拥塞控制](#37-tcp拥塞控制)中讨论)

TCP连接是一条逻辑连接，其共同状态仅保留在两个通信端系统的TCP程序中。由于TCP协议只在端系统中运行，而不在中间的网络元素(路由器和链路层交换机)中运行，所以中间的网络元素不会维持TCP连接状态。事实上，中间路由器对TCP连接完全视而不见，它们看到的是数据报，而不是连接

TCP连接总是**点对点**的，即在单个发送方与单个接收方之间的连接。所谓"多播"，即在一次发送操作中，从一个发送方将数据传送给多个接收方，这种情况对TCP来说是不可能的

TCP连接是怎样建立的：假设运行在某台主机上的一个进程想与另一台主机上的一个进程建立一条连接。发起连接的这个进程被称为客户进程，而另一个进程被称为服务器进程。该客户应用进程首先要通知客户运输层，它想与服务器上的一个进程建立一条连接。客户首先发送一个特殊的TCP报文段，服务器用另一个特殊的TCP报文段来响应，最后，客户再用第三个特殊报文段作为响应。前两个报文段不承载"有效载荷"，也就是不包含应用层数据；而第三个报文段可以承载有效载荷。由于在这两台主机之间发送了3个报文段，所以这种连接建立过程常被称为**三次握手**

一旦建立起一条TCP连接，两个应用进程之间就可以相互发送数据了。我们考虑一下从客户进程向服务器进程发送数据的情况。客户进程通过套接字传递数据流。数据一旦通过套接字，它就由客户中运行的TCP控制了。TCP将这些数据引导到该连接的**发送缓存**里，发送缓存是发起三次握手期间设置的缓存之一。接下来TCP就会不时从发送缓存里取出一块数据，并将数据传递到网络层。在TCP规范中却没提及TCP应何时实际发送缓存里的数据，只是描述为"TCP应该在它方便的时候以报文段的形式发送数据"。TCP可从缓存中取出并放入报文段中的数据数量受限于**最大报文段长度(MSS)**。MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度(即所谓的**最大传输单元(MTU)**)来设置。设置该MSS要保证一个TCP报文段(当封装在一个IP数据报中)加上TCP/IP首部长度(通常40字节)将适合单个链路层帧。以太网和PPP链路层协议都具有1500字节的MTU，因此MSS的典型值为1460字节。已经提出了多种发现路径MTU的方法，并基于路径MTU值设置MSS(**路径MTU**是指能在从源到目的地的所有链路上发送的最大链路层帧)。注意到MSS是指在报文段里应用层数据的最大长度，而不是指包括首部的TCP报文段的最大长度

TCP为每块客户数据配上一个TCP首部，从而形成多个**TCP报文段**。这些报文段被下传给网络层，网络层将其分别封装在网络层IP数据报中。然后这些IP数据报被发送到网络中。当TCP在另一端接收到一个报文段后，该报文段的数据就被放入该TCP连接的接收缓存中。应用程序从此缓存中读取数据流。该连接的每一端都有各自的发送缓存和接收缓存

TCP连接的组成包括：一台主机上的缓存、变量和与进程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。在这两台主机之间的网络元素(路由器、交换机和中继器)中没有为该连接分配任何缓存和变量

### 3.5.2 TCP报文段结构

TCP报文段由首部字段和一个数据字段组成。数据字段包含一块应用数据。MSS限制了报文段数据字段的最大长度。当TCP发送一个大文件，，TCP通常是将该文件划分成长度为MSS的若干块(最后一块除外，它通常小于MSS)。然而，交互式应用通常传送长度小于MSS的数据块

TCP报文段结构如下↓：

|每行为16比特|
|:-:|
|源端口号|
|目的端口号|
|序号(1/2)|
|序号(2/2)|
|确认号(1/2)|
|确认号(2/2)|
|首部长度<br>保留未用<br>CWR<br>ECE<br>URG<br>ACK<br>PSH<br>RST<br>SYN<br>FIN|
|接受窗口|
|因特网校验和|
|紧急数据指针|
|选项(1/...)|
|选项......|
|数据(1/...)|
|数据......|

* 源端口号、目的端口号：用于多路复用/分解来自或送到上层应用的数据

* 序号字段、确认号：被TCP发送方和接收方用来实现可靠数据传输服务，讨论见后

* 首部长度(4比特)：指示了以32比特的字为单位的TCP首部长度。由于TCP选项字段的原因，TCP首部的长度是可变的(通常，选项字段为空，所以TCP首部的典型长度是20字节)

* 标志字段(6比特)：

	* CWR和ECE比特：明确拥塞通告

	* URG比特：用来指示报文段里存在着被发送端的上层实体置为"紧急"的数据。紧急数据的最后一个字节由16比特的**紧急数据指针字段**指出。当紧急数据存在并给出指向紧急数据尾指针的时候，TCP必须通知接收端的上层实体

	* ACK比特：用于指示确认字段中的值是有效的，即该报文段包括一个对已被成功接收报文段的确认

	* PSH比特：当PSH比特被置位时，就指示接收方应立即将数据交给上层

	* RST、SYN和FIN比特：用于连接建立和拆除，我们将在本节后面讨论该问题

	* 在实践中，PSH、URG和紧急数据指针并没有使用。为了完整性起见才提到这些字段

* 接受窗口：用于流量控制，用于指示接收方愿意接受的字节数量

* 校验和字段：用于检测在一个传输分组中的比特错误

* 紧急数据指针字段：对应于标志字段中的URG比特

TCP报文段首部中两个最重要的字段是序号字段和确认号字段。这两个字段是TCP可靠传输服务的关键部分

TCP把数据看成一个无结构的、有序的字节流。我们从TCP对序号的使用上可以看出这一点，因为序号是建立在传送的字节流之上，而不是建立在传送的报文段的序列之上。**一个报文段的序号**因此是该报文段首字节的字节流编号。假设主机A上的一个进程想通过一条TCP连接向主机B上的一个进程发送一个数据流。主机A中的TCP将隐式地对数据流中的每一个字节编号。假定数据流由一个包含500 000字节的文件组成，其MSS为1000字节，数据流的首字节编号是0。该TCP将为该数据流构建500个报文段。给第一个报文段分配序号0，第二个报文段分配序号1000，第三个报文段分配序号2000，以此类推。每一个序号被填入到相应TCP报文段首部的序号字段中

TCP是全双工的，因此主机A在向主机B发送数据的同时，也许也接收来自主机B的数据(都是同一条TCP连接的一部分)。从主机B到达的每个报文段中都有一个序号用于从B流向A的数据。主机A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号。假设主机A已收到了来自主机B的编号为0~535的所有字节，同时假设它打算发送一个报文段给主机B。主机A等待主机B的数据流中字节536及之后的所有字节。所以主机A就会在它发往主机B的报文段的确认号字段中填上536。因为TCP只确认该流中至第一个丢失字节为止的字节，所以TCP被称为提供**累积确认**

当主机在一条TCP连接中收到失序报文段时该怎么办？TCP规范并没有为此明确规定任何规则，而是把这一问题留给实现TCP的编程人员去处理。他们有两个基本的选择：1.接收方立即丢弃失序报文段(这可以简化接收方的设计)；2.接收方保留失序的字节，并等待缺少的字节以填补该间隔。显然，后一种选择对网络带宽而言更为有效，是实践中采用的方法

一条TCP连接的双方均可随机地选择初始序号。这样做可以减少将那些仍在网络中存在的来自两台主机之间先前已终止的连接的报文段，误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性(它碰巧与旧连接使用了相同的端口号)

### 3.5.3 往返时间的估计与超时

TCP如同前面[3.4 可靠数据运输原理](#34-可靠数据运输原理)节所讲的rdt协议一样，它采用超时/重传机制来处理报文段的丢失问题。尽管这在概念上简单，但是当在如TCP这样的实际协议中实现超时/重传机制时还是会产生许多微妙的问题。也许最明显的一个问题就是超时间隔长度的设置。显然，超时间隔必须大于该连接的往返时间(RTT)，即从一个报文段发出到它被确认的时间。否则会造成不必要的重传。但是这个时间间隔到底应该是多大呢？刚开始时应如何估计往返时间呢？是否应该为所有未确认的报文段各设一个定时器？本节讨论TCP中的某种实现

1. 估计往返时间

报文段的样本RTT(表示为SampleRTT)就是从某报文段被发出(即交给IP)到对该报文段的确认被收到之间的时间量。大多数TCP的实现仅在某个时刻做一次SampleRTT测量，而不是为每个发送的报文段测量一个SampleRTT。这就是说，在任意时刻，仅为一个已发送的但目前尚未被确认的报文段估计SampleRTT，从而产生一个接近每个RTT的新SampleRTT值。另外，TCP决不为已被重传的报文段计算SampleRTT；它仅为传输一次的报文段测量SampleRTT

由于路由器的拥塞和端系统负载的变化，这些报文段的SampleRTT值会随之波动。由于这种波动，任何给定的SampleRTT值也许都是非典型的。因此，为了估计一个典型的RTT，自然要采取某种对SampleRTT取平均的办法。TCP维持一个SampleRTT均值(称为EstimatedRTT)。一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新EstimatedRTT：$EstimatedRTT=(1-α)*EstimatedRTT+α*SampleRTT$。在［RFC 6298］中给岀的a推荐值是a=1/8。

EstimatedRTT是一个SampleRTT值的加权平均值。这个加权平均对最近的样本赋予的权值要大于对旧样本赋予的权值，因为越近的样本越能更好地反映网络的当前拥塞情况。从统计学观点讲，这种平均被称为**指数加权移动平均(EWMA)**。在 EWMA中的"指数"一词看起来是指一个给定的SampleRTT的权值在更新的过程中呈指数型快速衰减

除了估算RTT外，测量RTT的变化也是有价值的。RTT偏差DevRTT用于估算SampleRTT一般会偏离EstimatedRTT的程度：$DevRTT=(1-β)*DevRTT+β*|SampleRTT-EstimatedRTT|$。注意到DevRTT是一个SampleRTT与EstimatedRTT之间差值的EWMA。如果SampleRTT值波动较小，那么DevRTT的值就会很小；另一方面，如果波动很大，那么DevRTT的值就会很大。β的推荐值为0.25。

2. 设置和管理重传超时间隔

假设已经给岀了EstimatedRTT值和DevRTT值，那么TCP超时间隔应该用什么值呢？很明显，超时间隔应该大于等于EstimatedRTT，否则，将造成不必要的重传。但是超时间隔也不应该比EstimatedRTT大太多，否则当报文段丢失时，TCP不能很快地重传该报文段，导致数据传输时延大。因此要求将超时间隔设为EstimatedRTT加上一定余量。当SampleRTT值波动较大时，这个余量应该大些；当波动较小时，这个余量应该小些。因此，DevRTT值应该在这里发挥作用了。在TCP的确定重传超时间隔的方法中，所有这些因素都考虑到了：$TimeoutInterval=EstimatedRTT+4*DevRTT$。推荐的初始TimeoutInterval值为1秒。同时，当出现超时后，TimeoutInterval值将加倍，以免即将被确认的后继报文段过早出现超时。然而，只要收到报文段并更新EstimatedRTT，就使用上述公式再次计算TimeoutInterval

### 3.5.4 可靠数据传输

因特网的网络层服务(IP服务)是不可靠的。IP不保证数据报的交付，不保证数据报的按序交付，也不保证数据报中数据的完整性。对于IP服务，数据报能够溢出路由器缓存而永远不能到达目的地，数据报也可能是乱序到达，而且数据报中的比特可能损坏(由0变为1或者相反)。由于运输层报文段是被IP数据报携带着在网络中传输的，所以运输层的报文段也会遇到这些问题

TCP在IP不可靠的尽力而为服务之上创建了一种**可靠数据传输服务**。TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是无损坏、无间隙、非冗余和按序的数据流；即该字节流与连接的另一方端系统发送出的字节流是完全相同。TCP提供可靠数据传输的方法涉及[3.4 可靠数据运输原理](#34-可靠数据运输原理)中的许多原理

在前面研发可靠数据传输技术时，曾假定每一个已发送但未被确认的报文段都与一个定时器相关联，这在概念上是最简单的。虽然这在理论上很好，但定时器的管理却需要相当大的开销。因此，推荐的定时器管理过程仅使用单一的重传定时器，即使有多个已发送但还未被确认的报文段。在本节中描述的TCP协议遵循了这种单一定时器的推荐

我们将以两个递增的步骤来讨论TCP是如何提供可靠数据传输的。我们先给出一个TCP发送方的高度简化的描述，该发送方只用超时来恢复报文段的丢失；然后再给岀一个更全面的描述，该描述中除了使用超时机制外，还使用冗余确认技术。在接下来的讨论中，我们假定数据仅向一个方向发送，即从主机A到主机B，且主机A在发送一个大文件

一个TCP发送方高度简化的描述如下所示↓：

```python
# 假设发送方不受TCP流量和拥塞控制的限制
# 来自上层数据的长度小于MSS
# 数据传送只在一个方向进行

NextSeqNum = InitialSeqNumber
# 下一个要发送的报文段第一个数据字节的字节流编号

SendBase = InitialSeqNumber
# 最早未被确认的字节的序号
# SendBase - 1是指接收方已正确按序接收到的数据的最后一个字节的序号

while True:
	if 事件：从上面应用程序接收到数据e:
		生成具有序号NextSeqNum的TCP报文段
		if 定时器当前没有运行:
			启动定时器
		向IP传递报文段
		NextSeqNum = NextSeqNum+len(data)
	elif 事件：定时器超时:
		重传具有最小序号但仍未应答的报文段
		启动定时器
	elif 事件：收到ACK，具有ACK字段值y:
		if y > SendBase:
			SendBase = y
			if 当前仍无任何应答报文段(即当前有未被确认的报文段):
				启动定时器

```

* 超时间隔加倍

在定时器时限过期后超时间隔的长度中，每当超时事件发生时，TCP重传具有最小序号的还未被确认的报文段。只是每次TCP重传时都会将下一次的超时间隔设为先前值的两倍，而不是用从EstimatedRTT和DevRTT推算出的值(如在[3.5.3 往返时间的估计与超时](#353-往返时间的估计与超时)中所描述的)。因此，超时间隔在每次重传后会呈指数型增长。然而，每当定时器在另两个事件(即收到上层应用的数据和收到ACK)中的任意一个启动时，TimeoutInterval由最近的EstimatedRTT值与DevRTT值推算得到。

这种修改提供了一个形式受限的拥塞控制(更复杂的TCP拥塞控制形式将在[3.7 TCP拥塞控制](#37-tcp拥塞控制)中学习)。定时器过期很可能是由网络拥塞引起的，即太多的分组到达源与目的地之间路径上的一台(或多台)路由器的队列中，造成分组丢失或长时间的排队时延。在拥塞的时候，如果源持续重传分组，会使拥塞更加严重。相反，TCP使用更文雅的方式，每个发送方的重传都是经过越来越长的时间间隔后进行的。当我们在[第6章 链路层和局域网](6.链路层和局域网.md)学习CSMA/CD时，将看到以太网采用了类似的思路

* 快速重传

超时触发重传存在的问题之一是超时周期可能相对较长。当一个报文段丢失时，这种长超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端时延。幸运的是，发送方通常可在超时事件发生之前通过注意所谓**冗余ACK**来较好地检测到丢包情况。冗余ACK就是再次确认某个报文段的ACK，而发送方先前已经收到对该报文段的确认。要理解发送方对冗余ACK的响应，我们必须首先看一下接收方为什么会发送冗余ACK。下表总结了TCP接收方的ACK生成策略。当TCP接收方收到一个具有这样序号的报文段时，即其序号大于下一个所期望的、按序的报文段，它检测到了数据流中的一个间隔，这就是说有报文段丢失。这个间隔可能是由于在网络中报文段丢失或重新排序造成的。因为TCP不使用否定确认所以接收方不能向发送方发回一个显式的否定确认。相反，它只是对已经接收到的最后一个按序字节数据进行重复确认(即产生一个冗余ACK)即可(在下表中允许接收方不丢弃失序报文段)↓：

|事件|TCP接收方动作|
|:-:|:-:|
|具有所期望序号的按序报文段到达。所有在期望序号及以前的数据都已经被确认|延迟的ACK。对另一个按序报文段的到达最多等待500ms。如果下一个按序报文段在这个时间间隔内没有到达，则发送一个ACK|
|具有所期望序号的按序报文段到达。另一个按序报文段等待ACK传输|立即发送单个累积ACK，以确认两个按序报文段|
|比期望序号大的失序报文段到达。检测出间隔|立即发送冗余ACK，指示下一个期待字节的序号(其为间隔的低端的序号)|
|能部分或完全填充接收数据间隔的报文段到达|倘若该报文段起始于间隔的低端，则立即发送ACK|

因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余ACK。如果TCP发送方接收到对相同数据的3个冗余ACK，它把这当作一种指示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。一旦收到3个冗余ACK，TCP就执行**快速重传**，即在该报文段的定时器过期之前重传丢失的报文段。对于采用快速重传的TCP，可用下列代码片段代替本节上文中ACK收到事件

```python
if 事件：收到ACK，具有ACK字段值y:
	if y > SendBase:
		SendBase = y
		if 当前仍无任何应答报文段(即当前有未被确认的报文段):
			启动定时器
	else:	# 快对已经确认的报文段的一个冗余ACK
		对y收到的冗余ACK数加1
		if 对y收到的冗余ACK数==3:
			重新发送具有序号y的报文段	# TCP快速重传
```

* 回退N步还是选择重传

TCP确认是累积式的，正确接收但失序的报文段是不会被接收方逐个确认的。因此，TCP发送方仅需维持已发送过但未被确认的字节的最小序号(SendBase)和下一个要发送的字节的序号(NextSeqNum)。在这种意义下，TCP看起来更像一个GBN风格的协议。但是TCP和GBN协议之间有着一些显著的区别。许多TCP实现会将正确接收但失序的报文段缓存起来

对TCP提岀的一种修改意见是所谓的**选择确认**，它允许TCP接收方有选择地确认失序报文段，而不是累积地确认最后一个正确接收的有序报文段。当将该机制与选择重传机制结合起来使用时(即跳过重传那些已被接收方选择性地确认过的报文段)，TCP看起来就很像我们通常的SR协议。因此，TCP的差错恢复机制也许最好被分类为GBN协议与SR协议的混合体

### 3.5.5 流量控制

一条TCP连接的每一侧主机都为该连接设置了接收缓存。当该TCP连接收到正确、按序的字节后，它就将数据放入接收缓存。相关联的应用进程会从该缓存中读取数据，但不必是数据刚一到达就立即读取。事实上，接收方应用也许正忙于其他任务，甚至要过很长时间后才去读取该数据。如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出

TCP为它的应用程序提供了**流量控制服务**以消除发送方使接收方缓存溢岀的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。TCP发送方也可能因为IP网络的拥塞而被遏制；这种形式的发送方的控制被称为**拥塞控制**，我们将在[3.6 拥塞控制原理](#36-拥塞控制原理)节和[3.7 TCP拥塞控制](#37-tcp拥塞控制)节详细地讨论这个主题。即使流量控制和拥塞控制采取的动作非常相似(对发送方的遏制)，但是它们显然是针对完全不同的原因而采取的措施。为了能从整体上看问题，我们在本节都假设TCP是这样实现的，即TCP接收方丢弃失序的报文段

TCP通过让发送方维护一个称为**接收窗口**的变量来提供流量控制。通俗地说，接收窗口用于给发送方一个指示---该接收方还有多少可用的缓存空间。因为TCP是全双工通信，在连接两端的发送方都各自维护一个接收窗口。我们在文件传输的情况下研究接收窗口。假设主机A通过一条TCP连接向主机B发送一个大文件。主机B为该连接分配了一个接收缓存，并用RcvBuffer来表示其大小。主机B上的应用进程不时地从该缓存中读取数据

我们定义以下变量：LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号；LastByteRcvd：从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节的编号。由于TCP不允许已分配的缓存溢岀，下式必须成立：LastByteRcvd - LastByteRead <= RcvBuffer。接收窗口用rwnd表示，根据缓存可用空间的数量来设置：rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)。由于该空间是随着时间变化的，所以rwnd是动态的

连接是如何使用变量rwnd来提供流量控制服务的呢？主机B通过把当前的rwnd值放入它发给主机A的报文段接收窗口字段中，通知主机A它在该连接的缓存中还有多少可用空间。开始时，主机B设定rwnd = RcvBuffer。注意到为了实现这一点，主机B必须跟踪几个与连接有关的变量。主机A轮流跟踪两个变量，LastByteSent和LastByteAcked，这两个变量的意义很明显。注意到这两个变量之间的差LastByteSent - LastByteAcked，就是主机A发送到连接中但未被确认的数据量。通过将未确认的数据量控制在值rwnd以内，就可以保证主机A不会使主机B的接收缓存溢出。因此，主机A在该连接的整个生命周期须保证：LastByteSent - LastByteAcked <= rwnd

对于这个方案还存在一个小小的技术问题。假设主机B的接收缓存已经存满，使得rwnd = 0。在将rwnd = 0通告给主机A之后，还要假设主机B没有任何数据要发给主机A。此时，因为主机B上的应用进程将缓存清空，TCP并不向主机A发送带有rwnd新值的新报文段；事实上，TCP仅当在它有数据或有确认要发时才会发送报文段给主机A。这样，主机A不可能知道主机B的接收缓存已经有新的空间了，即主机A被阻塞而不能再发送数据！为了解决这个问题，TCP规范中要求：当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值

描述了 TCP的流量控制服务以后，我们在此要简要地提一下UDP并不提供流量控制，报文段由于缓存溢出可能在接收方丢失。例如，考虑一下从主机A上的一个进程向主机B上的一个进程发送一系列UDP报文段的情形。对于一个典型的UDP实现，UDP将在一个有限大小的缓存中加上报文段，该缓存在相应套接字(进程的门户)"之前"。进程每次从缓存中读取一个完整的报文段。如果进程从缓存中读取报文段的速度不够快，那么缓存将会溢出，并且将丢失报文段

### 3.5.6 TCP连接管理

* 观察一条TCP连接是如何建立的：假设运行在一台主机(客户)上的一个进程想与另一台主机(服务器)上的一个进程建立一条连接。客户应用进程首先通知客户TCP，它想建立一个与服务器上某个进程之间的连接。客户中的TCP会用以下方式与服务器中的TCP建立一条TCP连接↓：

	1. 客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文段中不包含应用层数据。但是在报文段的首部中的SYN比特标志位被置为1。因此，这个特殊报文段被称为**SYN报文段**。另外，客户会随机地选择一个初始序号(client_isn)，并将此编号放置于该起始的TCP SYN报文段的序号字段中。该报文段会被封装在一个IP数据报中，并发送给服务器。为了避免某些安全性攻击，在适当地随机化选择client_isn方面有着不少有趣的研究

	2. 一旦包含TCP SYN报文段的IP数据报到达服务器主机(假定它的确到达了)，服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段(我们将在[第8章 计算机网络中的安全](8.计算机网络中的安全.md)看到，在完成三次握手的第三步之前分配这些缓存和变量，使得TCP易于受到称为SYN洪泛的拒绝服务攻击)。这个允许连接的报文段也不包含应用层数据。但是，在报文段的首部却包含3个重要的信息。首先，SYN比特被置为1。其次，该TCP报文段首部的确认号字段被置为client_isn + 1。最后，服务器选择自己的初始序号(server_isn)，并将其放置到TCP报文段首部的序号字段中。这个允许连接的报文段实际上表明了："我收到了你发起建立连接的SYN分组，该分组带有初始序号client_isn。我同意建立该连接。我自己的初始序号是server_isn。"该允许连接的报文段被称为**SYNACK报文段**

	3. 在收到SYNACK报文段后，客户也要给该连接分配缓存和变量。客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认(该客户通过将值server_isn + 1放置到TCP报文段首部的确认字段中来完成此项工作)。因为连接已经建立了，所以该SYN比特被置为0。该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据

	* 一旦完成这3个步骤，客户和服务器主机就可以相互发送包括数据的报文段了。在以后每一个报文段中，SYN比特都将被置为0。注意到为了创建该连接，在两台主机之间发送了3个分组。由于这个原因，这种连接创建过程通常被称为**3次握手**

* 参与一条TCP连接的两个进程中的任何一个都能终止该连接。当连接结束后，主机中的"资源"(即缓存和变量)将被客户释放。假设某客户打算关闭连接，客户应用进程发出一个关闭连接命令。这会引起客户TCP向服务器进程发送一个特殊的TCP报文段。这个特殊的报文段让其首部中的一个标志位即FIN比特被设置为1。当服务器接收到该报文段后，就向发送方回送一个确认报文段。然后，服务器发送它自己的终止报文段，其FIN比特被置为1。最后该客户对这个服务器的终止报文段进行确认。此时，在两台主机上用于该连接的所有资源都被释放了

在一个TCP连接的生命周期内，运行在每台主机中的TCP协议在各种**TCP状态**之间变迁：

* 客户端TCP会经历的一系列典型TCP状态如下↓：

	* 客户TCP开始时处于CLOSED(关闭)状态

	* 客户的应用程序发起一个新的TCP连接。这引起客户中的TCP向服务器中的TCP发送一个SYN报文段。在发送过SYN报文段后，客户TCP进入了SYN_SENT状态

	* 当客户TCP处在SYN_SENT状态时，它等待来自服务器TCP的对客户所发报文段进行确认且SYN比特被置为1的SYNACK报文段。收到这样一个报文段之后，客户TCP进入ESTABLISHED(已建立)状态

	* 当处在ESTABLISHED状态时，客户TCP就能发送和接收包含有效载荷数据(即应用层产生的数据)的TCP报文段了

	* 假设客户应用程序决定要关闭该连接(注意到服务器也能选择关闭该连接)。这引起客户TCP发送一个带有FIN比特被置为1的TCP报文段，并进入FIN_WAIT_1状态

	* 当处在FIN_WAIT_1状态时，客户TCP等待一个来自服务器的带有确认的TCP报文段。当它收到该报文段时，客户TCP不对收到的报文段进行回复，而是直接进入FIN_WAIT_2状态

	* 当处在FIN_WAIT_2状态时，客户等待来自服务器的FIN比特被置为1的另一个报文段；当收到该报文段后，
客户TCP对服务器的报文段进行确认，并进入TIME_WAIT状态

	* 假定ACK丢失，TIME_WAIT状态使TCP客户重传最后的确认报文。在TIME_WAIT状态中所消耗的时间是与具体实现有关的，而典型的值是30秒、1分钟或2分钟。经过等待后，连接就正式关闭，客户端所有资源(包括端口号)将被释放

* 服务器端TCP会经历的一系列典型TCP状态如下，其中假设客户开始连接拆除↓：

	* 服务器TCP开始时处于CLOSED(关闭)状态

	* 服务器的应用程序创建一个监听套接字，服务器TCP进入了LISTEN状态

	* 当服务器TCP处在LISTEN状态时，它等待来自客户TCP的SYN比特被置为1的SYN报文段，收到这样一个报文段之后，服务器TCP对收到的报文段进行确认且发送SYN比特被置为1的SYNACK报文段，服务器TCP进入SYN_RCVD状态

	* 当服务器受到ACK确认报文后，不发送回复报文，服务器TCP进入ESTABLISHED(已建立)状态

	* 当处在ESTABLISHED状态时，服务器TCP就能发送和接收包含有效载荷数据(即应用层产生的数据)的TCP报文段了

	* 当服务器受到一个带有FIN比特被置为1的TCP报文段时，服务器发送该报文段的确认ACK报文段，服务器进入CLOSE_WAIT状态

	* 当服务器TCP处在CLOSE_WAIT状态时，服务器向客户发送一个FIN比特被置为1的报文段，服务器进入LAST_ACK状态

	* 当服务器TCP处于LAST_ACK状态时，服务器TCP收到客户对上一条发送的FIN比特被置为1的报文段的确认报文段，服务器不对该收到的报文段进行回复确认，直接进入CLOSE状态

上面的讨论假定了客户和服务器都准备通信，即服务器正在监听客户发送其SYN报文段的端口。现在来考虑当一台主机接收到一个TCP报文段，其端口号或源IP地址与该主机上进行中的套接字都不匹配的情况。例如，假如一台主机接收了具有目的端口80的一个TCP SYN分组，但该主机在端口80不接受连接(即它不在端口80上运行Web服务器)。则该主机将向源发送一个特殊重置报文段。该TCP报文段将RST标志位置为1。因此，当主机发送一个重置报文段时，它告诉该源"我没有那个报文段的套接字。请不要再发送该报文段了"。当一台主机接收一个UDP分组，它的目的端口与进行中的UDP套接字不匹配，该主机发送一个特殊的ICMP数据报，这将在[第4章 网络层：数据平面](4.网络层：数据平面.md)中讨论

## 3.6 拥塞控制原理

在前面几节中已经分析了面临分组丢失时用于提供可靠数据传输服务的基本原理及特定的TCP机制。在实践中，这种丢包一般是当网络变得拥塞时由于路由器缓存溢岀引起的。分组重传因此作为网络拥塞的征兆(某个特定的运输层报文段的丢失)来对待，但是却无法处理导致网络拥塞的原因，因为有太多的源想以过高的速率发送数据。为了处理网络拥塞原因，需要一些机制以在面临网络拥塞时遏制发送方

### 3.6.1 拥塞原因与代价

通过分析3个复杂性越来越高的发生拥塞的情况，开始对拥塞控制的一般性研究。在每种情况下，我们首先将看看出现拥塞的原因以及拥塞的代价(根据资源未被充分利用以及端系统得到的低劣服务性能来评价)。我们暂不关注如何对拥塞做出反应或避免拥塞，而是重点理解一个较为简单的问题，即随着主机增加其发送速率并使网络变得拥塞，这时会发生的情况

1. 情况一：两个发送方和一台具有无穷大缓存的路由器

先考虑也许是最简单的拥塞情况：两台发送端主机(A和B)都有一条连接，且这两条连接共享源与目的地之间的单跳路由。来自主机A和主机B的分组通过一台路由器，在一段容量为R的共享式输出链路上传输。该路由器带有缓存，可用于当分组到达速率超过该输出链路的容量时存储"入分组"。在此第一种情况下，我们将假设路由器有无限大的缓存空间。**发送速率**为应用程序将初始数据发送到套接字中的速率，**每连接的吞吐量**为接收方每秒接收的字节数。

当发送速率在0~R/2之间时，接收方的吞吐量等于发送方的发送速率，即发送方发送的所有数据经有限时延后到达接收方。然而当发送速率超过R/2时，它的吞吐量只能达R/2。这个吞吐量上限是由两条连接之间共享链路容量造成的。链路完全不能以超过R/2的稳定状态速率向接收方交付分组。无论主机A和主机B将其发送速率设置为多高，它们都不会看到超过R/2的吞吐量

取得每连接R/2的吞吐量实际上看起来可能是件好事，因为在将分组交付到目的地的过程中链路被充分利用了。但是当发送速率接近R/2时，平均时延就会越来越大。当发送速率超过R/2时，路由器中的平均排队分组数就会无限增长，源与目的地之间的平均时延也会变成无穷大(假设这些连接以此发送速率运行无限长时间并且有无限量的缓存可用)。因此，虽然从吞吐量角度看，运行在总吞吐量接近R的状态也许是一个理想状态，但从时延角度看，却远不是一个理想状态

在这种(极端)理想化的情况中，我们已经发现了拥塞网络的一种代价，即当分组的到达速率接近链路容量时，分组经历巨大的排队时延

2. 情况二：两个发送方和一台具有有限缓存的路由器

从下列两个方面对情况1稍微做一些修改。首先，假定路由器缓存的容量是有限的，当分组到达一个已满的缓存时会被丢弃。其次，我们假定每条连接都是可靠的。如果一个包含有运输层报文段的分组在路由器中被丢弃，那么它终将被发送方重传。由于分组可以被重传，所以**发送速率**表示示应用程序将初始数据发送到套接字中的速率，**供给载荷**表示运输层向网络中发送报文段(含有初始数据或重传数据)的速率

首先，考虑一种不真实的情况，即主机A能够以某种方式(不可思议地)确定路由器中的缓存是否空闲，因而仅当缓存空闲时才发送一个分组。在这种情况下，将不会产生丢包，发送速率与供给载荷相等，并且连接的吞吐量就等于发送速率。从吞吐量的角度看，性能是理想的，即发送的每个分组都被接收到。注意到在这种情况下，平均主机发送速率不能超过R/2，因为假定不会发生分组丢失

接下来考虑一种更为真实的情况，发送方仅当在确定了一个分组已经丢失时才重传(同样，所做的假设有一些弹性。然而，发送主机有可能将超时时间设置得足够长，以无形中使其确信一个还没有被确认的分组已经丢失)。在这种情况下，我们在此看到了另一种网络拥塞的代价，即发送方必须执行重传以补偿因为缓存溢出而丢弃(丢失)的分组

最后，我们考虑下面一种情况：发送方也许会提前发生超时并重传在队列中已被推迟但还未丢失的分组。在这种情况下，初始数据分组和重传分组都可能到达接收方。当然，接收方只需要一份这样的分组副本就行了，重传分组将被丢弃。在这种情况下，路由器转发重传的初始分组副本是在做无用功，因为接收方已收到了该分组的初始版本。而路由器本可以利用链路的传输能力去发送另一个分组。这里，我们又看到了网络拥塞的另一种代价，即发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本

3. 情况三：4个发送方和具有有限缓存的多台路由器及多跳路径

由于拥塞而丢弃分组的另一种代价，即当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了

### 3.6.2 拥塞控制方法

在最为宽泛的级别上，我们可根据网络层是否为运输层拥塞控制提供了显式帮助，来区分拥塞控制方法

* **端到端拥塞控制**：在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显式支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察(如分组丢失与时延)来推断之。我们将在[3.7.1 公平性](#371-公平性)中将看到，TCP采用端到端的方法解决拥塞控制，因为IP层不会向端系统提供有关网络拥塞的反馈信息。TCP报文段的丢失(通过超时或3次冗余确认而得知)被认为是网络拥塞的一个迹象，TCP会相应地减小其窗口长度。我们还将看到关于TCP拥塞控制的一些最新建议，即使用增加的往返时延值作为网络拥塞程度增加的指示

* **网络辅助的拥塞控制**：在网络辅助的拥塞控制中，路由器向发送方提供关于网络中拥塞状态的显式反馈信息。这种反馈可以简单地用一个比特来指示链路中的拥塞情况。更复杂的网络反馈也是可能的。例如，在**ATM可用比特率(ABR**)拥塞控制中，路由器显式地通知发送方它(路由器)能在输出链路上支持的最大主机发送速率。如上面所提到的，默认因特网版本的IP和TCP采用端到端拥塞控制方法。然而，我们在[3.7.2 明确拥塞通告：网络辅助拥塞控制](#372-明确拥塞通告网络辅助拥塞控制)中将看到，最近IP和TCP也能够选择性地实现网络辅助拥塞控制

	* 对于网络辅助的拥塞控制，拥塞信息从网络反馈到发送方通常有两种方式。直接反馈信息可以由网络路由器发给发送方。这种方式的通知通常采用了一种**阻塞分组**的形式(主要是说："我拥塞了！")。更为通用的第二种形式的通知是，路由器标记或更新从发送方流向接收方的分组中的某个字段来指示拥塞的产生。一旦收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示。注意到后一种形式的通知至少要经过一个完整的往返时间

## 3.7 TCP拥塞控制

TCP为运行在不同主机上的两个进程之间提供了可靠传输服务。TCP的另一个关键部分就是其拥塞控制机制。如在前一节所指出，TCP必须使用端到端拥塞控制而不是使用网络辅助的拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈

TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。如果一个TCP发送方感知从它到目的地之间的路径上没什么拥塞，则TCP发送方增加其发送速率；如果发送方感知沿着该路径有拥塞，则发送方就会降低其发送速率。但是这种方法提出了三个问题：1.一个TCP发送方如何限制它向其连接发送流量的速率呢？2.一个TCP发送方如何感知从它到目的地之间的路径上存在拥塞呢？3.当发送方感知到端到端的拥塞时，采用何种算法来改变其发送速率呢？

首先分析TCP发送方是如何限制向其连接发送流量的。在[3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)中我们看到，TCP连接的每一端都是由一个接收缓存、一个发送缓存和几个变量(LastByteRead、rwnd等)组成。运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即**拥塞窗口**。拥塞窗口表示为cwnd，它对一个TCP发送方能向网络中发送流量的速率进行了限制。特别是，在一个发送方中未被确认的数据量不会超过cwnd与rvnd(接收窗口)中的最小值，即：$LastByteSend-LastByteAcked \le min(cwnd， rwnd)$。为了关注拥塞控制(与流量控制形成对比)，我们后面假设TCP接收缓存足够大，以至可以忽略接收窗口的限制；因此在发送方中未被确认的数据量仅受限于cwnd。我们还假设发送方总是有数据要发送，即在拥塞窗口中的所有报文段要被发送。上面的约束限制了发送方中未被确认的数据量，因此间接地限制了发送方的发送速率。为了理解这一点，我们来考虑一个丢包和发送时延均可以忽略不计的连接。因此粗略地讲，在每个往返时间(RTT)的起始点，上面的限制条件允许发送方向该连接发送cwnd个字节的数据，在该RTT结束时发送方接收对数据的确认报文。因此，该发送方的发送速率大概是cwnd/RTT字节/秒。通过调节cwnd的值，发送方因此能调整它向连接发送数据的速率

接下来考虑TCP发送方是如何感知在它与目的地之间的路径上出现了拥塞的。我们将一个TCP发送方的"丢包事件"定义为：要么出现超时，要么收到来自接收方的3个冗余ACK。当出现过度的拥塞时，在沿着这条路径上的一台(或多台)路由器的缓存会溢出，引起一个数据报(包含一个TCP报文段)被丢弃。丢弃的数据报接着会引起发送方的丢包事件(要么超时或收到3个冗余ACK)，发送方就认为在发送方到接收方的路径上出现了拥塞的指示

接下来考虑网络没有拥塞这种更为乐观的情况，即没有出现丢包事件的情况。在此情况下，在TCP的发送方将收到对于以前未确认报文段的确认。TCP将这些确认的到达作为一切正常的指示，即在网络上传输的报文段正被成功地交付给目的地，并使用确认来增加窗口的长度(及其传输速率)。注意到如果确认以相当慢的速率到达(例如，如果该端到端路径具有高时延或包含一段低带宽链路)，则该拥塞窗口将以相当慢的速率增加。在另一方面，如果确认以高速率到达，则该拥塞窗口将会更为迅速地增大。因为TCP使用确认来触发(或计时)增大它的拥塞窗口长度，TCP被说成是**自计时**的

给定调节cwnd值以控制发送速率的机制，关键的问题依然存在：TCP发送方怎样确定它应当发送的速率呢？如果众多TCP发送方总体上发送太快，它们能够拥塞网络，导致拥塞崩溃。事实上，为了应对在较早TCP版本下观察到的因特网拥塞崩溃，研发了该版本的TCP(我们马上将学习它)。然而，如果TCP发送方过于谨慎，发送太慢，它们不能充分利用网络的带宽；这就是说，TCP发送方能够以更高的速率发送而不会使网络拥塞。那么TCP发送方如何确定它们的发送速率，既使得网络不会拥塞，与此同时又能充分利用所有可用的带宽？TCP发送方是显式地协作，或存在一种分布式方法使TCP发送方能够仅基于本地信息设置它们的发送速率？TCP使用下列指导性原则回答这些问题↓：

* **一个丢失的报文段表意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率**：回想[3.5.4 可靠数据传输](#354-可靠数据传输)中的讨论，对于给定报文段，一个超时事件或四个确认(一个初始ACK和其后的三个冗余ACK)被解释为跟随该四个ACK的报文段的"丢包事件"的一种隐含的指示。从拥塞控制的观点看，该问题是TCP发送方应当如何减小它的拥塞窗口长度，即减小其发送速率，以应对这种推测的丢包事件

* **一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率**。确认的到达被认为是一切顺利的隐含指示，即报文段正从发送方成功地交付给接收方，因此该网络不拥塞。拥塞窗口长度因此能够增加

* **带宽探测**：给定ACK指示源到目的地路径无拥塞，而丢包事件指示路径拥塞，TCP调节其传输速率的策略是增加其速率以响应到达的ACK，除非岀现丢包事件，此时才减小传输速率。因此，为探测拥塞开始出现的速率，TCP发送方增加它的传输速率直到出现丢包，从该速率后退，进而再次开始探测直到丢包，看看拥塞开始速率是否发生了变化。注意到网络中没有明确的拥塞状态信令，即ACK和丢包事件充当了隐式信号，并且每个TCP发送方根据异步于其他TCP发送方的本地信息而行动

**TCP拥塞控制算法**：该算法包括3个主要部分：1.慢启动；2.拥塞避免；3.快速恢复。慢启动和拥塞避免是TCP的强制部分，两者的差异在于对收到的ACK做出反应时增加cwnd长度的方式。慢启动比拥塞避免能更快地增加cwnd的长度(不要被名称所迷惑)。快速恢复是推荐部分，对TCP发送方并非是必需的

1. 慢启动

当一条TCP连接开始时，cwnd的值通常初始置为一个MSS(最大报文段长度)的较小值，这就使得初始发送速率大约为MSS/RTT，即本次发送一个报文段。由于对TCP发送方而言，可用带宽可能比MSS/RTT大得多，TCP发送方希望迅速找到可用带宽的数量。因此，在慢启动状态，cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS。这一过程每过一个RTT，发送速率就翻番。因此，TCP发送速率起始慢，但在慢启动阶段以指数增长

但是，何时结束这种指数增长呢？

1、如果存在一个由超时指示的丢包事件(即拥塞)，TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量的值ssthresh("慢启动阈值"的速记)设置为cwnd/2，即当检测到拥塞时将ssthresh置为拥塞窗口值的一半

2、与ssthresh的值相关联。因为当检测到拥塞时ssthresh设为cwnd的值一半，当到达或超过ssthresh的值时，继续使cwnd翻番可能有些鲁莽。因此，当cwnd的值等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式。当进入拥塞避免模式时，TCP更为谨慎地增加cwnd

3、如果检测到3个冗余ACK，这时TCP执行一种快速重传(参见[3.5.4 可靠数据传输](#354-可靠数据传输)节)并进入快速恢复状态，后面将讨论相关内容

2. 拥塞避免

一旦进入拥塞避免状态，cwnd的值大约是上次遇到拥塞时的值的一半，即距离拥塞可能并不遥远！因此，TCP无法每过一个RTT再将cwnd的值翻番，而是采用了一种较为保守的方法，每个RTT只将cwnd的值增加一个MSS。这能够以几种方式完成。一种通用的方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加MSS/cwnd字节。例如，如果MSS是1460字节并且cwnd是14600字节，则在一个RTT内发送10个报文段。每个到达ACK(假定每个报文段一个ACK)增加1/10 MSS的拥塞窗口长度，因此在收到对所有10个报文段的确认后，拥塞窗口的值将增加了一个MSS

但是何时应当结束拥塞避免的线性增长(每RTT增加1个MSS)呢？

1、当出现超时时，TCP的拥塞避免算法与慢启动的情况一样，cwnd的值被设置为1个MSS

2、当丢包事件出现时，ssthresh的值被更新为cwnd值的一半。当丢包事件由三个冗余ACK事件触发时，TCP将cwnd的值减半(为使测量结果更好，计及已收到的3个冗余的ACK要加上3个MSS)，并且当收到3个冗余的ACK，将ssthresh的值记录为cwnd的值的一半。接下来进入快速恢复状态

3. 快速恢复阶段

在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的ACK，cwnd的值增加一个MSS。最终，当对丢失报文段的一个ACK到达时，TCP在降低cwnd后进入拥塞避免状态。如果出现超时事件，快速恢复在执行如同在慢启动和拥塞避免中相同的动作后，迁移到慢启动状态，cwnd的值被设置为1个MSS，并且ssthresh的值设置为cwnd值的一半

4. TCP拥塞控制回顾

忽略一条连接开始时初始的慢启动阶段，假定丢包由3个冗余的ACK而不是超时指示，TCP的拥塞控制是：每个RTT内cwnd线性(加性)增加1 MSS，然后出现3个冗余ACK事件时cwnd减半(乘性减)。因此，TCP拥塞控制常常被称为**加性增、乘性减(AIMD**)拥塞控制方式。TCP线性地增加它的拥塞窗口长度(因此增加其传输速率)，直到出现3个冗余ACK事件，然后以2为因子来减少它的拥塞窗口长度，然后又开始了线性增长，探测是否还有另外的可用带宽

上述算法的许多变种已被提出。TCP Vegas 算法试图在维持较好的吞吐量的同时避免拥塞。Vegas的基本思想是：1.在分组丢失发生之前，在源与目的地之间检测路由器中的拥塞；2.当检测出快要发生的分组丢失时，线性地降低发送速率。快要发生的分组丢失是通过观察RTT来预测的。分组的RTT越长，路由器中的拥塞越严重

TCP拥塞窗口cwnd在拥塞控制时的变化情况如下图所示↓：

![TCP拥塞窗口cwnd在拥塞控制时的变化情况](./images/TCP拥塞窗口cwnd在拥塞控制时的变化情况.png)

TCP的拥塞控制流程图如下图所示↓：

![TCP的拥塞控制流程图](./images/TCP的拥塞控制流程图.png)



### 3.7.1 公平性

考虑K条TCP连接，每条都有不同的端到端路径，但是都经过一段传输速率为R bps的瓶颈链路(所谓瓶颈链路，是指对于每条连接，沿着该连接路径上的所有其他段链路都不拥塞，而且与该瓶颈链路的传输容量相比，它们都有充足的传输容量)。假设每条连接都在传输一个大文件，而且无UDP流量通过该段瓶颈链路。如果每条连接的平均传输速率接近R/K，即每条连接都得到相同份额的链路带宽，则认为该拥塞控制机制是公平的

在理想化情形中，我们假设仅有TCP连接穿过瓶颈链路，所有的连接具有相同的RTT值，且对于一个主机-目的地对而言只有一条TCP连接与之相关联，TCP趋于在竞争的多条TCP连接之间提供对一段瓶颈链路带宽的平等分享。实践中，这些条件通常是得不到满足的，客户-服务器应用因此能获得非常不平等的链路带宽份额。特别是，已经表明当多条连接共享一个共同的瓶颈链路时，那些具有较小RTT的连接能够在链路空闲时更快地抢到可用带宽(即较快地打开其拥塞窗口)，因而将比那些具有较大RTT的连接享用更高的吞吐

1. 公平性和UDP

TCP拥塞控制是通过拥塞窗口机制来调节一个应用程序的传输速率的。许多多媒体应用如因特网电话和视频会议，经常就因为这种特定原因而不在TCP上运行，因为它们不想其传输速率被扼制，即使在网络非常拥塞的情况下。相反，这些应用宁可在UDP上运行，UDP是没有内置的拥塞控制的。当运行在UDP上时，这些应用能够以恒定的速率将其音频和视频数据注入网络之中并且偶尔会丢失分组，而不愿在拥塞时将其发送速率降至"公平"级别并且不丢失任何分组。从TCP的观点来看，运行在UDP上的多媒体应用是不公平的，因为它们不与其他连接合作，也不适时地调整其传输速率。因为TCP拥塞控制在面临拥塞增加(丢包)时，将降低其传输速率，而UDP源则不必这样做，UDP源有可能压制TCP流量

2. 公平性和并行TCP连接

即使我们能够迫使UDP流量具有公平的行为，但公平性问题仍然没有完全解决。这是因为我们没有什么办法阻止基于TCP的应用使用多个并行连接。例如，Web浏览器通常使用多个并行TCP连接来传送一个Web页中的多个对象(多条连接的确切数目可以在多数浏览器中进行配置)。当一个应用使用多条并行连接时，它占用了一条拥塞链路中较大比例的带宽。举例来说，考虑一段速率为R且支持9个在线客户-服务器应用的链路，每个应用使用一条TCP连接。如果一个新的应用加入进来，也使用一条TCP连接，则每个应用得到差不多相同的传输速率R/10。但是如果这个新的应用这次使用了11个并行TCP连接，则这个新应用就不公平地分到超过R/2的带宽。Web流量在因特网中是非常普遍的，所以多条并行连接并非不常见

### 3.7.2 明确拥塞通告：网络辅助拥塞控制

一个TCP发送方不会收到来自网络层的明确拥塞指示，而是通过观察分组丢失来推断拥塞。最近，对于IP和TCP的扩展方案已经提出并已经实现和部署，该方案允许网络明确向TCP发送方和接收方发出拥塞信号。这种形式的网络辅助拥塞控制称为**明确拥塞通告(ECN)**

在网络层，IP数据报首部的服务类型字段中的两个比特(总的说来，有四种可能的值)被用于ECN。路由器所使用的一种ECN比特设置指示该路由器正在历经拥塞。该拥塞指示则由被标记的IP数据报所携带，送给目的主机，再由目的主机通知发送主机。标准没有提供路由器拥塞时的定义；该判断是由路由器厂商所做的配置选择，并且由网络操作员决定。然而，标准推荐仅当拥塞持续不断存在时才设置ECN比特。发送主机所使用的另一种ECN比特设置通知路由器发送方和接收方是ECN使能的，因此能够对于ECN指示的网络拥塞采取行动

当接收主机中的TCP通过一个接收到的数据报收到了一个ECN拥塞指示时，接收主机中的TCP通过在接收方到发送方的TCP ACK报文段中设置ECE(明确拥塞通告回显)比特，通知发送主机中的TCP收到拥塞指示。接下来，TCP发送方通过减半拥塞窗口对一个具有ECE拥塞指示的ACK做出反应，就像它对丢失报文段使用快速重传做出反应一样，并且在下一个传输的TCP发送方到接收方的报文段首部中对CWR(拥塞窗口缩减)比特进行设置

除了TCP以外的其他运输层协议也可以利用网络层发送ECN信号。数据报拥塞控制协议(DCCP)提供了一种低开销、控制拥塞的类似UDP不可靠服务，该协议利用了ECN。DCTCP(数据中心TCP)是一种专门为数据中心网络设计的TCP版本，也利用了ECN

## 3.8 小结

本章我们首先学习了运输层协议能够向网络应用程序提供的服务。在一个极端，运输层协议非常简单，并向应用程序不提供不必要的服务，而仅向通信进程提供多路复用/分解的功能。因特网中的UDP协议就是这样一种不提供不必要服务的运输层协议。在另一个极端，运输层协议能够向应用程序提供各种各样的保证，例如数据的可靠交付、时延保证和带宽保证。无论如何，运输层协议能够提供的服务经常受下面网络层协议服务模型的限制。如果网络层协议不能向运输层报文段提供时延或带宽保证，那么运输层协议就不能向进程间发送的报文提供时延或带宽保证

在[3.4 可靠数据运输原理](#34-可靠数据运输原理)中，我们学习了运输层协议能够提供可靠数据传输，即使下面的网络层是不可靠的。我们看到了提供可靠的数据传送会遇到许多微妙的问题，但都可以通过精心地结合确认、定时器、重传以及序号机制来完成任务

尽管在本章中我们包含了可靠数据传送，但是我们应该理解在链路层、网络层、运输层或应用层协议中都可以提供可靠数据传送。该协议栈中上面4层的任意一层都可以实现确认、定时器、重传以及序号，能够向其上层提供可靠数据传送。事实上，在过去数年中，工程师以及计算机科学家们已经独立地设计并实现了提供可靠数据传送的链路层、网络层、运输层以及应用层协议(虽然这些协议中的许多已经销声匿迹了)

在[3.5 面向连接的运输：TCP](#35-面向连接的运输tcp)中，我们详细地研究了TCP协议，它是因特网中面向连接和可靠的运输层协议。我们知道TCP是非常复杂的，它涉及了连接管理、流量控制、往返时间估计以及可靠数据传送。事实上，TCP比我们描述的要更为复杂，即我们有意地避而不谈在各种TCP实现版本中广泛实现的各种TCP补丁、修复和改进。然而，所有这些复杂性都对网络层应用隐藏了起来。如果某主机上的客户希望向另一台主机上的服务器可靠地发送数据，它只需要打开对该服务器的一个TCP套接字，然后将数据注入该套接字。客户-服务器应用程序则乐于对TCP的复杂性视而不见

在[3.6 拥塞控制原理](#36-拥塞控制原理)中，我们从广泛的角度研究了拥塞控制，在[3.7 TCP拥塞控制](#37-tcp拥塞控制)中我们阐述了TCP是如何实现拥塞控制的。我们知道了拥塞控制对于网络良好运行是必不可少的。没有拥塞控制，网络很容易出现死锁，使得端到端之间很少或没有数据能被传输。在[3.7 TCP拥塞控制](#37-tcp拥塞控制)中我们学习了TCP实现的一种端到端拥塞控制机制，即当TCP连接的路径上判断不拥塞时，其传输速率就加性增；当岀现丢包时，传输速率就乘性减。这种机制也致力于做到每一个通过拥塞链路的TCP连接能平等地共享该链路带宽。我们也深入探讨了TCP连接建立和慢启动对时延的影响。我们观察到在许多重要场合，连接建立和慢启动会对端到端时延产生严重影响。我们再次强调，尽管TCP在这几年一直在发展，但它仍然是一个值得深入研究的领域，并且在未来的几年中还可能持续演化

在本章中我们对特定因特网运输协议的讨论集中在UDP和TCP上，它们是因特网运输层的两匹"驮马"。然而，对这两个协议的二十多年的经验已经使人们认识到，这两个协议都不是完美无缺的。研究人员因此在忙于研制其他的运输层协议，其中的几种现在已经成为IETF建议的标准

计算机网络能被划分成"网络边缘"和"网络核心"。网络边缘包含了在端系统中发生的所有事情。既然已经覆盖了应用层和运输层，我们关于网络边缘的讨论也就结束了。接下来是探寻网络核心的时候了！[第4章 网络层：数据平面](4.网络层：数据平面.md)和[第5章 网络层：控制平面](5.网络层：控制平面.md)将学习网络层，并且将在[第6章 链路层和局域网](6.链路层和局域网.md)继续学习链路层
