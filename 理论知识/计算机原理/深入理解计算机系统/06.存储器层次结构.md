- [处理器层次结构](#处理器层次结构)
	- [6.1 存储技术](#61-存储技术)
		- [6.11 随机访问存储器(RAM, Random-Access Memory)](#611-随机访问存储器ram-random-access-memory)
		- [6.1.2 磁盘存储](#612-磁盘存储)
		- [6.1.3 固态硬盘(SSD)](#613-固态硬盘ssd)
		- [6.1.4 存储技术趋势](#614-存储技术趋势)
	- [6.2 局部性](#62-局部性)
		- [6.2.1 对程序数据引用的局部性](#621-对程序数据引用的局部性)
		- [6.2.2 取指令的局部性](#622-取指令的局部性)
		- [6.2.3 局部性小结](#623-局部性小结)
	- [6.3 存储器层次结构](#63-存储器层次结构)
		- [6.3.1 存储器层次结构中的缓存](#631-存储器层次结构中的缓存)
		- [6.3.2 存储器层次结构概念小结](#632-存储器层次结构概念小结)
	- [6.4 高速缓存存储器](#64-高速缓存存储器)
		- [6.4.1 通用的高速缓存存储器组织结构](#641-通用的高速缓存存储器组织结构)
		- [6.4.2 直接映射高速缓存](#642-直接映射高速缓存)
		- [6.4.3 组相联高速缓存](#643-组相联高速缓存)
		- [6.4.4 全相联高速缓存](#644-全相联高速缓存)
		- [6.4.5 有关写的问题](#645-有关写的问题)
		- [6.4.6 一个真实的高速缓存层次结构的解剖](#646-一个真实的高速缓存层次结构的解剖)
		- [6.4.7 高速缓存参数的性能影响](#647-高速缓存参数的性能影响)
	- [6.5 编写高速缓存友好的代码](#65-编写高速缓存友好的代码)
	- [6.6 综合：高速缓存对程序性能的影响](#66-综合高速缓存对程序性能的影响)
		- [6.6.1 存储器山](#661-存储器山)
		- [6.6.2 重新排列循环以提高空间局部性](#662-重新排列循环以提高空间局部性)
		- [6.6.3 在程序中利用局部性](#663-在程序中利用局部性)
	- [6.7 小结](#67-小结)

# 处理器层次结构

到目前为止，在对系统的研究中，我们依赖于一个简单的计算机系统模型，CPU执行指令，而存储器系统为CPU存放指令和数据。在简单模型中，存储器系统是一个线性的字节数组，而CPU能够在一个常数时间内访问每个存储器位置。虽然迄今为止这都是一个有效的模型，但是它没有反映现代系统实际工作的方式。

实际上，存储器系统是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存存储器作为一部分存储在相对慢速的主存储器中数据和指令的缓冲区域。主存缓存存储在容量较大的、慢速磁盘上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。

如果程序需要的数据是存储在CPU寄存器中的，那么在指令的执行期间，在0个周期内就能访问到它们。如果存储在高速缓存中，需要4~75个周期。如果存储在主存中，需要上百个周期。而如果存储在磁盘上，需要大约几千万个周期

计算机程序的基本属性局部性：具有良好局部性的程序倾向于一次又一次地访问相同的数据项集合，或是倾向于访问邻近的数据项集合。具有良好局部性的程序比局部性差的程序更多地倾向于从存储器层次结构中较高层次处访问数据项，因此运行得更快。

## 6.1 存储技术

### 6.11 随机访问存储器(RAM, Random-Access Memory)

RAM分为两类：静态的和动态的。静态RAM(SRAM)比动态RAM(DRAM)更快，但也贵得多。SRAM用来作为高速缓存存储器，既可以在CPU芯片上，也可以在片下。DRAM用来作为主存以及图形系统的帧缓冲区。典型地，一个桌面系统的SRAM不会超过几兆字节，但是DRAM却有几百或者几千兆字节。

1. 静态RAM(SRAM)

SRAM将每个位存储在一个双稳态的存储器单元里。每个单元是用一个六晶体管电路来实现的。这个电路有这样一个属性，它可以无限期地保持在两个不同的电压配置或状态之一。其他任何状态都是不稳定的，从不稳定状态开始，电路会迅速地转移到两个稳定状态中的一个。

由于SRAM存储器单元的**双稳态特性**，只要有电，它就会永远地保持它的值。即使有干扰(例如电子噪音)来扰乱电压，当干扰消除时，电路就会恢复到稳定值。

2. 动态RAM(DRAM)

DRAM将每个位存储为对一个电容的充电。这个电容非常小，通常只有大约$30×10^{-15}F$。。DRAM存储器可以制造得非常密集，每个单元由一个电容和一个访问晶体管组成。但是，与SRAM不同，DRAM存储器单元对干扰非常敏感。当电容的电压被扰乱之后，它就永远不会恢复了。暴露在光线下会导致电容电压改变。实际上，数码照相机和摄像机中的传感器本质上就是DRAM单元的阵列。

很多原因会导致漏电，使得 DRAM单元在10～100毫秒时间内失去电荷。幸运的是,计算机运行的时钟周期是以纳秒来衡量的，所以相对而言这个保持时间是比较长的。内存系统必须周期性地通过读出，然后重写来刷新内存每一位。有些系统也使用纠错码，其中计算机的字会被多编码几个位(例如64位的字可能用72位来编码)，这样一来，电路可以发现并纠正一个字中任何单个的错误位。

||每位晶体管数|相对访问时间|是否持续|是否敏感|相对花费|应用|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|SRAM|6|1X|是|否|1000X|高速缓存存储器|
|DRAM|1|10X|否|是|1X|主存，帧缓冲区|

只要有供电，SRAM就会保持不变。与DRAM不同，SRAM不需要刷新。SRAM的存取比DRAM快。SRAM对诸如光和电噪声这样的干扰不敏感。代价是SRAM单元比DRAM单元使用更多的晶体管，因而密集度低，而且更贵,功耗更大。

3. 传统的DRAM

DRAM芯片中的单元(位)被分成d个超单元，每个超单元都由w个 DRAM单元组成。一个d×w的DRAM总共存储了dw位信息。超单元被组织成一个r行c列的长方形阵列，这里rc=d。每个超单元有形如(i,j)的地址，这里i表示行，而j表示列。信息通过称为引脚的外部连接器流入和流出芯片。每个引脚携带1位的信号。

存储领域从来没有为DRAM的阵列元素确定一个标准的名字。计算机构架师倾向于称之为“单元”，使这个术语具有DRAM存储单元之意。电路设计者倾向于称之为“字”，使之具有主存一个字之意。为了避免混淆，我们采用了无歧义的术语“超单元”。

每个DRAM芯片被连接到某个称为内存控制器的电路，这个电路可以一次传送w位到每个DRAM芯片或一次从每个DRAM芯片传出w位。为了读出超单元(i，j)的内容，内存控制器将行地址i发送到DRAM，然后是列地址j。DRAM把超单元(i，j)的内容发回给控制器作为响应。行地址i称为RAS(行访问选通脉冲)请求。列地址j称为CAS(列访问选通脉冲)请求。注意，RAS和CAS请求共享相同的DRAM地址引脚。

例如，要从16×8的DRAM中读出超单元(2，1)，内存控制器发送行地址2。DRAM的响应是将行2的整个内容都复制到一个内部行缓冲区。接下来，内存控制器发送列地址1。DRAM的响应是从行缓冲区复制出超单元(2，1)中的8位，并把它们发送到内存控制器。

电路设计者将DRAM组织成二维阵列而不是线性数组的一个原因是降低芯片上地址引脚的数量。例如，如果示例的128位DRAM被组织成一个16个超单元的线性数组，地址为0～15，那么芯片会需要4个地址引脚而不是2个。二维阵列组织的缺点是必须分两步发送地址，这增加了访问时间。

4. 内存模块

DRAM芯片封装在内存模块中，它插到主板的扩展槽上。

一个内存模块的基本思想。示例模块用8个64Mbit的8M×8的 DRAM芯片，总共存储64MB(兆字节)，这8个芯片编号为0~7。每个超单元存储主存的一个字节,而用相应超单元地址为(i，j)的8个超单元来表示主存中字节地址A处的64位字。在示例中，DRAM0存储第一个(低位)字节，DRAM1存储下一个字节，依此类推。

要取出内存地址A处的一个字，内存控制器将A转换成一个超单元地址(i，j)，并将它发送到内存模块，然后内存模块再将à和j广播到每个DRAM。作为响应，每个DRAM输出它的(i，j)超单元的8位内容。模块中的电路收集这些输出，并把它们合并成一个64位字,再返回给内存控制器。

通过将多个内存模块连接到内存控制器，能够聚合成主存。在这种情况中，当控制器收到一个地址A时，控制器选择包含A的模块k，将A转换成它的(i，j)的形式，并将(i，j)发送到模块k。

5. **增强的DRAM**：每种都是基于传统的DRAM单元，并进行一些优化，提高访问基本DRAM单元的速度。   * **快页模式DRAM(FPM DRAM)**。传统的DRAM将超单元的一整行复制到它的内部行缓冲区中，使用一个，然后丢弃剩余的。FPMDRAM 允许对同一行连续地访问可以直接从行缓冲区得到服务，从而改进了这一点。例如，要从一个传统的DRAM的行i中读4个超单元，内存控制器必须发送4个RAS/CAS请求，即使是行地址主在每个情况中都是一样的。要从一个FPMDRAM的同一行中读取超单元，内存控制器发送第一个RAS/CAS请求，后面跟三个CAS请求。初始的RAS/CAS请求将行i复制到行缓冲区，并返回CAS寻址的那个超单元。接下来三个超单元直接从行缓冲区获得，因此返回得比初始的超单元更快。

   * **扩展数据输出DRAM(EDO DRAM)**。FPM DRAM的一个增强的形式，它允许各个CAS信号在时间上靠得更紧密一点。

   * **同步DRAM(SDRAM)**。就它们与内存控制器通信使用一组显式的控制信号来说，常规的、FPM和EDO DRAM都是异步的。SDRAM用与驱动内存控制器相同的外部时钟信号的上升沿来代替许多这样的控制信号。我们不会深入讨论细节，最终效果就是SDRAM能够比那些异步的存储器更快地输出它的超单元的内容。

   * **双倍数据速率同步DRAM(DDR SDRAM)**。DDR SDRAM是对SDRAM的一种增强，它通过使用两个时钟沿作为控制信号,从而使 DRAM的速度翻倍。不同类型的DDR SDRAM是用提高有效带宽的很小的预取缓冲区的大小来划分的:DDR(2位)、DDR2(4位)和DDR(8位)。

   * **视频RAM(VRAM)**。它用在图形系统的帧缓冲区中。VRAM的思想与FPM DRAM类似。两个主要区别是:1)VRAM的输出是通过依次对内部缓冲区的整个内容进行移位得到的;2)VRAM允许对内存并行地读和写。因此，系统可以在写下一次更新的新值(写)的同时，用帧缓冲区中的像素刷屏幕(读)。

6. **非易失性存储器(ROM，Read-Only Memory)**：如果断电，DRAM和SRAM会丢失它们的信息，从这个意义上说，它们是易失的。另一方面，非易失性存储器即使是在关电后，仍然保存着它们的信息。现在有很多种非易失性存储器。由于历史原因，虽然ROM中有的类型既可以读也可以写，但是它们整体上都被称为只读存储器。ROM是以它们能够被重编程(写)的次数和对它们进行重编程所用的机制来区分的。

   * **可编程ROM(PROM)**。只能被编程一次，PROM的每个存储器单元有一种熔丝，只能用高电流熔断一次。

   * **可擦写可编程ROM(EPROM)**。有一个透明的石英窗口，允许光到达存储单元。紫外线光照射过窗口，EPROM单元就被清除为0。对EPROM编程是通过使用一种把1写入EPROM的特殊设备来完成的。EPROM能够被擦除和重编程的次数的数量级可以达到1000次。

   * **电子可擦除PROM(EEPROM)**。类似于EPROM，但是它不需要一个物理上独立的编程设备，因此可以直接在印制电路卡上编程。EEPROM 能够被编程的次数的数量级可以达到$10^5$次。

   * **闪存**。是一类非易失性存储器，基于EEPROM，它已经成为了一种重要的存储技术。闪存无处不在，为大量的电子设备提供快速而持久的非易失性存储，包括数码相机、手机、音乐播放器、PDA 和笔记本、台式机和服务器计算机系统。在6.1.3节中，我们会仔细研究一种新型的基于闪存的磁盘驱动器，称为固态硬盘(SSD)，它能提供相对于传统旋转磁盘的一种更快速、更强健和更低能耗的选择。

存储在ROM设备中的程序通常被称为**固件**。当一个计算机系统通电以后，它会运行存储在ROM中的固件。一些系统在固件中提供了少量基本的输入和输出函数，例如PC的BIOS(基本输入/输出系统)例程。复杂的设备，像图形卡和磁盘驱动控制器，也依赖固件翻译来自CPU的I/O(输入/输出)请求。

7. 访问主存

数据流通过称为总线(bus)的共享电子电路在处理器和DRAM主存之间来来回回。每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，这些步骤称为总线事务。读事务从主存传送数据到CPU。写事务从CPU传送数据到主存。

**总线**是一组并行的导线，能携带地址、数据和控制信号。取决于总线的设计，数据和地址信号可以共享同一组导线，也可以使用不同的。同时，两个以上的设备也能共享同一总线。控制线携带的信号会同步事务，并标识出当前正在被执行的事务的类型。

示例计算机系统的**配置**，主要部件是CPU芯片、我们将称为I/O桥接器的芯片组(其中包括内存控制器)，以及组成主存的DRAM内存模块。这些部件由一对总线连接起来，其中一条总线是系统总线，它连接CPU和I/O桥接器，另一条总线是内存总线，它连接I/О桥接器和主存。I/O桥接器将系统总线的电子信号翻译成内存总线的电子信号。I/O桥也将系统总线和内存总线连接到I/O总线，像磁盘和图形卡这样的I/О设备共享I/O总线。

**加载操作**`movq A, %rax`将地址A的内容加载到寄存器%rax中。CPU芯片上称为总线接口的电路在总线上发起读事务。读事务是由三个步骤组成的。首先，CPU将地址A放到系统总线上。I/O桥将信号传递到内存总线。接下来，主存接收到内存总线上的地址信号，从内存总线读地址，从 DRAM取出数据字，并将数据写到内存总线。I/O桥将内存总线信号翻译成系统总线信号，然后沿着系统总线传递。最后，CPU接收到系统总线上的数据，从总线上读数据，并将数据复制到寄存器%rax。

**存储操作**`movq %rax, A`将寄存器%rax的内容写到地址A。同样有三个基本步骤。首先，CPU将地址放到系统总线上。内存从内存总线读出地址，并等待数据到达。接下来，CPU将%rax中的数据字复制到系统总线。最后，主存从内存总线读出数据字，并且将这些位存储到DRAM中。

### 6.1.2 磁盘存储

磁盘是广为应用的保存大量数据的存储设备，存储数据的数量级可以达到几百到几千千兆字节，而基于RAM的存储器只能有几百或几千兆字节。不过，从磁盘上读信息的时间为毫秒级，比从 DRAM读慢了10万倍，比从SRAM读慢了100万倍。

1. 磁盘构造

磁盘是由盘片构成的。每个盘片有两面或者称为表面，表面覆盖着磁性记录材料。盘片中央有一个可以旋转的主轴，它使得盘片以固定的旋转速率旋转，通常是5400~15000转每分钟(RPM)。磁盘通常包含一个或多个这样的盘片，并封装在一个密封的容器内。

典型的**磁盘表面**是由一组称为磁道的同心圆组成的。每个磁道被划分为一组扇区。每个扇区包含相等数量的数据位(通常是512字节)，这些数据编码在扇区上的磁性材料中。扇区之间由一些间隙分隔开，这些间隙中不存储数据位。间隙存储用来标识扇区的格式化位。

**磁盘**是由一个或多个叠放在一起的盘片组成的，它们被封装在一个密封的包装里。整个装置通常被称为磁盘驱动器，我们通常简称为磁盘。有时，我们会称磁盘为旋转磁盘，以使之区别于基于闪存的固态硬盘(SSD)，SSD是没有移动部分的。

磁盘制造商通常用术语**柱面**来描述多个盘片驱动器的构造，这里，柱面是所有盘片表面上到主轴中心的距离相等的磁道的集合。例如，如果一个驱动器有三个盘片和六个面，每个表面上的磁道的编号都是一致的，那么柱面k就是6个磁道k的集合。

1. 磁盘容量

一个磁盘上可以记录的最大位数称为它的最大容量，或者简称为容量。磁盘容量是由以下技术因素决定的:

* 记录密度(位/英寸):磁道一英寸的段中可以放入的位数。

* 磁道密度(道/英寸):从盘片中心出发半径上一英寸的段内可以有的磁道数。

* 面密度(位/平方英寸):记录密度与磁道密度的乘积。

现代大容量磁盘使用一种称为**多区记录**的技术，在这种技术中，柱面的集合被分割成不相交的子集合，称为记录区。每个区包含一组连续的柱面。一个区中的每个柱面中的每条磁道都有相同数量的扇区，这个扇区的数量是由该区中最里面的磁道所能包含的扇区数确定的。

$1GB=10^9字节$，$1TB=10^{12}字节$

3. 磁盘操作

磁盘用读/写头来读写存储在磁性表面的位，而读写头连接到一个传动臂一端。通过沿着半径轴前后移动这个传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上。这样的机械运动称为**寻道**。一旦读/写头定位到了期望的磁道上，那么当磁道上的每个位通过它的下面时，读/写头可以感知到这个位的值(读该位)，也可以修改这个位的值(写该位)。有多个盘片的磁盘针对每个盘面都有一个独立的读/写头。读/写头垂直排列，一致行动。在任何时刻，所有的读/写头都位于同一个柱面上。

在传动臂末端的读/写头在磁盘表面高度大约0.1微米处的一层薄薄的气垫上飞翔(就是字面上这个意思)，速度大约为80 km/h。这可以比喻成将一座摩天大楼(442米高)放倒，然后让它在距离地面2.5cm(1英寸)的高度上环绕地球飞行，绕地球一圈只需要8秒钟!在这样小的间隙里，盘面上一粒微小的灰尘都像一块巨石。如果读/写头碰到了这样的一块巨石，读/写头会停下来，撞到盘面，所谓的**读/写头冲撞**。为此，磁盘总是密封包装的。

磁盘以扇区大小的块来读写数据。对扇区的访问时间有三个主要的部分:寻道时间(seek time)、旋转时间(rotational latency)和传送时间(transfer time):

* 寻道时间:为了读取某个目标扇区的内容，传动臂首先将读/写头定位到包含目标扇区的磁道上。移动传动臂所需的时间称为寻道时间。寻道时间$T_{seek}$依赖于读/写头以前的位置和传动臂在盘面上移动的速度。现代驱动器中平均寻道时间$T_{avg\ seek}$是通过对几千次对随机扇区的寻道求平均值来测量的，通常为3~9ms。一次寻道的最大时间$T_{max\ seek}$可以高达20ms。

* 旋转时间:一旦读/写头定位到了期望的磁道，驱动器等待目标扇区的第一个位旋转到读/写头下。这个步骤的性能依赖于当读/写头到达目标扇区时盘面的位置以及磁盘的旋转速度。在最坏的情况下，读/写头刚刚错过了目标扇区，必须等待磁盘转一整圈。因此,最大旋转延迟(以秒为单位)是$T_{max\ rotation}=\frac{1}{RPM}*\frac{60s}{1min}$平均旋转时间$T_{avg\ rotation}$是$T_{max\ rotation}$的一半。

* 传送时间:当目标扇区的第一个位位于读/写头下时，驱动器就可以开始读或者写该扇区的内容了。一个扇区的传送时间依赖于旋转速度和每条磁道的扇区数目。因此，我们可以粗略地估计一个扇区以秒为单位的平均传送时间如下$T_{avg\ transfer}=\frac{1}{RPM}*\frac{1}{平均扇区数/磁道}*\frac{60s}{1min}$。

我们可以估计访问一个磁盘扇区内容的**平均时间**为平均寻道时间、平均旋转延迟平均传送时间之和。

访问一个磁盘扇区中512个字节的时间主要是寻道时间和旋转延迟。访问扇区中的第一个字节用了很长时间，但是访问剩下的字节几乎不用时间。

因为寻道时间和旋转延迟大致相等，所以将寻道时间乘2是估计磁盘访问时间的简单而合理的方法。

对存储在SRAM中的一个64位字的访问时间大约是4ns，对 DRAM的访问时间是60ns。因此，从内存中读一个512个字节扇区大小的块的时间对SRAM来说大约是256ns，对 DRAM来说大约是4000ns。磁盘访问时间，大约10ms，是SRAM的大约40 000倍，是 DRAM的大约2500倍。

4. 逻辑磁盘块

现代磁盘构造复杂，有多个盘面，这些盘面上有不同的记录区。为了对操作系统隐藏这样的复杂性，现代磁盘将它们的构造呈现为一个简单的视图，一个B个扇区大小的逻辑块的序列，编号为0，1，…，B一1。磁盘封装中有一个小的硬件/固件设备，称为磁盘控制器，维护着逻辑块号和实际(物理)磁盘扇区之间的映射关系。

当操作系统想要**执行一个I/O操作**时，例如读一个磁盘扇区的数据到主存，操作系统会发送一个命令到磁盘控制器，让它读某个逻辑块号。控制器上的固件执行一个快速表查找，将一个逻辑块号翻译成一个(盘面，磁道，扇区)的三元组，这个三元组唯一地标识了对应的物理扇区。控制器上的硬件会解释这个三元组，将读/写头移动到适当的柱面，等待扇区移动到读/写头下，将读/写头感知到的位放到控制器上的一个小缓冲区中，然后将它们复制到主存中。

磁盘控制器必须对磁盘进行**格式化**，然后才能在该磁盘上存储数据。格式化包括用标识扇区的信息填写扇区之间的间隙，标识出表面有故障的柱面并且不使用它们，以及在每个区中预留出一组柱面作为备用，如果区中一个或多个柱面在磁盘使用过程中坏掉了，就可以使用这些备用的柱面。因为存在着这些备用的柱面，所以磁盘制造商所说的格式化容量比最大容量要小。

5. 连接I/O设备

例如图形卡、监视器、鼠标、键盘和磁盘这样的输入/输出(I/O)设备，都是通过I/O总线，例如Intel的外围设备互连(PCI)总线连接到CPU和主存的。I/O总线与I/O桥接器相连。系统总线和内存总线是与CPU相关的，与它们不同，诸如PCI这样的I/0总线设计成与底层CPU无关。例如，PC和Mac都可以使用PCI总线。一个典型的I/O总线结构连接了CPU、主存和I/О设备。虽然I/О总线比系统总线和内存总线慢，但是它可以容纳种类繁多的第三方I/O设备。

* 通用串行总线(USB)控制器是一个连接到USB总线的设备的中转机构，USB总线是一个广泛使用的标准，连接各种外围I/O设备，包括键盘、鼠标、调制解调器、数码相机、游戏操纵杆、打印机、外部磁盘驱动器和固态硬盘。USB 3.0总线的最大带宽为625MB/s。USB 3.1总线的最大带宽为1250MB/s。

* 图像卡(或适配器)包含硬件和软件逻辑，它们负责代表CPU在显示器上画像素。

* 主机总线适配器将一个或多个磁盘连接到I/O总线，使用的是一个特别的主机总线接口定义的通信协议。两个最常用的这样的磁盘接口是SCSI和SATA。SCSI磁盘通常比SATA驱动器更快但是也更贵。SCSI主机总线适配器(通常称为SCSI控制器)可以支持多个磁盘驱动器，SATA适配器只能支持一个驱动器。

* 其他的设备，例如网络适配器，可以通过将适配器插入到主板上空的扩展槽中，从而连接到I/O总线,这些插槽提供了到总线的直接电路连接。

6. 访问磁盘

CPU使用一种称为内存映射I/O的技术来向I/O设备发射命令。在使用内存映射I/O的系统中，地址空间中有一块地址是为与I/O设备通信保留的。每个这样的地址称为一个I/O端口。当一个设备连接到总线时，它与一个或多个端口相关联(或它被映射到一个或多个端口)。

来看一个简单的例子，假设磁盘控制器映射到端口0xa0。随后，CPU可能通过执行三个对地址0xa0的存储指令，发起磁盘读:第一条指令是发送一个命令字，告诉磁盘发起一个读，同时还发送了其他的参数，例如当读完成时，是否中断CPU(我们会在8.1节中讨论中断)。第二条指令指明应该读的逻辑块号。第三条指令指明应该存储磁盘扇区内容的主存地址。

当CPU发出了请求之后，在磁盘执行读的时候，它通常会做些其他的工作。一个1GHz的处理器时钟周期为1ns，在用来读磁盘的16ms时间里，它潜在地可能执行1600万条指令。在传输进行时，只是简单地等待，什么都不做是一种极大的浪费。

在磁盘控制器收到来自CPU的读命令之后，它将逻辑块号翻译成一个扇区地址，读该扇区的内容，然后将这些内容直接传送到主存，不需要CPU的干涉。设备可以自己执行读或者写总线事务而不需要CPU干涉的过程，称为直接内存访问(DMA)。这种数据传送称为**DMA传送**。

在DMA传送完成，磁盘扇区的内容被安全地存储在主存中以后，磁盘控制器通过给CPU发送一个中断信号来通知CPU。基本思想是中断会发信号到CPU芯片的一个外部引脚上。这会导致CPU暂停它当前正在做的工作，跳转到一个操作系统例程。这个程序会记录下I/O已经完成，然后将控制返回到CPU被中断的地方。

### 6.1.3 固态硬盘(SSD)

**固态硬盘(SSD)** 是一种基于闪存的存储技术，在某些情况下是传统旋转磁盘的极有吸引力的替代产品。SSD封装插到I/O总线上标准硬盘插槽(通常是USB或SATA)中，行为就和其他硬盘一样，处理来自CPU的读写逻辑磁盘块的请求。一个SSD封装由一个或多个闪存芯片和闪存翻译层组成，闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层是一个硬件/固件设备，扮演与磁盘控制器相同的角色，将对逻辑块的请求翻译成对底层物理设备的访问。

**读SSD比写要快**。随机读和写的性能差别是由底层闪存基本属性决定的。一个闪存由B个块的序列组成，每个块由Р页组成。通常，页的大小是512字节~4KB，块是由32~128页组成的，块的大小为16KB~512KB。数据是以页为单位读写的。只有在一页所属的块整个被擦除之后，才能写这一页(通常是指该块中的所有位都被设置为1)。不过，一旦一个块被擦除了，块中每一个页都可以不需要再进行擦除就写一次。在大约进行100 000次重复写之后，块就会磨损坏。一旦一个块磨损坏之后,就不能再使用了。

**随机写很慢**,有两个**原因**。首先，擦除块需要相对较长的时间,1ms级的，比访问页所需时间要高一个数量级。其次，如果写操作试图修改一个包含已经有数据(也就是不是全为1)的页p，那么这个块中所有带有用数据的页都必须被复制到一个新(擦除过的)块，然后才能进行对页p的写。制造商已经在闪存翻译层中实现了复杂的逻辑，试图抵消擦写块的高昂代价，最小化内部写的次数，但是随机写的性能不太可能和读一样好。

比起旋转磁盘，SSD有很多**优点**。它们由半导体存储器构成，没有移动的部件，因而随机访问时间比旋转磁盘要快，能耗更低，同时也更结实。不过，也有一些缺点。首先，因为反复写之后，闪存块会磨损，所以SSD也容易磨损。闪存翻译层中的平均磨损逻辑试图通过将擦除平均分布在所有的块上来最大化每个块的寿命。实际上，平均磨损逻辑处理得非常好，要很多年SSD才会磨损坏。其次，SSD每字节比旋转磁盘贵,因此常用的存储容量比旋转磁盘小.

### 6.1.4 存储技术趋势

不同的存储技术有不同的价格和性能折中。速度：SRAM > DRAM > SSD > 磁盘。每字节造价：SRAM > DRAM > SSD > 磁盘。

不同存储技术的价格和性能属性以截然不同的速率变化着。增加密度从而降低成本比降低访问时间容易的多。

DRAM和磁盘的性能滞后于CPU的性能。现代计算机频繁地使用基于SRAM的高速缓存，试图弥补处理器与内存之间的差距。这种方法行之有效是因为应用程序的一个称为局部性(locality)的基本属性。

## 6.2 局部性

一个编写良好的计算机程序常常具有良好的局部性。也就是，它们倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。这种倾向性，被称为**局部性原理**，是一个持久的概念，对硬件和软件系统的设计和性能都有着极大的影响。

局部性通常有两种不同的形式:**时间局部性和空间局部性**。在一个具有良好时间局部性的程序中，被引用过一次的内存位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个内存位置被引用了一次,那么程序很可能在不远的将来引用附近的一个内存位置。

一般而言，**有良好局部性的程序比局部性差的程序运行得更快**。现代计算机系统的各个层次，从硬件到操作系统、再到应用程序，它们的设计都利用了局部性。在硬件层，局部性原理允许计算机设计者通过引入称为高速缓存存储器的小而快速的存储器来保存最近被引用的指令和数据项，从而提高对主存的访问速度。在操作系统级，局部性原理允许系统使用主存作为虚拟地址空间最近被引用块的高速缓存。类似地，操作系统用主存来缓存磁盘文件系统中最近被使用的磁盘块。局部性原理在应用程序的设计中也扮演着重要的角色。例如，Web浏览器将最近被引用的文档放在本地磁盘上，利用的就是时间局部性。大容量的Web服务器将最近被请求的文档放在前端磁盘高速缓存中，这些缓存能满足对这些文档的请求，而不需要服务器的任何干预。

### 6.2.1 对程序数据引用的局部性

顺序访问一个向量每个元素的函数，具有步长为1的引用模式(相对于元素的大小)。有时我们称步长为1的引用模式为顺序引用模式。一个连续向量中，每隔k个元素进行访问，就称为步长为k的引用模式。步长为1的引用模式是程序中空间局部性常见和重要的来源。一般而言，随着步长的增加，空间局部性下降。

### 6.2.2 取指令的局部性

因为程序指令是存放在内存中的，CPU必须取出(读出)这些指令，所以我们也能够评价一个程序关于取指令的局部性。代码区别于程序数据的一个重要属性是在运行时它是不能被修改的。当程序正在执行时，CPU 只从内存中读出它的指令。CPU很少会重写或修改这些指令。

### 6.2.3 局部性小结

重复引用相同变量的程序有良好的时间局部性。

对于具有步长为k的引用模式的程序，步长越小，空间局部性越好。具有步长为1的引用模式的程序有很好的空间局部性。在内存中以大步长跳来跳去的程序空间局部性会很差。

对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。

## 6.3 存储器层次结构

**存储技术**:不同存储技术的访问时间差异很大。速度较快的技术每字节的成本要比速度较慢的技术高，而且容量较小。CPU和主存之间的速度差距在增大。

**计算机软件**:一个编写良好的程序倾向于展示出良好的局部性。

**存储器层次结构**：主要思想是上一层的存储器作为低一层的存储器的高速缓存

L0：寄存器→→→L1：L1高速缓存(SRAM)→→→L2：L2高速缓存(SRAM)→→→L3：L3高速缓存(SRAM)→→→L4：主存(DRAM)→→→L5：本地二级存储(本地磁盘)→→→L6：远程二级存储(分布式文件系统，Web服务器)

**存储器层次结构**，从高层往底层走，存储设备变得更慢、更便宜和更大。在最高层(L0)，是少量快速的CPU寄存器，CPU可以在一个时钟周期内访问它们。接下来是一个或多个小型到中型的基于SRAM的高速缓存存储器，可以在几个CPU时钟周期内访问它们。然后是一个大的基于DRAM的主存，可以在几十到几百个时钟周期内访问它们。接下来是慢速但是容量很大的本地磁盘。最后，有些系统甚至包括了一层附加的远程服务器上的磁盘，要通过网络来访问它们。像安德鲁文件系统(AFS)或者网络文件系统(NFS)这样的分布式文件系统，允许程序访问存储在远程的网络服务器上的文件。万维网允许程序访问存储在世界上任何地方的Web服务器上的远程文件。

### 6.3.1 存储器层次结构中的缓存

一般而言，高速缓存(cache)是一个小而快速的存储设备，它作为存储在更大、也更慢的设备中的数据对象的缓冲区域。使用高速缓存的过程称为**缓存**。

**存储器层次结构的中心思想**是，对于每个k，位于k层的更快更小的存储设备作为位于k+1层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层的数据对象。例如，本地磁盘作为通过网络从远程磁盘取出的文件的缓存，主存作为本地磁盘上数据的缓存,依此类推,直到最小的缓存CPU寄存器组。

存储器层次结构中缓存的**一般性概念**，第k+1层的存储器被划分成连续的数据对象组块，称为块。每个块都有一个唯一的地址或名字，使之区别于其他的块。块可以是固定大小的(通常是这样的)，也可以是可变大小的(例如存储在Web服务器上的远程HTML文件)。

类似地，第k层的存储器被划分成较少的块的集合，每个块的大小与k＋1层的块的大小一样。在任何时刻，第k层的缓存包含第k+1层块的一个子集的副本。

数据总是以块大小为传送单元在第k层和第k＋1层之间来回复制的。虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以有不同的块大小。Ll和L0之间的传送通常使用的是1个字大小的块。L2和L1之间(以及L3和L2之间、L4和I3之间)的传送通常使用的是几十个字节的块。而L5和L4之间的传送用的是大小为几百或几千字节的块。一般而言，层次结构中较低层(离CPU较远)的设备的访问时间较长，因此为了补偿这些较长的访问时间，倾向于使用较大的块。

1. 缓存命中

当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。如果d刚好缓存在第k层中，那么就是我们所说的缓存命中。该程序直接从第k层读取d，根据存储器层次结构的性质，这要比从第k＋1层读取d更快。

2. 缓存不命中

另一方面，如果第k层中没有缓存数据对象d，那么就是我们所说的缓存不命中。当发生缓存不命中时，第k层的缓存从第k＋1层缓存中取出包含d的那个块，如果第k层的缓存已经满了，可能就会覆盖现存的一个块。

覆盖一个现存的块的过程称为**替换或驱逐这个块**。被驱逐的这个块有时也称为牺牲块。决定该替换哪个块是由缓存的替换策略来控制的。例如，一个具有随机替换策略的缓存会随机选择一个牺牲块。一个具有最近最少被使用(LRU)替换策略的缓存会选择那个最后被访问的时间距现在最远的块。

在第k层缓存从第k+1层取出那个块之后，程序就能像前面一样从第k层读出d了。例如，在第k层中读块12中的一个数据对象，会导致一个缓存不命中，因为块12当前不在第k层缓存中。一旦把块12从第k＋1层复制到第k层之后，它就会保持在那里，等待稍后的访问。

3. 缓存不命中的种类

区分不同种类的缓存不命中有时候是很有帮助的。如果第k层的缓存是空的，那么对任何数据对象的访问都会不命中。一个空的缓存有时被称为冷缓存，此类不命中称为**强制性不命中或冷不命中**。冷不命中很重要，因为它们通常是短暂的事件，不会在反复访问存储器使得缓存暖身之后的稳定状态中出现。

只要发生了不命中，第k层的缓存就必须执行某个放置策略，确定把它从第k+1层中取出的块放在哪里。最灵活的替换策略是允许来自第k＋1层的任何块放在第k层的任何块中。对于存储器层次结构中高层的缓存(靠近CPU)，它们是用硬件来实现的，而且速度是最优的，这个策略实现起来通常很昂贵，因为随机地放置块，定位起来代价很高。

因此，硬件缓存通常使用的是更严格的放置策略，这个策略将第k+1层的某个块限制放置在第k层块的一个小的子集中(有时只是一个块)。

这种限制性的放置策略会引起一种不命中，称为**冲突不命中**，在这种情况中，缓存足够大，能够保存被引用的数据对象，但是因为这些对象会映射到同一个缓存块，缓存会一直不命中。

程序通常是按照一系列阶段(如循环)来运行的，每个阶段访问缓存块的某个相对稳定不变的集合。例如，一个嵌套的循环可能会反复地访问同一个数组的元素。这个块的集合称为这个阶段的工作集。当工作集的大小超过缓存的大小时，缓存会经历容量不命中。换句话说就是，缓存太小了，不能处理这个工作集。

4. 缓存管理

正如我们提到过的，存储器层次结构的本质是，每一层存储设备都是较低一层的缓存。在每一层上，某种形式的逻辑必须管理缓存。这里，我们的意思是指某个东西要将缓存划分成块，在不同的层之间传送块，判定是命中还是不命中，并处理它们。管理缓存的逻辑可以是硬件、软件，或是两者的结合。

例如，编译器管理寄存器文件，缓存层次结构的最高层。它决定当发生不命中时何时发射加载，以及确定哪个寄存器来存放数据。L1、L2和L3层的缓存完全是由内置在缓存中的硬件逻辑来管理的。在一个有虚拟内存的系统中，DRAM主存作为存储在磁盘上的数据块的缓存，是由操作系统软件和CPU上的地址翻译硬件共同管理的。对于一个具有像AFS这样的分布式文件系统的机器来说，本地磁盘作为缓存，它是由运行在本地机器上的AFS客户端进程管理的。在大多数时候，缓存都是自动运行的，不需要程序采取特殊的或显式的行动。

### 6.3.2 存储器层次结构概念小结

概括来说，基于缓存的存储器层次结构行之有效，是因为较慢的存储设备比较快的存储设备更便宜,还因为程序倾向于展示局部性:

利用时间局部性:由于时间局部性，同一数据对象可能会被多次使用。一旦一个数据对象在第一次不命中时被复制到缓存中，我们就会期望后面对该目标有一系列的访问命中。因为缓存比低一层的存储设备更快，对后面的命中的服务会比最开始的不命中快很多。

利用空间局部性:块通常包含有多个数据对象。由于空间局部性，我们会期望后面对该块中其他对象的访问能够补偿不命中后复制该块的花费

|类型|缓存内容|被缓存在何处|延迟(周期数)|由谁管理|
|:-:|:-:|:-:|:-:|:-:|
|CPU寄存器|4字节或8字节字|芯片上的CPU寄存器|0|编译器|
|TLB(翻译后备缓冲器)|地址翻译|芯片上的TLB|0|硬件MMU(内存管理单元)|
|L1高速缓存|64字节块|芯片上的L1高速缓存|4|硬件|
|L2高速缓存|64字节块|芯片上的L2高速缓存|10|硬件|
|L3高速缓存|64字节块|芯片上的L3高速缓存|50|硬件|
|虚拟内存|4KB页|主存|200|硬件+OS(操作系统)|
|缓冲区缓存|部分文件|主存|200|OS|
|磁盘缓存|磁盘扇区|磁盘控制器|10W|控制器固件|
|网络缓存|部分文件|本地磁盘|1KW|NFS(网络文件系统)客户|
|浏览器缓存|Web页|本地磁盘|1KW|Web浏览器|
|Web缓存|Web页|远程服务器磁盘|10E|Web代理服务器|

## 6.4 高速缓存存储器

早期计算机系统的存储器层次结构只有三层:CPU寄存器、DRAM主存储器和磁盘存储。不过，由于CPU和主存之间逐渐增大的差距，系统设计者被迫在CPU寄存器文件和主存之间插入了一个小的SRAM高速缓存存储器，称为Ll高速缓存(一级缓存)。Ll高速缓存的访问速度几乎和寄存器一样快，典型地是大约4个时钟周期。

随着CPU和主存之间的性能差距不断增大，系统设计者在Ll高速缓存和主存之间又插入了一个更大的高速缓存，称为L2高速缓存，可以在大约10个时钟周期内访问到它。有些现代系统还包括有一个更大的高速缓存，称为L3高速缓存，在存储器层次结构中，它位于L2高速缓存和主存之间，可以在大约50个周期内访问到它。虽然安排上有相当多的变化，但是通用原则是一样的。

### 6.4.1 通用的高速缓存存储器组织结构

计算机系统中每个存储器地址有m位，形成$M=2^m$个不同的地址。这样一个机器的高速缓存被组织成一个有$S=2^s$个高速缓存组的数组。每个组包含E个高速缓存行。每个行是由一个B=2字节的数据块(block)组成的，一个有效位指明这个行是否包含有意义的信息，还有t=m-(b+s)个标记位(是当前块的内存地址的位的一个子集)，它们唯一地标识存储在这个高速缓存行中的块。

一般而言，高速缓存的结构可以用元组(S，E，B，m)来描述。高速缓存的大小(或容量)C指的是所有块的大小的和。标记位和有效位不包括在内。因此，C=S\*E\*B。

当一条**加载**指令指示CPU从主存地址A中读一个字时，它将地址A发送到高速缓存。如果高速缓存正保存着地址A处那个字的副本，它就立即将那个字发回给CPU。高速缓存的结构使得它能通过简单地检查地址位，找到所请求的字，类似于使用极其简单的哈希函数的哈希表。

参数S和B将m个地址位分为了三个字段。A中s个组索引位是一个到S个组的数组的索引。第一个组是组0，第二个组是组1，依此类推。组索引位被解释为一个无符号整数，它告诉我们这个字必须存储在哪个组中。一旦我们知道了这个字必须放在哪个组中，A中的t个标记位就告诉我们这个组中的哪一行包含这个字(如果有的话)。当且仅当设置了有效位并且该行的标记位与地址A中的标记位相匹配时，组中的这一行才包含这个字。一旦我们在由组索引标识的组中定位了由标号所标识的行，那么b个块偏移位给出了在B个字节的数据块中的字偏移。

|基本参数|描述|
|:-:|:-:|
|$S=2^s$|组数|
|E|每个组的行数|
|$B=2^b$|块大小(字节)|
|m=log_2(M)|(主存)物理地址位数|

|衍生参数|描述|
|:-:|:-:|
|$M=2^m$|内存地址的最大数量|
|$s=log_2(S)$|组索引位数量|
|$b=log_2(B)$|块偏移位数量|
|t=m-(s+b)|标记位数量|
|C=B\*E\*S|不包括像有效位和标记位这样开销的高速缓存大小(字节)|

### 6.4.2 直接映射高速缓存

根据每个组的高速缓存行数E，高速缓存被分为不同的类。每个组只有一行(E=1)的高速缓存称为直接映射高速缓存。直接映射高速缓存是最容易实现和理解的，所以我们会以它为例来说明一些高速缓存工作方式的通用概念。

假设我们有这样一个系统，它有一个CPU、一个寄存器文件、一个Ll高速缓存和一个主存。当CPU执行一条读内存字w的指令，它向Ll高速缓存请求这个字。如果L1高速缓存有w的一个缓存的副本，那么就得到L1高速缓存命中，高速缓存会很快抽取出W，并将它返回给CPU。否则就是缓存不命中，当L1高速缓存向主存请求包含w的块的一个副本时，CPU必须等待。当被请求的块最终从内存到达时，Ll高速缓存将这个块存放在它的一个高速缓存行里，从被存储的块中抽取出字w，然后将它返回给CPU。高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程，分为三步:1）组选择;2)行匹配;3）字抽取。

1. 直接映射高速缓存中的组选则

在这一步中，高速缓存从w的地址中间抽取出s个组索引位。这些位被解释成一个对应于一个组号的无符号整数。换句话来说，如果我们把高速缓存看成是一个关于组的一维数组，那么这些组索引位就是一个到这个数组的索引。

2. 直接映射高速缓存中的行匹配

在上一步中我们已经选择了某个组i，接下来的一步就要确定是否有字w的一个副本存储在组i包含的一个高速缓存行中。在直接映射高速缓存中这很容易，而且很快，这是因为每个组只有一行。当且仅当设置了有效位，而且高速缓存行中的标记与w的地址中的标记相匹配时,这一行中包含w的一个副本。

直接映射高速缓存中行匹配的工作方式，选中的组中只有一个高速缓存行。这个行的有效位设置了，所以我们知道标记和块中的位是有意义的。因为这个高速缓存行中的标记位与地址中的标记位相匹配，所以我们知道我们想要的那个字的一个副本确实存储在这个行中。换句话说，我们得到一个缓存命中。另一方面，如果有效位没有设置，或者标记不相匹配，那么我们就得到一个缓存不命中。

3. 直接映射高速缓存中的字选择

一旦命中，我们知道w就在这个块中的某个地方。最后一步确定所需要的字在块中是从哪里开始的。块偏移位提供了所需要的字的第一个字节的偏移。就像我们把高速缓存看成一个行的数组一样，我们把块看成一个字节的数组，而字节偏移是到这个数组的一个索引。

4. 直接映射高速缓存中不命中时的行替换

如果缓存不命中，那么它需要从存储器层次结构中的下一层取出被请求的块，然后将新的块存储在组索引位指示的组中的一个高速缓存行中。一般而言，如果组中都是有效高速缓存行了，那么必须要驱逐出一个现存的行。对于直接映射高速缓存来说，每个组只包含有一行，替换策略非常简单:用新取出的行替换当前的行。

5. 综合：运行中的直接映射高速缓存

标记位和索引位连起来唯一地标识了内存中的每个块。内存块过于高速缓存组时，多个块会映射到同一个高速缓存组(既它们有相同的组索引)。映射到用一个高速缓存组的块由标记位唯一地标识。

6. 直接映射高速缓存中的冲突不命中

冲突不命中在真实的程序中很常见，会导致令人困惑的性能问题。当程序访问大小为2的幂的数组时，直接映射高速缓存中通常会发生冲突不命中。

术语**抖动**描述高速缓存反复地加载和驱逐相同的高速缓存块的组。简要来说就是，即使程序有良好的空间局部性，而且高速缓存中也有足够得到空间来存放块，每次引用还是会导致冲突不命中，这是因为这些块被映射到了同一个高速缓存组。

一个修正抖动的简单方法是在大小为2的幂的数组结尾放B字节的填充。

### 6.4.3 组相联高速缓存

直接映射高速缓存中冲突不命中造成的问题源于每个组只有一行(或者，按照我们的术语来描述就是E=1)这个限制。组相联高速缓存放松了这条限制,所以每个组都保存有多于一个的高速缓存行。一个1\<E\<C/B的高速缓存通常称为E路组相联高速缓存。在下一节中，我们会讨论E=C/B这种特殊情况。

1. 组相联高速缓存中的组选择

它的组选择与直接映射高速缓存的组选择一样，组索引位标识组。

2. 组相联高速缓存中的行匹配和字选择

组相联高速缓存中的行匹配比直接映射高速缓存中的更复杂，因为它必须检查多个行的标记位和有效位，以确定所请求的字是否在集合中。传统的内存是一个值的数组，以地址作为输入，并返回存储在那个地址的值。另一方面，相联存储器是一个(key，value)对的数组，以key为输入，返回与输入的key相匹配的(key，value)对中的 value值。因此，我们可以把组相联高速缓存中的每个组都看成一个小的相联存储器，key是标记和有效位，而value就是块的内容。

组相联高速缓存行匹配的一个重要思想就是组中的任何一行都可以包含任何映射到这个组的内存块。所以高速缓存必须搜索组中的每一行，寻找一个有效的行，其标记与地址中的标记相匹配。如果高速缓存找到了这样一行，那么我们就命中，块偏移从这个块中选择一个字，和前面一样。

有效位设置且高速缓存行中某一行的标记位匹配地址中的标记位，则高速缓存命中，然后块偏移选择起始字节。

3. 组相联高速缓存中不命中时的行替换

如果CPU请求的字不在组的任何一行中，那么就是缓存不命中，高速缓存必须从内存中取出包含这个字的块。不过，一旦高速缓存取出了这个块，该替换哪个行呢?当然，如果有一个空行，那它就是个很好的候选。但是如果该组中没有空行，那么我们必须从中选择一个非空的行,希望CPU不会很快引用这个被替换的行。

最简单的替换策略是随机选择要替换的行。其他更复杂的策略利用了局部性原理，以使在比较近的将来引用被替换的行的概率最小。例如，最不常使用(LFU)策略会替换在过去某个时间窗口内引用次数最少的那一行。最近最少使用(LRU)策略会替换最后一次访问时间最久远的那一行。所有这些策略都需要额外的时间和硬件。但是，越往存储器层次结构下面走，远离CPU，一次不命中的开销就会更加昂贵，用更好的替换策略使得不命中最少也变得更加值得了。

### 6.4.4 全相联高速缓存

全相联高速缓存是由一个包含所有高速缓存行的组(即E=C/B)组成的。

1. 全相联高速缓存中的组选择

全相联高速缓存中的组选择非常简单，因为只有一个组,注意地址中没有组索引位，地址只被划分成了一个标记和一个块偏移。

2. 全相联高速缓存中的行匹配和字选择

全相联高速缓存中的行匹配和字选择与组相联高速缓存中的是一样的，它们之间的区别主要是规模大小的问题。

因为高速缓存电路必须并行地搜索许多相匹配的标记，构造一个又大又快的相联高速缓存很困难，而且很昂贵。因此，全相联高速缓存只适合做小的高速缓存，例如虚拟内存系统中的翻译备用缓冲器(TLB)，它缓存页表项(见9.6.2节)。

### 6.4.5 有关写的问题

高速缓存关于读的操作非常简单。首先，在高速缓存中查找所需字w的副本。如果命中，立即返回字w给CPU。如果不命中，从存储器层次结构中较低层中取出包含字w的块，将这个块存储到某个高速缓存行中(可能会驱逐一个有效的行)，然后返回字w。

写的情况就要复杂一些了。假设我们要写一个已经缓存了的字w(写命中)。在高速缓存更新了它的w的副本之后，怎么更新w在层次结构中紧接着低一层中的副本呢?最简单的方法，称为**直写**，就是立即将w的高速缓存块写回到紧接着的低一层中。虽然简单，但是**直写的缺点**是每次写都会引起总线流量。另一种方法，称为**写回**，尽可能地推迟更新，只有当替换算法要驱逐这个更新过的块时，才把它写到紧接着的低一层中。由于局部性，写回能显著地减少总线流量，但是它的**缺点**是增加了复杂性。高速缓存必须为每个高速缓存行维护一个额外的修改位，表明这个高速缓存块是否被修改过。

另一个问题是如何处理**写不命中**。一种方法，称为**写分配**，加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。写分配试图利用写的空间局部性，但是**缺点**是每次不命中都会导致一个块从低一层传送到高速缓存。另一种方法，称为**非写分配**，避开高速缓存，直接把这个字写到低一层中。直写高速缓存通常是非写分配的。写回高速缓存通常是写分配的。

对于试图编写高速缓存比较友好的程序的程序员来说，我们建议**在心里采用一个使用写回和写分配的高速缓存的模型**。这样建议有几个原因。通常，由于较长的传送时间，存储器层次结构中较低层的缓存更可能使用写回，而不是直写。例如，虚拟内存系统(用主存作为存储在磁盘上的块的缓存)只使用写回。但是由于逻辑电路密度的提高，写回的高复杂性也越来越不成为阻碍了，我们在现代系统的所有层次上都能看到写回缓存。所以这种假设符合当前的趋势。假设使用写回写分配方法的另一个原因是，它与处理读的方式相对称，因为写回写分配试图利用局部性。因此，我们可以在高层次上开发我们的程序，展示良好的空间和时间局部性，而不是试图为某一个存储器系统进行优化。

### 6.4.6 一个真实的高速缓存层次结构的解剖

高速缓存既保存数据，也保存指令。只保存指令的高速缓存称为i-cache。只保存程序数据的高速缓存称为d-cache。既保存指令又包括数据的高速缓存称为统一的高速缓存(unified cache)。现代处理器包括独立的i-cache和d-cache。这样做有很多原因。有两个独立的高速缓存，处理器能够同时读一个指令字和一个数据字。i-cache通常是只读的，因此比较简单。通常会针对不同的访问模式来优化这两个高速缓存，它们可以有不同的块大小，相联度和容量。使用不同的高速缓存也确保了数据访问不会与指令访问形成冲突不命中，反过来也是一样，代价就是可能会引起容量不命中增加。

### 6.4.7 高速缓存参数的性能影响

**不命中率**。在一个程序执行或程序的一部分执行期间，内存引用不命中的比率。它是这样计算的:不命中数量/引用数量。

**命中率**。命中的内存引用比率。它等于1-不命中率。

**命中时间**。从高速缓存传送一个字到CPU所需的时间，包括组选择、行确认和字选择的时间。对于L1高速缓存来说，命中时间的数量级是几个时钟周期。

**不命中处罚**。由于不命中所需要的额外的时间。Ll不命中需要从L2得到服务的处罚,通常是数10个周期；从L3得到服务的处罚，50个周期；从主存得到的服务的处罚，200个周期。

**优化高速缓存的成本和性能的折中**是一项很精细的工作，它需要在现实的基准程序代码上进行大量的模拟，因此超出了我们讨论的范围。不过，还是可以认识一些定性的折中考量的。

1. 高速缓存大小的影响

一方面，较大的高速缓存可能会提高命中率。另一方面，使大存储器运行得更快总是要难一些的。结果，较大的高速缓存可能会增加命中时间。这解释了为什么Ll高速缓存比L2高速缓存小，以及为什么L2高速缓存比L3高速缓存小。

2. 块大小的影响

大的块有利有弊。一方面，较大的块能利用程序中可能存在的空间局部性，帮助提高命中率。不过，对于给定的高速缓存大小，块越大就意味着高速缓存行数越少，这会损害时间局部性比空间局部性更好的程序中的命中率。较大的块对不命中处罚也有负面影响，因为块越大，传送时间就越长。现代系统(如Core i7)会折中使高速缓存块包含64个字节。

3. 相联度的影响

这里的问题是参数E选择的影响，E是每个组中高速缓存行数。较高的相联度(也就是E的值较大)的优点是降低了高速缓存由于冲突不命中出现抖动的可能性。不过，较高的相联度会造成较高的成本。较高的相联度实现起来很昂贵，而且很难使之速度变快。每一行需要更多的标记位，每一行需要额外的LRU状态位和额外的控制逻辑。较高的相联度会增加命中时间，因为复杂性增加了，另外，还会增加不命中处罚，因为选择牺牲行的复杂性也增加了

相联度的选择最终变成了命中时间和不命中处罚之间的折中。传统上，努力争取时钟频率的高性能系统会为L1高速缓存选择较低的相联度(这里的不命中处罚只是几个周期)，而在不命中处罚比较高的较低层上使用比较小的相联度。例如，Intel Core i7系统中，Ll和L2高速缓存是8路组相联的，而L3高速缓存是16路组相联的。

4. 写策略的影响

直写高速缓存比较容易实现，而且能使用独立于高速缓存的写缓冲区,用来更新内存。此外，读不命中开销没这么大，因为它们不会触发内存写。另一方面，写回高速缓存引起的传送比较少，它允许更多的到内存的带宽用于执行DMA的I/O设备。此外，越往层次结构下面走，传送时间增加，减少传送的数量就变得更加重要。一般而言,高速缓存越往下层，越可能使用写回而不是直写。

**高速缓存块、行和组的区别**：

块是一个固定大小的信息包，在高速缓存和主存(或下一层高速缓存)之间来回传送。行是高速缓存中的一个容器，存储块以及其他信息(例如有效位和标记位)。组是一个或多个行的集合。直接映射高速缓存中的组只由一行组成。组相联和全相联高速缓存中的组是由多个行组成的。

在直接映射高速缓存中，组和行实际上是等价的。不过，在相联高速缓存中，组和行是很不一样的，这两个词不能互换使用。

因为一行总是存储一个块，术语“行”和“块”通常互换使用。例如，系统专家总是说高速缓存的“行大小”，实际上他们指的是块大小。

## 6.5 编写高速缓存友好的代码

局部性比较好的程序更容易有较低的不命中率，而不命中率较低的程序往往比不命中率较高的程序运行得更快。因此，从具有良好局部性的意义上来说，应该试着去编写高速缓存友好的代码。下面就是我们用来**确保代码高速缓存友好的基本方法**。

1)让最常见的情况运行得快。程序通常把大部分时间都花在少量的核心函数上，而这些函数通常把大部分时间都花在了少量循环上。所以要把注意力集中在核心函数里的循环上，而忽略其他部分。

2)尽量减小每个循环内部的缓存不命中数量。在其他条件(例如加载和存储的总次数)相同的情况下,不命中率较低的循环运行得更快。

对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中(时间局部性)。

步长为1的引用模式是好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块(空间局部性)。

在对多维数组记性操作的程序中，空间局部性尤其重要。由于C语言以行优先顺序存储数组，所以按照行优先顺序对一个二维数组进行遍历即为步长为1的访问模式。

## 6.6 综合：高速缓存对程序性能的影响

### 6.6.1 存储器山

一个程序从存储系统中读数据的速率称为**读吞吐量**，或者有时称为读带宽。如果一个程序在s秒的时间段内读n个字节，那么这段时间内的读吞吐量就等于n/s，通常以兆字节每秒(MB/s)为单位。

**存储器山**：读带宽的关于时间和空间局部性的二维函数。

即使是当程序的时间局部性很差时，空间局部性仍然能补救，并且是非常重要的。

Core i7存储器系统中有硬件预取机制，它会自动地识别顺序的、步长为1的引用模式，师徒在一些块被访问之前，将它们取到高速缓存中。即使工作集超出了L1和L2的大小，读吞吐量相对保持不变。这个算法对小步长效果最好。

存储器系统的性能不是一个数字就能描述的。相反，它是一座时间和空间局部性的山，这座山的上升高度差别可以超过一个数量级。明智的程序员会试图构造他们的程序，使得程序运行在山峰而不是低谷。目标就是利用时间同部性，使得频繁使用的字从L1中取出，还要利用空间局部性，使得尽可能多的字从一个L1高速缓存行中访问到。

### 6.6.2 重新排列循环以提高空间局部性

计算矩阵乘法C=A*B时，以下遍历顺序计算速度最佳。
```C
for (i = 0; i < n i++)
	for (k = 0; k < n; k++) {
		r = A[i][k];
			for (j = 0; j < n; j++)
				C[i][j] += A[i][k] * r;
	}
```

使用分块来提高时间局部性

称为分块可以提高内循环的时间局部性。分块的大致思想是将一个程序中的数据结构组织成的大的片，称为块(在这个上下文中，“块”指的是一个应用级的数据组块，而不是高速缓存块)。这样构造程序，使得能够将一个片加载到L1高速缓存中，并在这个片中进行所需的所有的读和写，然后丢掉这个片，加载下一个片，依此类推。

与为提高空间局部性所做的简单循环变换不同，分块使得代码更难阅读和理解。由于这个原因，它最适合于优化编译器或者频繁执行的库函数。由于Core i7有完善的预取硬件，分块不会提高矩阵乘在Core i7上的性能。不过，学习和理解这项技术还是很有趣的，因为它是一个通用的概念，可以在一些没有预取的系统上获得极大的性能收益。

### 6.6.3 在程序中利用局部性

存储系统被组织成一-个存储设备的层次结构，较小、较快的设备靠近顶部，较大、较慢的设备靠近底部。由于采用了这种层次结构，程序访问存储位置的实际速率不是一个数字能描述的。相反，它是一个变化很大的程序局部性的函数(我们称之为存储器山)，变化可以有几个数量级。有良好局部性的程序从快速的高速缓存存储器中访问它的大部分数据。局部性差的程序从相对慢速的DRAM主存中访问它的大部分数据。

理解存储器层次结构本质能够利用这些知识编写出更有效的程序，无论具体的存储系统结构是怎样的。特别地，我们推荐下列技术:

* 将你的注意力集中在内循环上，大部分计算和内存访问都发生在这里。

* 通过按照数据对象存储在内存中的顺序、以步长为1的来读数据，从而使得你程序中的空间局部性最大。

* 一旦从存诸器中读入了一个数据对象，就尽可能多地使用它，从而使得程序中的时间局部性最大。

## 6.7 小结

基本存储技术包括随机存储器(RAM)、非易失性存储器(ROM)和磁盘。RAM有两种基本类型。静态RAM(SRAM)快一些，但是也贵一些，它既可以用做CPU芯片上的高速缓存，也可以用做芯片下的高速缓存。动态RAM(DRAM)慢一点，也便宜一些，用做主存和图形帧缓冲区。即使是在关电的时候，ROM也能保持它们的信息，可以用来存储固件。旋转磁盘是机械的非易失性存储设备，以每个位很低的成本保存大量的数据，但是其访问时间比DRAM长得多。固态硬盘(SSD)基于非易失性的闪存，对某些应用来说，越来越成为旋转磁盘的具有吸引力的替代产品。

一般而言，较快的存储技术每个位会更贵，而且容量更小。这些技术的价格和性能属性正在以显著不同的速度变化着。特别地，DRAM和磁盘访问时间远远大于CPU周期时间。系统通过将存储器组织成存储设备的层次结构来弥补这些差异，在这个层次结构中，较小、较快的设备在顶部，较大、较慢的设备在底部。因为编写良好的程序有好的局部性，大多数数据都可以从较高层得到服务，结果就是存储系统能以较高层的速度运行，但却有较低层的成本和容量。

程序员可以通过编写有良好空间和时间局部性的程序来显著地改进程序的运行时间。利用基于SRAM的高速缓存存储器特别重要。主要从高速缓存取数据的程序能比主要从内存取数据的程序运行得快得多。
