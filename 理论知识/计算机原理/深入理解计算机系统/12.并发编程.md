- [并发编程](#并发编程)
	- [12.1 基于进程的并发编程](#121-基于进程的并发编程)
		- [12.1.1 基于进程的并发服务器](#1211-基于进程的并发服务器)
		- [12.1.2 进程的优劣](#1212-进程的优劣)
	- [12.2 基于I/O多路复用的并发编程](#122-基于io多路复用的并发编程)
		- [12.2.1 基于I/O多路复用的并发事件驱动服务器](#1221-基于io多路复用的并发事件驱动服务器)
		- [12.2.2 I/O多路复用技术的优劣](#1222-io多路复用技术的优劣)
	- [12.3 基于线程的并发编程](#123-基于线程的并发编程)
		- [12.3.1 线程执行模型](#1231-线程执行模型)
		- [12.3.6 分离线程](#1236-分离线程)
	- [12.4 多线程程序中的共享变量](#124-多线程程序中的共享变量)
		- [12.4.1 线程内存模型](#1241-线程内存模型)
		- [12.4.2 将变量映射到内存](#1242-将变量映射到内存)
		- [12.4.3 共享变量](#1243-共享变量)
	- [12.5 用信号量同步线程](#125-用信号量同步线程)
		- [12.5.1 进度图](#1251-进度图)
		- [12.5.2 信号量](#1252-信号量)
		- [12.5.3 使用信号量来实现互斥](#1253-使用信号量来实现互斥)
		- [12.5.4 利用信号量来调度共享资源](#1254-利用信号量来调度共享资源)
		- [12.5.5 综合：基于预线程化的并发服务器](#1255-综合基于预线程化的并发服务器)
	- [12.6 使用线程提高并行性](#126-使用线程提高并行性)
	- [12.7 其他并发问题](#127-其他并发问题)
		- [12.7.1 线程安全](#1271-线程安全)
		- [12.7.2 可重入性](#1272-可重入性)
		- [12.7.3 在线程化的程序中使用已存在的库函数](#1273-在线程化的程序中使用已存在的库函数)
		- [12.7.4 竞争](#1274-竞争)
		- [12.7.5 死锁](#1275-死锁)
	- [12.8 小结](#128-小结)

# 并发编程

如果逻辑控制流在时间上重叠，那么它们就是并发的。这种常见的现象称为**并发**，出现在计算机系统的许多不同层面上。硬件异常处理程序、进程和Linux信号处理程序都是大家很熟悉的例子。

到目前为止，我们主要将并发看做是一种操作系统内核用来运行多个应用程序的机制。但是，并发不仅仅局限于内核。它也可以在应用程序中扮演重要角色。例如，Linux信号处理程序如何允许应用响应异步事件，例如用户键入Ctrl+C，或者程序访问虚拟内存的一个未定义的区域。**应用级并发在其他情况下也是很有用的**:

* **访问慢速I/О设备**。当一个应用正在等待来自慢速I/O设备(例如磁盘)的数据到达时，内核会运行其他进程，使CPU保持繁忙。每个应用都可以按照类似的方式，通过交替执行I/О请求和其他有用的工作来利用并发。

* **与人交互**。和计算机交互的人要求计算机有同时执行多个任务的能力。例如，他们在打印一个文档时，可能想要调整一个窗口的大小。现代视窗系统利用并发来提供这种能力。每次用户请求某种操作(比如通过单击鼠标)时，一个独立的并发逻辑流被创建来执行这个操作。

* **通过推迟工作以降低延迟**。有时，应用程序能够通过推迟其他操作和并发地执行它们，利用并发来降低某些操作的延迟。比如，一个动态内存分配器可以通过推迟合并，把它放到一个运行在较低优先级上的并发“合并”流中，在有空闲的CPU周期时充分利用这些空闲周期，从而降低单个free操作的延迟。

* **服务多个网络客户端**。第11章中的迭代网络服务器是不现实的，因为它们一次只能为一个客户端提供服务。因此，一个慢速的客户端可能会导致服务器拒绝为所有其他客户端服务。对于一个真正的服务器来说，可能期望它每秒为成百上千的客户端提供服务，由于一个慢速客户端导致拒绝为其他客户端服务，这是不能接受的。一个更好的方法是创建一个并发服务器，它为每个客户端创建一个单独的逻辑流。这就允许服务器同时为多个客户端服务，并且也避免了慢速客户端独占服务器。

* **在多核机器上进行并行计算**。许多现代系统都配备多核处理器，多核处理器中包含有多个CPU。被划分成并发流的应用程序通常在多核机器上比在单处理器机器上运行得快,因为这些流会并行执行，而不是交错执行。

使用应用级并发的应用程序称为并发程序。现代操作系统提供了**三种基本的构造并发程序的方法**:

* **进程**。用这种方法，每个逻辑控制流都是一个进程，由内核来调度和维护。因为进程有独立的虚拟地址空间，想要和其他流通信，控制流必须使用某种显式地进程间通信(IPC)机制。

* **I/O多路复用**。在这种形式的并发编程中，应用程序在一个进程的上下文中显式地调度它们自己的逻辑流。逻辑流被模型化为状态机，数据到达文件描述符后，主程序显式地从一个状态转换到另一个状态。因为程序是一个单独的进程，所以所有的流都共享同一个地址空间。

* **线程**。线程是运行在一个单一进程上下文中的逻辑流，由内核进行调度。你可以把线程看成是其他两种方式的混合体，像进程流一样由内核进行调度，而像I/O多路复用流一样共享同一个虚拟地址空间。

## 12.1 基于进程的并发编程

构造并发程序最简单的方法就是用**进程**，使用那些大家都很熟悉的函数，像fork、exec和 waitpid。例如，一个构造并发服务器的自然方法就是，在父进程中接受客户端连接请求，然后创建一个新的子进程来为每个新客户端提供服务。

为了了解这是**如何工作**的，假设我们有两个客户端和一个服务器，服务器正在监听一个监听描述符(比如指述符3)上的连接请求。现在假设服务器接受了客户端1的连接请求，并返回一个已连接描述符(比如指述符4)。在接受连接请求之后，服务器派生一个子进程，这个子进程获得服务器描述符表的完整副本。子进程关闭它的副本中的监听描述符3，而父进程关闭它的已连接描述符4的副本，因为不再需要这些描述符了，此时子进程正忙于为客户端提供服务。

因为父、子进程中的已连接描述符都指向同一个文件表表项，所以父进程关闭它的已连接描述符的副本是至关重要的。否则，将永不会释放已连接描述符4的文件表条目，而且由此引起的内存泄漏将最终消耗光可用的内存，使系统崩溃。

现在，假设在父进程为客户端1创建了子进程之后，它接受一个新的客户端2的连接请求，并返回一个新的已连接描述符(比如描述符5)。然后，父进程又派生另一个子进程，这个子进程用已连接描述符5为它的客户端提供服务。此时，父进程正在等待下一个连接请求，而两个子进程正在并发地为它们各自的客户端提供服务。

### 12.1.1 基于进程的并发服务器

通常服务器会运行很长的时间，所以我们必须要包括一个SIGCHLD处理程序，来回收僵死子进程的资源。因为当SIGCHLD处理程序执行时，SIGCHLD信号是阻塞的，而Linux信号是不排队的，所以SIGCHLD处理程序必须准备好回收多个僵死子进程的资源。

其次，父子进程必须关闭它们各自的connfd副本。就像我们已经提到过的，这对父进程而言尤为重要，它必须关闭它的已连接描述符，以避免内存泄漏。

最后，因为套接字的文件表表项中的引用计数，直到父子进程的connfd都关闭了，到客户端的连接才会终止。

### 12.1.2 进程的优劣

对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。进程有独立的地址空间既是优点也是缺点。这样一来，一个进程不可能不小心覆盖另一个进程的虚拟内存，这就消除了许多令人迷惑的错误，这是一个明显的优点。

另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，它们必须使用显式的IPC(进程间通信)机制。基于进程的设计的另一个缺点是，它们往往比较慢，因为进程控制和IPC的开销很高

## 12.2 基于I/O多路复用的并发编程

假设要求你编写一个echo服务器，它也能对用户从标准输入键入的交互命令做出响应。在这种情况下，服务器必须响应两个互相独立的I/O事件:1)网络客户端发起连接请求，2)用户在键盘上键入命令行。我们先等待哪个事件呢?没有哪个选择是理想的。如果在accept中等待一个连接请求，我们就不能响应输入的命令。类似地，如果在read中等待一个输入命令，我们就不能响应任何连接请求。

针对这种困境的一个解决办法就是I/0多路复用技术。基本的思路就是使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后，才将控制返回给应用程序。

```C
#include <sys/select.h>

int select(int n, fd_set *fdset，NULL，NULL，NULL);
// 返回已准备好的描述符的非零的个数,若出错则为-1

FD_ZERO(fd_set *fdset);	/* Clear all bits in fdset */
FD_CLR(int fd, fd_set *fdset);	/* Clear bit fd in fdset */
FD_SET(int fd，fd_set *fdset);	/* Turn on bit fd in fdset */
FD_ISSET(int fd，fd_set *fdset);	/* Is bit fd in fdset on? */
// 处理描述符集合的宏。
```

select是一个复杂的函数，有许多不同的使用场景。我们将只讨论第一种场景:等待一组描述符准备好读。

select函数处理类型为fd_set的集合，也叫做**描述符集合**。逻辑上，我们将描述符集合看成一个大小为n的位向量:$b_{n-1},…,b_1,b_0$。每个位b对应于描述符k。当且仅当b=1，描述符k才表明是描述符集合的一个元素。只允许你对描述符集合做三件事:1)分配它们，2)将一个此种类型的变量赋值给另一个变量，3)用FD_ZERO、FD_SET、FD_CLR和FD_ISSET宏来修改和检查它们。

针对我们的目的，select函数有两个输入:一个称为读集合的描述符集合(fdset)和该读集合的基数(n)(实际上是任何描述符集合的最大基数)。select函数会一直阻塞，直到读集合中至少有一个描述符准备好可以读。当且仅当一个从该描述符读取一个字节的请求不会阻塞时，描述符k就表示准备好可以读了。select有一个副作用，它修改参数fdset指向的fd_set，指明读集合的一个子集，称为准备好集合(ready set)，这个集合是由读集合中准备好可以读了的描述符组成的。该函数返回的值指明了准备好集合的基数。注意，由于这个副作用，我们必须在每次调用select时都更新读集合。

### 12.2.1 基于I/O多路复用的并发事件驱动服务器

I/O多路复用可以用做并发事件驱动程序的基础，在事件驱动程序中，某些事件会导致流向前推进。一般的思路是将逻辑流模型化为状态机。不严格地说，一个状态机就是一组状态、输入事件和转移，其中转移是将状态和输入事件映射到状态。每个转移是将一个(输入状态，输入事件)对映射到一个输出状态。自循环是同一输入和输出状态之间的转移。通常把状态机画成有向图，其中节点表示状态，有向弧表示转移，而弧上的标号表示输入事件。一个状态机从某种初始状态开始执行。每个输入事件都会引发一个从当前状态到下一状态的

对于每个新的客户端k，基于I/O多路复用的并发服务器会创建一个新的状态机$s_k$，并将它和已连接描述符$d_k$联系起来。每个状态机$s_k$都有一个状态(“等待描述符$d_k$准备好可读”)、一个输入事件(“描述符$d_k$准备好可以读了”)和一个转移(“从描述符$d_k$读一个文本行”)。

服务器使用I/O多路复用，借助select函数检测输入事件的发生。当每个已连接描述符准备好可读时，服务器就为相应的状态机执行转移，在这里就是从描述符读和写回一个文本行。

### 12.2.2 I/O多路复用技术的优劣

事件驱动设计的一个**优点**是，它比基于进程的设计给了程序员更多的对程序行为的控制。例如，我们可以设想编写一个事件驱动的并发服务器，为某些客户端提供它们需要的服务，而这对于基于进程的并发服务器来说，是很困难的。

另一个**优点**是，一个基于I/O多路复用的事件驱动服务器是运行在单一进程上下文中的，因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容易。一个与作为单个进程运行相关的**优点**是，你可以利用熟悉的调试工具，例如GDB,来调试你的并发服务器，就像对顺序程序那样。最后，事件驱动设计常常比基于进程的设计要高效得多，因为它们不需要进程上下文切换来调度新的流。

事件驱动设计一个明显的**缺点**就是编码复杂。我们的事件驱动的并发echo服务器需要的代码比基于进程的服务器多三倍，并且很不幸，随着并发粒度的减小，复杂性还会上升。这里的粒度是指每个逻辑流每个时间片执行的指令数量。例如，在示例并发服务器中，并发粒度就是读一个完整的文本行所需要的指令数量。只要某个逻辑流正忙于读一个文本行，其他逻辑流就不可能有进展。对我们的例子来说这没有问题，但是它使得在“故意只发送部分文本行然后就停止”的恶意客户端的攻击面前，我们的事件驱动服务器显得很脆弱。修改事件驱动服务器来处理部分文本行不是一个简单的任务，但是基于进程的设计却能处理得很好，而且是自动处理的。基于事件的设计另一个重要的缺点是它们不能充分利用多核处理器。

## 12.3 基于线程的并发编程

到目前为止，我们已经看到了两种创建并发逻辑流的方法。在第一种方法中，我们为每个流使用了单独的进程。内核会自动调度每个进程，而每个进程有它自己的私有地址空间，这使得流共享数据很困难。在第二种方法中，我们创建自己的逻辑流，并利用I/O多路复用来显式地调度流。因为只有一个进程，所有的流共享整个地址空间。本节介绍第三种方法：基于**线程**,它是这两种方法的混合。

**线程就是运行在进程上下文中的逻辑流**。在本书里迄今为止，程序都是由每个进程中一个线程组成的。但是现代系统也允许我们编写一个进程里同时运行多个线程的程序。线程由内核自动调度。每个线程都有它自己的线程上下文，包括一个唯一的整数线程ID(TID)、栈、栈指针、程序计数器、通用目的寄存器和条件码。所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间。

**基于线程的逻辑流结合了基于进程和基于I/O多路复用的流的特性**。同进程一样，线程由内核自动调度，并且内核通过一个整数ID来识别线程。同基于I/O多路复用的流一样，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的所有内容，包括它的代码、数据、堆、共享库和打开的文件。

### 12.3.1 线程执行模型

**多线程的执行模型在某些方面和多进程的执行模型是相似的**。每个进程开始生命周期时都是单一线程，这个线程称为主线程。在某一时刻，主线程创建一个对等线程，从这个时间点开始，两个线程就并发地运行。最后，因为主线程执行一个慢速系统调用，例如read或者sleep，或者因为被系统的间隔计时器中断，控制就会通过上下文切换传递到对等线程。对等线程会执行一段时间，然后控制传递回主线程，依次类推。

**在一些重要的方面，线程执行是不同于进程的**。因为一个线程的上下文要比一个进程的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程不像进程那样，不是按照严格的父子层次来组织的。和一个进程相关的线程组成一个对等(线程)池，独立于其他线程创建的线程。主线程和其他线程的区别仅在于它总是进程中第一个运行的线程。对等(线程)池概念的主要影响是，一个线程可以杀死它的任何对等线程，或者等待它的任意对等线程终止。另外，每个对等线程都能读写相同的共享数据。

### 12.3.6 分离线程

**在任何一个时间点上，线程是可结合的或者是分离的**。一个可结合的线程能够被其他线程收回和杀死。在被其他线程回收之前，它的内存资源(例如栈)是不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的。它的内存资源在它终止时由系统自动释放。

**默认情况下，线程被创建成可结合的**。为了避免内存泄漏，每个可结合线程都应该要么被其他线程显式地收回，要么通过调用pthread_detach函数被分离。

## 12.4 多线程程序中的共享变量

从程序员的角度来看，线程很有吸引力的一个方面是多个线程很容易**共享相同的程序变量**。然而，这种共享也是很棘手的。为了编写正确的多线程程序，我们必须对所谓的共享以及它是如何工作的有很清楚的了解。

为了理解C程序中的一个变量是否是共享的，有一些基本的问题要解答:1)线程的基础内存模型是什么?2）根据这个模型，变量实例是如何映射到内存的?3）最后，有多少线程引用这些实例?一个变量是共享的，当且仅当多个线程引用这个变量的某个实例。

示例程序由一个创建了两个对等线程的主线程组成。主线程传递一个唯一的ID给每个对等线程，每个对等线程利用这个ID输出一条个性化的信息，以及调用该线程例程的总次数。

### 12.4.1 线程内存模型

**一组并发线程运行在一个进程的上下文中**。每个线程都有它自己独立的线程上下文，包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值。每个线程和其他线程一起共享进程上下文的剩余部分。这包括整个用户虚拟地址空间，它是由只读文本(代码)、读/写数据、堆以及所有的共享库代码和数据区域组成的。线程也共享相同的打开文件的集合。

**从实际操作的角度来说，让一个线程去读或写另一个线程的寄存器值是不可能的**。另一方面，任何线程都可以访问共享虚拟内存的任意位置。如果某个线程修改了一个内存位置，那么其他每个线程最终都能在它读这个位置时发现这个变化。因此，寄存器是从不共享的，而虚拟内存总是共享的。

**各自独立的线程栈的内存模型不是那么整齐清楚的**。这些栈被保存在虚拟地址空间的栈区域中，并且通常是被相应的线程独立地访问的。我们说通常而不是总是，是因为不同的线程栈是不对其他线程设防的。所以，如果一个线程以某种方式得到一个指向其他线程栈的指针，那么它就可以读写这个栈的任何部分。示例程序对等线程直接通过全局变量ptr间接引用主线程的栈的内容。

### 12.4.2 将变量映射到内存

多线程的C程序中变量根据它们的存储类型被映射到虚拟内存:

* 全局变量。全局变量是定义在函数之外的变量。在运行时，虚拟内存的读/写区域只包含每个全局变量的一个实例，任何线程都可以引用。当一个变量只有一个实例时，我们只用变量名(在这里就是ptr)来表示这个实例。

* 本地自动变量。本地自动变量就是定义在函数内部但是没有static属性的变量。在运行时，每个线程的栈都包含它自己的所有本地自动变量的实例。即使多个线程执行同一个线程例程时也是如此。例如，有一个本地变量tid的实例，它保存在主线程的栈中。我们用tid.m来表示这个实例。再来看一个例子，本地变量myid有两个实例，一个在对等线程0的栈内，另一个在对等线程1的栈内。我们将这两个实例分别表示为myid.p0和 myid.p1。

* 本地静态变量。本地静态变量是定义在函数内部并有static属性的变量。和全局变量一样，虚拟内存的读/写区域只包含在程序中声明的每个本地静态变量的一个实例。例如，即使示例程序中的每个对等线程都在第25行声明了cnt，在运行时，虚拟内存的读/写区域中也只有一个cnt的实例。每个对等线程都读和写这个实例。

### 12.4.3 共享变量

我们说一个变量v是共享的，当且仅当它的一个实例被一个以上的线程引用。例如，示例程序中的变量cnt就是共享的，因为它只有一个运行时实例，并且这个实例被两个对等线程引用。在另一方面，myid不是共享的，因为它的两个实例中每一个都只被一个线程引用。然而，认识到本地自动变量也能被共享是很重要的。

## 12.5 用信号量同步线程

共享变量是十分方便的，但是它们也引入了同步错误的可能性。

### 12.5.1 进度图

**进度图**将n个并发线程的执行模型化为一条n维笛卡儿空间中的轨迹线。每条轴k对应于线程k的进度。每个点($I_1, I_2,...,I_n$)代表线程k(k=1，…，n)已经完成了指令$I_k$这一状态。图的原点对应于没有任何线程完成一条指令的初始状态。

**二维进度图**示例水平轴对应于线程1，垂直轴对应于线程2。点($L_1, S_2$)对应于线程1完成了$L_1$而线程2完成了$S_2$的状态。

**进度图将指令执行模型化为从一种状态到另一种状态的转换**。转换被表示为一条从一点到相邻点的有向边。合法的转换是向右(线程1中的一条指令完成)或者向上(线程2中的一条指令完成)的。两条指令不能在同一时刻完成——对角线转换是不允许的。程序决不会反向运行，所以向下或者向左移动的转换也是不合法的。一个程序的执行历史被模型化为状态空间中的一条轨迹线。

对于线程i，操作共享变量cnt内容的指令($L_i, U_i, S_i$)构成了一个(关于共享变量cnt的)**临界区**，这个临界区不应该和其他进程的临界区交替执行。换句话说，我们想要确保每个线程在执行它的临界区中的指令时，拥有对共享变量的互斥的访问。通常这种现象称为**互斥**。

在进度图中，两个临界区的交集形成的状态空间区域称为**不安全区**。注意，不安全区和与它交界的状态相毗邻，但并不包括这些状态。绕开不安全区的轨迹线叫做安全轨迹线。相反，接触到任何不安全区的轨迹线就叫做不安全轨迹线。

任何安全轨迹线都将正确地更新共享计数器。为了保证线程化程序示例的正确执行(实际上任何共享全局数据结构的并发程序的正确执行)我们必须以某种方式同步线程，使它们总是有一条安全轨迹线。一个经典的方法是基于信号量的思想。

### 12.5.2 信号量

一种经典的解决同步不同执行线程问题的方法，这种方法是基于一种叫做信号量的特殊类型变量的。**信号量**s是具有非负整数值的全局变量，只能由两种特殊的操作来处理，这两种操作称为Р和V:

* **P(s)**：如果s是非零的，那么Р将s减1，并且立即返回。如果s为零，那么就挂起这个线程，直到s变为非零，而一个V操作会重启这个线程。在重启之后，Р操作将s减1，并将控制返回给调用者。

* **V(s)**：V操作将s加1。如果有任何线程阻塞在P操作等待s变成非零，那么V操作会重启这些线程中的一个，然后该线程将s减1，完成它的Р操作。

**P中的测试和减1操作是不可分割的**，也就是说,一旦预测信号量s变为非零，就会将s减1，不能有中断。**V中的加1操作也是不可分割的**，也就是加载、加1和存储信号量的过程中没有中断。注意，V的定义中没有定义等待线程被重启动的顺序。唯一的要求是V必须只能重启一个正在等待的线程。因此，当有多个线程在等待同一个信号量时，你不能预测V操作要重启哪一个线程。

P和V的定义确保了一个正在运行的程序绝不可能进入这样一种状态，也就是一个正确初始化了的信号量有一个负值。这个属性称为信号量不变性，为控制并发程序的轨迹线提供了强有力的工具。

### 12.5.3 使用信号量来实现互斥

**信号量提供了一种很方便的方法来确保对共享变量的互斥访问**。基本思想是将每个共享变量(或者一组相关的共享变量)与一个信号量s(初始为1)联系起来，然后用P(s)和V(s)操作将相应的临界区包围起来。

以这种方式来保护共享变量的信号量叫做**二元信号量**，因为它的值总是0或者1。以提供互斥为目的的二元信号量常常也称为**互斥锁**。在一个互斥锁上执行Р操作称为对互斥锁加锁。类似地，执行V操作称为对互斥锁解锁。对一个互斥锁加了锁但是还没有解锁的线程称为占用这个互斥锁。一个被用作一组可用资源的计数器的信号量被称为计数信号量。

**如何利用二元信号量来正确地同步计数器程序示例**。每个状态都标出了该状态中信号量s的值。关键思想是这种Р和V操作的结合创建了一组状态，叫做禁止区，其中s<0。因为信号量的不变性，没有实际可行的轨迹线能够包含禁止区中的状态。而且，因为禁止区完全包括了不安全区，所以没有实际可行的轨迹线能够接触不安全区的任何部分。因此，每条实际可行的轨迹线都是安全的，而且不管运行时指令顺序是怎样的，程序都会正确地增加计数器值。

从可操作的意义上来说，由P和V操作创建的禁止区使得在任何时间点上，在被包围的临界区中，不可能有多个线程在执行指令。换句话说，**信号量操作确保了对临界区的互斥访问**。

总的来说，为了用信号量正确同步计数器程序示例，我们首先声明一个信号量mutex，然后在主例程中将mutex初始化为1，最后，我们通过把在线程例程中对共享变量cnt的更新包围P和V操作，从而保护它们。

**进程图的局限性**：进度图给了我们一种较好的方法，将在单处理器上的并发程序执行可视化，也帮助我们理解为什么需要同步。然而，它们确实也有局限性,特别是对于在多处理器上的并发执行，在多处理器上一组CPU/高速缓存对共享同一个主存。多处理器的工作方式是进度图不能解释的。特别是，一个多处理器内存系统可以处于一种状态，不对应于进度图中任何轨迹线。不管如何，结论总是一样的:无论是在单处理器还是多处理器上运行程序,都要同步你对共享变量的访问。

### 12.5.4 利用信号量来调度共享资源

除了提供互斥之外，信号量的另一个重要作用是调度对共享资源的访问。在这种场景中，一个线程用信号量操作来通知另一个线程，程序状态中的某个条件已经为真了。两个经典而有用的例子是生产者-消费者和读者-写者问题。

1. **生产者-消费者问题**

**生产者和消费者线程共享一个有n个槽的有限缓冲区**。生产者线程反复地生成新的项目，并把它们插入到缓冲区中。消费者线程不断地从缓冲区中取出这些项目，然后消费(使用)它们。也可能有多个生产者和消费者的变种。

**因为插入和取出项目都涉及更新共享变量，所以我们必须保证对缓冲区的访问是互斥的**。但是只保证互斥访问是不够的，我们还需要调度对缓冲区的访问。如果缓冲区是满的(没有空的槽位)，那么生产者必须等待直到有一个槽位变为可用。与之相似，如果缓冲区是空的(没有可取用的项目)，那么消费者必须等待直到有一个项目变为可用。

**生产者-消费者的相互作用在现实系统中是很普遍的**。例如，在一个多媒体系统中，生产者编码视频帧，而消费者解码并在屏幕上呈现出来。缓冲区的目的是为了减少视频流的抖动，而这种抖动是由各个帧的编码和解码时与数据相关的差异引起的。缓冲区为生产者提供了一个槽位池，而为消费者提供一个已编码的帧池。另一个常见的示例是图形用户接口设计。生产者检测到鼠标和键盘事件，并将它们插入到缓冲区中。消费者以某种基于优先级的方式从缓冲区取出这些事件,并显示在屏幕上。

2. **读者-写者问题**

读者-写者问题是互斥问题的一个概括。**一组并发的线程要访问一个共享对象**，例如一个主存中的数据结构，或者一个磁盘上的数据库。有些线程只读对象，而其他的线程只修改对象。修改对象的线程叫做写者。只读对象的线程叫做读者。写者必须拥有对对象的独占的访问，而读者可以和无限多个其他的读者共享对象。一般来说，有无限多个并发的读者和写者。

**读者-写者交互在现实系统中很常见**。例如，一个在线航空预定系统中，允许有无限多个客户同时查看座位分配，但是正在预订座位的客户必须拥有对数据库的独占的访问。再来看另一个例子，在一个多线程缓存Web代理中，无限多个线程可以从共享页面缓存中取出已有的页面，但是任何向缓存中写入一个新页面的线程必须拥有独占的访问。

**读者-写者问题有几个变种，分别基于读者和写者的优先级**。第一类读者-写者问题，读者优先,要求不要让读者等待，除非已经把使用对象的权限赋予了一个写者。换句话说，读者不会因为有一个写者在等待而等待。第二类读者-写者问题,写者优先,要求一旦一个写者准备好可以写，它就会尽可能快地完成它的写操作。同第一类问题不同，在一个写者后到达的读者必须等待，即使这个写者也是在等待。

对这两种读者-写者问题的正确解答可能导致**饥饿**，饥饿就是一个线程无限期地阻塞，无法进展。

### 12.5.5 综合：基于预线程化的并发服务器

我们已经知道了如何使用信号量来访问共享变量和调度对共享资源的访问。为了帮助你更清晰地理解这些思想，让我们把它们应用到一个基于称为预线程化技术的并发服务器上。

在示例并发服务器中，我们为每一个新客户端创建了一个新线程。这种方法的缺点是我们为每一个新客户端创建一个新线程，导致不小的代价。一个基于预线程化的服务器试图通过使用生产者-消费者模型来降低这种开销。服务器是由一个主线程和一组工作者线程构成的。主线程不断地接收来自客户端的连接请求，并将得到的连接描述符放在一个有限缓冲区中。每一个工作者线程反复地从共享缓冲区中取出描述符，为客户端服务，然后等待下一个描述符。

## 12.6 使用线程提高并行性

到目前为止，在对并发的研究中，我们都假设并发线程是在单处理器系统上执行的。然而，大多数现代机器具有多核处理器。并发程序通常在这样的机器上运行得更快，因为操作系统内核在多个核上并行地调度这些并发线程，而不是在单个核上顺序地调度。

所有程序的集合能够被划分成不相交的顺序程序集合和并发程序的集合。写顺序程序只有一条逻辑流。写并发程序有多条并发流。并行程序是一个运行在多个处理器上的并发程序。因此，并行程序的集合是并发程序集合的真子集。

并行程序的详细处理超出了本书讲述的范围，将任务分配大搜不同线程的最直接方法是将序列划分成t个不相交的区域，然后给t个不同的线程每个分配一个区域。多个线程并行处理分配给它们的区域的不同方法，最简单也最直接的选择是将线程的和放入一个共享全局变量中，用互斥锁保护这个变量。

**并行编程的一项重要教训**：同步开销巨大，要尽可能避免。如果无可避免，必须要用尽可能多的有用计算弥补这个开销。

* **刻画并行程序的性能**

虽然绝对运行时间是衡量程序性能的终极标准，但是还是有一些有用的相对衡量标准能够说明并行程序有多好地利用了潜在的并行性。

并行程序的**加速比**通常定义为$S_p=\frac{T_1}{T_p}$。这里p是处理器核的数量，$T_x$是在k个核上的运行时间。这个公式有时被称为**强扩展**。当$T_1$是程序顺序执行版本的执行时间时，$S_p$称为**绝对加速比**。当$T_1$是程序并行版本在一个核上的执行时间时，$S_p$称为**相对加速比**。绝对加速比比相对加速比能更真实地衡量并行的好处。即使是当并行程序在一个处理器上运行时，也常常会受到同步开销的影响，而这些开销会人为地增加相对加速比的数值，因为它们增加了分子的大小。另一方面，绝对加速比比相对加速比更难以测量，因为测量绝对加速比需要程序的两种不同的版本。对于复杂的并行代码，创建一个独立的顺序版本可能不太实际，或者因为代码太复杂，或者因为源代码不可得。

一种相关的测量量称为**效率**，定义为$E_p=\frac{S_p}{p}=\frac{T_1}{pT_p}$。通常表示为范围在(0，100]之间的百分比。效率是对由于并行化造成的开销的衡量。具有高效率的程序比效率低的程序在有用的工作上花费更多的时间，在同步和通信上花费更少的时间。

加速比还有另外一面，称为**弱扩展**，在增加处理器数量的同时，增加问题的规模，这样随着处理器数量的增加，每个处理器执行的工作量保持不变。在这种描述中，加速比和效率被表达为单位时间完成的工作总量。例如，如果将处理器数量翻倍，同时每个小时也做了两倍的工作量，那么我们就有线性的加速比和100%的效率。

**弱扩展常常是比强扩展更真实的衡量值**，因为它更准确地反映了我们用更大的机器做更多的工作的愿望。对于科学计算程序来说尤其如此，科学计算问题的规模很容易增加，更大的问题规模直接就意味着更好地预测。不过，还是有一些应用的规模不那么容易增加，对于这样的应用，强扩展是更合适的。例如，实时信号处理应用所执行的工作量常常是由产生信号的物理传感器的属性决定的。改变工作总量需要用不同的物理传感器，这不太实际或者不太必要。对于这类应用，我们通常想要用并行来尽可能快地完成定量的工作。

## 12.7 其他并发问题

这一小节是关于在写并发程序时需要注意的一些问题的(非常不完整的)综述。为了让事情具体化，将以线程为例描述讨论。不过要记住，这些典型问题是任何类型的并发流操作共享资源时都会出现的。

### 12.7.1 线程安全

当用线程编写程序时，必须小心地编写那些具有称为**线程安全性**属性的函数。一个函数被称为线程安全的，当且仅当被多个并发线程反复地调用时，它会一直产生正确的结果。如果一个函数不是线程安全的，我们就说它是线程不安全的。

我们能够定义出**四个(不相交的)线程不安全函数类**:

1. **不保护共享变量的函数**。示例函数对一个未受保护的全局计数器变量加1。将这类线程不安全函数变成线程安全的，相对而言比较容易:利用像P和V操作这样的同步操作来保护共享的变量。这个方法的优点是在调用程序中不需要做任何修改。缺点是同步操作将减慢程序的执行时间。

2. **保持跨越多个调用的状态的函数**。例如当前调用的结果依赖于前次调用的中间结果。使得像示例函数线程安全的唯一方式是重写它，使得它不再使用任何static数据，而是依靠调用者在参数中传递状态信息。这样做的缺点是，程序员现在还要被迫修改调用程序中的代码。在一个大的程序中，可能有成百上千个不同的调用位置，做这样的修改将是非常麻烦的，而且容易出错。

3. **返回指向静态变量的指针的函数**。某些函数将计算结果放在一个static变量中，然后返回一个指向这个变量的指针。如果我们从并发线程中调用这些函数，那么将可能发生灾难，因为正在被一个线程使用的结果会被另一个线程悄悄地覆盖了。有两种方法来处理这类线程不安全函数。一种选择是重写函数，使得调用者传递存放结果的变量的地址。这就消除了所有共享数据，但是它要求程序员能够修改函数的源代码。如果线程不安全函数是难以修改或不可能修改的(例如，代码非常复杂或是没有源代码可用)，那么另外一种选择就是使用加锁-复制技术。基本思想是将线程不安全函数与互斥锁联系起来。在每一个调用位置，对互斥锁加锁，调用线程不安全函数，将函数返回的结果复制到一个私有的内存位置，然后对互斥锁解锁。为了尽可能地减少对调用者的修改，你应该定义一个线程安全的包装函数它执行加锁-复制，然后通过调用这个包装函数来取代所有对线程不安全函数的调用。

4. **调用线程不安全函数的函数**。如果函数f调用线程不安全函数g，那么f就是线程不安全的吗?不一定。如果g是第2类函数，即依赖于跨越多次调用的状态，那么f也是线程不安全的，而且除了重写g以外，没有什么办法。然而，如果g是第1类或者第3类函数，那么只要你用一个互斥锁保护调用位置和任何得到的共享数据，f仍然可能是线程安全的。

### 12.7.2 可重入性

有一类重要的线程安全函数，叫做**可重入函数**，其特点在于它们具有这样一种属性:当它们被多个线程调用时，不会引用任何共享数据。尽管线程安全和可重入有时会(不正确地)被用做同义词，但是它们之间还是有清晰的**技术差别**，值得留意。所有函数的集合被划分成不相交的线程安全和线程不安全函数集合。可重入函数集合是线程安全函数的一个真子集。可重入函数通常要比不可重入的线程安全的函数高效一些，因为它们不需要同步操作。更进一步来说，将第2类线程不安全函数转化为线程安全函数的唯一方法就是重写它，使之变为可重入的。关键思想是我们用一个调用者传递进来的指针取代了静态的变量。

检查某个函数的代码并先验地断定它是可重入的，这可能吗?不幸的是，不一定能这样。如果所有的函数参数都是传值传递的(即没有指针)，并且所有的数据引用都是本地的自动栈变量(即没有引用静态或全局变量)，那么函数就是**显式可重入**的，也就是说，无论它是被如何调用的，都可以断言它是可重入的。

然而，如果把假设放宽松一点，允许显式可重入函数中一些参数是引用传递的(即允许它们传递指针)，那么我们就得到了一个**隐式可重入**的函数，也就是说，如果调用线程小心地传递指向非共享数据的指针，那么它是可重入的。

我们总是使用术语可重入的既包括显式可重入函数也包括隐式可重入函数。然而，认识到可重入性有时既是调用者也是被调用者的属性，并不只是被调用者单独的属性是非常重要的。

### 12.7.3 在线程化的程序中使用已存在的库函数

一些线程不安全库函数都是第3类的，它们返回一个指向静态变量的指针。如果我们需要在一个线程化的程序中调用这些函数中的某一个，对调用者来说最不惹麻烦的方法是加锁-复制。然而，加锁-复制方法有许多缺点。首先，额外的同步降低了程序的速度。第二，部分函数返回指向复杂结构的结构的指针，要复制整个结构层次，需要深层复制结构。第三，加锁-复制方法对像rand这样依赖跨越调用的静态状态的第2类函数并不有效。

因此，Linux系统提供大多数线程不安全函数的可重入版本。可重入版本的名字总是以“_r”后缀结尾。例如，asctime的可重入版本就叫做asctime_r。我们建议尽可能地使用这些函数。

### 12.7.4 竞争

当一个程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流中的x点时，就会发生**竞争**。通常发生竞争是因为程序员假定线程将按照某种特殊的轨迹线穿过执行状态空间，而忘记了另一条准则规定:多线程的程序必须对任何可行的轨迹线都正确工作。

为了**消除竞争**，我们可以动态地为每个整数ID分配一个独立的块，并且传递给线程例程一个指向这个块的指针。请注意线程例程必须释放这些块以避免内存泄漏。

### 12.7.5 死锁

信号量引入了一种潜在的令人厌恶的运行时错误，叫做**死锁**，它指的是一组线程被阻塞了，等待一个永远也不会为真的条件。进度图对于理解死锁是一个无价的工具。进度图中两个禁止区域s和t部分重叠，则他们的外切矩形的左下角即为死锁状态d。

* 程序员使用Р和V操作顺序不当，以至于两个信号量的禁止区域里叠。如果某个执行轨迹线碰巧到达了死锁状态d，那么就不可能有进一步的进展了，因为重叠的祭止区域阻塞了每个合法方向上的进展。换句话说，程序死锁是因为每个线程都在等待其他线程执行一个根本不可能发生的V操作。

* 重叠的禁止区域引起了一组称为死锁区域的状态。如果一个轨迹线碰巧到达了一个死锁区域中的状态，那么死锁就是不可避免的了。轨迹线可以进入死锁区域，但是它们不可能离开。

* 死锁是一个相当困难的问题，因为它不总是可预测的。一些幸运的执行轨迹线将绕开死锁区域，而其他的将会陷入这个区域。你可以运行一个程序1000次不出任何问题，但是下一次它就死锁了。或者程序在一台机器上可能运行得很好，但是在另外的机器上就会死锁。最糟糕的是，错误常常是不可重复的，因为不同的执行有不同的轨迹线。

程序死锁有很多原因，要避免死锁一般而言是很困难的。然而，当使用二元信号量来实现互斥时，你可以应用下面的简单而有效的规则来避免死锁:

互斥锁加锁顺序规则:给定所有互斥操作的一个全序，如果每个线程都是以一种顺序获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的。

## 12.8 小结

一个并发程序是由在时间上重叠的一组逻辑流组成的。在这一章中，我们学习了三种不同的构建并发程序的机制:进程、I/O多路复用和线程。我们以一个并发网络服务器作为贯穿全章的应用程序。

进程是由内核自动调度的，而且因为它们有各自独立的虚拟地址空间，所以要实现共享数据，必须要有显式的IPC机制。事件驱动程序创建它们自己的并发逻辑流，这些逻辑流被模型化为状态机，用I/O多路复用来显式地调度这些流。因为程序运行在一个单一进程中,所以在流之间共享数据速度很快而且很容易。线程是这些方法的混合。同基于进程的流一样，线程也是由内核自动调度的。同基于I/О多路复用的流一样，线程是运行在一个单一进程的上下文中的，因此可以快速而方便地共享数据。

无论哪种并发机制，同步对共享数据的并发访问都是一个困难的问题。提出对信号量的P和V操作就是为了帮助解决这个问题。信号量操作可以用来提供对共享数据的互斥访问，也对诸如生产者-消费者程序中有限缓冲区和读者-写者系统中的共享对象这样的资源访问进行调度。一个并发预线程化的echo服务器提供了信号量使用场景的很好的例子。

并发也引入了其他一些困难的问题。被线程调用的函数必须具有一种称为线程安全的属性。我们定义了四类线程不安全的函数，以及一些将它们变为线程安全的建议。可重入函数是线程安全函数的一个真子集，它不访问任何共享数据。可重入函数通常比不可重入函数更为有效，因为它们不需要任何同步原语。竞争和死锁是并发程序中出现的另一些困难的问题。当程序员错误地假设逻辑流该如何调度时，就会发生竞争。当一个流等待一个永远不会发生的事件时，就会产生死锁。