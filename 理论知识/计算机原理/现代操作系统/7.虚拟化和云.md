- [7. 虚拟化和云](#7-虚拟化和云)
	- [7.2 虚拟化的必要条件](#72-虚拟化的必要条件)
	- [7.3 第一类和第二类虚拟机管理程序](#73-第一类和第二类虚拟机管理程序)
	- [7.4 高效虚拟化技术](#74-高效虚拟化技术)
		- [7.4.1 在不支持虚拟化的平台上实现虚拟化](#741-在不支持虚拟化的平台上实现虚拟化)
		- [7.4.2 虚拟化的开销](#742-虚拟化的开销)
	- [7.5 虚拟机管理程序时正确的微内核吗](#75-虚拟机管理程序时正确的微内核吗)
	- [7.6 内存虚拟化](#76-内存虚拟化)
	- [7.7 I/O虚拟化](#77-io虚拟化)
	- [7.8 虚拟装置](#78-虚拟装置)
	- [7.9 多核CPU上的虚拟机](#79-多核cpu上的虚拟机)
	- [7.11 云](#711-云)
		- [7.11.1 云即服务](#7111-云即服务)
		- [7.11.2 虚拟机迁移](#7112-虚拟机迁移)
		- [7.11.3 检查点](#7113-检查点)
	- [7.12 案例研究：VMware](#712-案例研究vmware)
		- [7.12.3 将虚拟化引入x86的挑战](#7123-将虚拟化引入x86的挑战)
		- [7.12.4 VMware Workstation解决方案概览](#7124-vmware-workstation解决方案概览)
		- [7.12.6 VMware的第一类虚拟机管理程序ESX Server](#7126-vmware的第一类虚拟机管理程序esx-server)

# 7. 虚拟化和云

多计算机系统的优点：1.可靠性：如果一台服务器崩溃了，其他的服务器并不受影响；2.安全性：恶意入侵者即使攻陷了一台服务器，也不能立即看到另一台服务器的数据，这个性质有时被称作沙盒；3.可以提供更多资源；4.可以运行多个操作系统

虚拟化技术：

虚拟化的主要思想是**虚拟机监控程序(VMM，又称虚拟机管理程序**)在同一物理硬件上创建出有多台虚拟机器的假象。第一类虚拟机管理程序运行在裸机上，第二类虚拟机管理程序依赖于底层操作系统提供的服务和抽象。无论是哪一类，虚拟化技术都允许单一计算机上运行多个虚拟机，各虚拟机能运行不同的操作系统

优点：1.一台虚拟机的故障不会影响其他虚拟机；2.物理机数量的减少节省了硬件和电力开销以及机架空间的占用；3.虚拟化技术还能在尝试新想法时提供帮助，虚拟机使得各个应用程序很容易拥有自己的运行环境；4.设置检查点和虚拟机迁移(如跨多台服务器进行负载均衡)比在普通操作系统上运行的迁移要容易得多；5.在已停止支持或无法工作于当前硬件的操作系统(或操作系统版本)上运行遗留应用程序；6.协助软件开发

云的核心思想是将计算或存储需求外包给一个管理良好的数据中心，领域专家组成的公司专门运营这个数据中心

## 7.2 虚拟化的必要条件

虚拟机管理程序需要在一下三个维度上有良好的表现：1.**安全性**：虚拟机管理程序应完全掌握虚拟资源；2.**保真性**：程序在虚拟机上执行的行为应与在裸机上相同；3.**高效性**：虚拟机中运行的大部分代码应不受虚拟机管理程序的干涉

在**解释器**中逐条考虑指令并准确执行其行为是一种安全执行指令的方式，目前可以认为解释器能够保证安全性，如果精心实现甚至能做到高保真，但是解释器的性能堪忧。为了满足性能妖气，虚拟机管理程序试图直接执行大多数代码

下面来讨论保真性。每个包含内核态和用户态的CPU都有一个特殊的指令集合，其中的指令在内核态和用户态执行的行为不同。这些指令包括进行I/O操作和修改MMU设置的指令，这类指令称为**敏感指令**。还有另一个指令集合，其中的指令在用户态执行时会导致陷入，这类指令称为**特权指令**。机器可虚拟化的一个必要条件是敏感指令为特权指令的子集。简单来说，如果用户态想要做不应该在用户态做的事情，硬件必须陷入

从2005年起，Intel和AMD开始在CPU中引入虚拟化支持，使得上述问题最终得到解决。在Intel CPU中，这项技术称作**VT**，在AMD CPU中，这项技术称作**SVM**。接下来将使用VT作为通用的术语。VT技术的基本思想是创建可以运行虚拟机的容器。客户操作系统在容器中启动并持续运行，直到触发异常并陷入虚拟机管理程序，例如试图执行I/O指令时。会造成陷入的指令集合由虚拟机管理程序设置的硬件位图控制。有了这些扩展之后，在x86平台实现经典的**陷入并模拟**虚拟机成为可能

**二进制翻译**：早期的CPU不支持虚拟化，虚拟机管理程序并未真正运行原始的客户操作系统。虚拟机管理程序在运行中改写了部分代码，将有问题的指令替换成了安全的指令序列，模拟原指令的功能。例如，假设客户操作系统执行特权I/O指令，或者修改CPU的特权控制寄存器(如保存页目录地址的CR3寄存器)。这些指令的执行结果必须被限制在虚拟机内部，不能影响其他虚拟机或者虚拟机管理程序自身。因而，一条不安全的I/O指令会被替换成一个陷入操作经过安全性检查之后,执行等价的指令并返回结果。由于进行了改写操作，因此可以替换掉不属于特权指令的敏感指令,其他的指令可以直接执行。这项技术称作**二进制翻译**，7.4节将讨论更多的细节

**全虚拟化**：呈现出一个与底层硬件一模一样的虚拟机；**半虚拟化**：提供一层类似物理机器的软件接口，显式暴露出自身是一个虚拟化的环境。例如，它提供一组**虚拟化调用**，允许客户机向虚拟机管理程序发送显式的请求,就像系统调用为应用程序提供服务那样。客户机使用虚拟化调用执行特权操作，如修改页表等，但由于操作是客户机和虚拟机管理程序协作完成的,因此整个系统更加简单快速。半虚拟化的缺点是客户机需要了解虚拟机API，这意味着客户操作系统一般需要为虚拟机管理程序进行显式定制

在深入探究第一类和第二类虚拟机管理程序之前，需要指出的是并非所有的虚拟化技术都试图使客户机认为它拥有整个系统。有时，目标仅仅是使一个为另一操作系统、体系结构编写的程序能够正常运行。因此，我们需要将完全的系统虚拟化和**进程级虚拟化**区分开来。虽然本章接下来重点关注前者，但是后者在实践中也有应用。著名的例子包括WINE兼容层，允许Windows应用程序运行在POSIX兼容的系统上，如Linux、BSD和OS X。还有QEMU模拟器的进程级版本，能让一个体系结构的应用程序运行在另一个体系结构上

## 7.3 第一类和第二类虚拟机管理程序

**第一类虚拟机管理程序**：运行在裸机上，从技术上讲，第一类虚拟机管理程序就像一个操作系统，因为它是唯一一个运行在最高特权级的程序，它的工作是支持真实硬件的多个虚拟机拷贝，类似于普通操作系统支持的进程

**第二类虚拟机管理程序**：依赖于Windows、Linux等操作系统分配和调度资源的程序，很想一个普通的进程。当然第二类虚拟机管理程序仍伪装成具有CPU和各种设备的完整计算机

第二类虚拟机管理程序有时又称作**托管型虚拟机管理程序**，依赖Windows、Linux、OS X等宿主操作系统提供的大量功能。首次启动时，第二类虚拟机管理程序像一个刚启动的计算机那样运转，期望找到一个包含操作系统的DVD、U盘或CD-ROM。这些驱动器可以是虚拟设备，例如，可以将包含操作系统的镜像保存为宿主机硬盘上的ISO文件，让虚拟机管理程序伪装成从正常DVD驱动器中读取。接下来,虚拟机管理程序运行DVD上的安装程序，将操作系统安装到**虚拟磁盘**（其实只是宿主操作系统中的一个文件)上。客户操作系统安装完成后，就能启动并运行了

两类虚拟机管理程序都必须以一种安全的方式执行机器命令，运行在虚拟机管理程序上的一个操作系统不能影响其他虚拟机操作系统

运行在两类虚拟机管理程序上的操作系统都称作**客户操作系统**。对于第二类虚拟机管理程序，运行在底层硬件上的操作系统称作**宿主操作系统**

虚拟化技术类别和虚拟机管理程序的组合↓：
|虚拟化方式|第一类虚拟机管理程序|第二类虚拟机管理程序|
|:-:|:-:|:-:|
|无硬件支持|ESX Server 1.0|VMware Workstation1|
|半虚拟化|Xen 1.0||
|有硬件支持|vSphere、Xen、Hyper-V|VMware Fusion、KVM、Parallels|
|进程虚拟化||Wine|

## 7.4 高效虚拟化技术

假设目前有一个支持一台虚拟机的第一类虚拟机管理程序。与其他第一类虚拟机管理程序一样，它也运行在裸机上的内核态中。虚拟机作为用户态的一个进程运行，不允许执行敏感指令。然而，虚拟机上的操作系统认为自己运行在内核态(实际上不是)。我们称之为**虚拟内核态**。虚拟机中也运行用户进程，这些用户进程认为自己运行在用户态(实际上确实是的)。

|软硬件层次|说明|
|:-:|:-:|
|虚拟机：用户进程|用户态中的虚拟用户态|
|虚拟机：客户操作系统|用户态中的虚拟内核态|
|第一类虚拟机管理程序|内核态|
|硬件||

### 7.4.1 在不支持虚拟化的平台上实现虚拟化

在VT出现之前，软件工程师们利用[二进制翻译](#72-虚拟化的必要条件)和x86平台存在的硬件特性(如处理器的特权级)构建出了虚拟机系统

多年来，x86支持四个特权级。用户程序运行在第3级上，权限最少。在此级别中不能执行特权指令。第0级是最高特权级，允许执行任何指令。在正常运转中，操作系统内核运行在第0级。现有的操作系统均未使用剩下的两个特权级。换句话说，虚拟机管理程序可以自由使用剩下的两个特权级。很多虚拟化解决方案保持了虚拟机管理程序运行于内核态(第0级)，应用程序运行于用户态(第3级)，但将客户操作系统安排到一个中间特权级(第1级)。结果是内核比用户进程的特权级高，用户进程如果尝试访问内核内存就会导致访问冲突。同时,客户操作系统执行的特权指令会陷入虚拟机管理程序。虚拟机管理程序检查之后代表客户机执行特权指令的功能

**二进制翻译**：虚拟机管理程序确保客户操作系统中的敏感指令不再执行，具体做法是代码改写，一次改写一个基本块。**基本块**（是以转移指令结尾的一小段顺序指令序列除最后一条指令外,内部不含跳转、调用、陷入、返回或其他改变控制流的指令。在执行一个基本块之前，虚拟机管理程序扫描该基本块以寻找敏感指令，如果存在，就替换成调用虚拟机管理程序中处理例程的指令。最后一条转移指令也会被替换成调用虚拟机管理程序的指令，以确保下一基本块能重复此过程。动态翻译和模拟听起来代价很大，但通常并非如此。翻译过的基本块可以缓存下来，以后无需再次翻译。而且，大多数基本块并不包含敏感指令或特权指令，可以直接执行。如果虚拟机管理程序精心配置硬件，那么二进制翻译器可以忽略所有用户进程，毕竟它们确实是在用户态执行的。一个基本块执行完毕后，控制流返回虚拟机管理程序，以定位下一个基本块。如果下一个基本块已经翻译过，就能立即执行。否则，下一个基本块将被翻译、缓存、执行。最终，程序的绝大部分都将在缓存里，程序能以接近满速运行。此过程中会用到各种优化，例如，如果一个基本块以跳转到(或调用)另一个基本块结尾，则结尾的指令可以替换成直接跳转到(或调用)翻译过的基本块，从而消除与查找后继块相关联的所有开销。再次强调，用户程序中的敏感指令无需替换硬件会处理好。另一方面，在所有运行于第1级的客户操作系统代码上进行二进制翻译并替换可能造成陷入的特权指令的做法也很常见。因为陷入的开销很大，所以二进制翻译之后性能反而更好

大多数现代的第二类虚拟机管理程序有一个在第0级运行的内核模块，能够使用特权指令操纵硬件。当然，在最底层操纵硬件并给予客户机完整的地址空间已经没问题了，但在特定时刻虚拟机管理程序需要清除设置并还原原始的处理器上下文。例如，假设客户机运行时一个外围设备产生中断。由于第二类虚拟机管理程序依赖宿主操作系统的设备驱动程序来处理中断，因此它需要重新配置硬件以运行宿主操作系统代码。当设备驱动程序运行时，需保证一切像它期望的那样。虚拟机管理程序就像趁父母不在家举办聚会的青少年一样，他们可以重新摆放家具，只要在父母回来前把家具复位即可。由宿主操作系统的硬件配置切换到客户操作系统的硬件配置称作**系统切换**，7.12节将在讨论VMware时详细探讨系统切换

我们现在应该清楚了为什么虚拟机管理程序能在不支持虚拟化的硬件上工作:客户机内核的敏感指令被替换为对模拟这些指令的例程的调用。真实硬件不会直接执行客户操作系统中的敏感指令。这些敏感指令被转为对虚拟机管理程序的调用，虚拟机管理程序模拟了这些指令的功能

### 7.4.2 虚拟化的开销

在虚拟化上支持VT的CPU与软件翻译方法各有优劣

**VT硬件**使用的陷入并模拟方法会产生大量陷入，而陷入在现代硬件上开销很大，因为CPU高速缓存、TLB、转移预测都会受到不利影响。当敏感指令被替换为(宿主机进程内部)对虚拟机管理程序例程的调用后，就不用承担这些上下文切换的开销。，根据工作负载的不同，软件方法有时优于硬件方法。基于这一原因，某些第一类(和第二类)虚拟机管理程序为了性能而进行二进制翻译，虽然无须二进制翻译虚拟机也能正确运行

使用**二进制翻译**后，代码既有可能变快，也有可能变慢。例如，假改客户操作系统使用CLI指令禁用硬件中断。根据体系结构的不同，这条指令执行可能很慢，在具有深度流水和乱序执行技术的特定CPU上会占用数十个时钟周期。我们已经知道，客户操作系统希望关闭中断并不意味着虚拟机管理程序需要真的关闭它们并影响整个机器。因而，虚拟机管理程序必须让客户机认为中断已经关闭，但并未真的关闭物理机器的中断。要实现这一点，虚拟机管理程序可以在为每个客尸机维护的虚拟CPU数据结构中记录一个专门的**IF** (中断标志)位，以确保虚拟机在中断打开前不会收到任何中断。客户机执行的每条CLI指令都会替换成类似`VirtualCPU.IF=0`的指令数据传送指令的开销很小,只需1~3个时钟周期。因而，翻译后的代码执行更快。不过，现代的VT硬件通常情况下仍比软件性能好

如果客户操作系统**修改页表**，则开销会很大。每个客户操作系统都认为自己"拥有"整个机器，可以将任意虚拟页自由映射到任意物理页。可是，如果一个虚拟机希望使用的物理页已被另一个虚拟机(或虚拟机管理程序）使用，就必须采取一定对策。在7.6节可以看到，解决方案是增加一层页表,将"客户机物理页"映射到宿主机上的实际物理页。毫无疑问，操纵多重页表的开销不小

## 7.5 虚拟机管理程序时正确的微内核吗

第一类和第二类虚拟机管理程序都支持未修改的客户操作系统，但需要费尽千辛万苦才能取得较好的性能。我们已经看到，**半虚拟化**采取了不同的方法，要求修改客户操作系统的源代码。半虚拟化的客户机执行**虚拟化调用**而不是敏感指令。实际上，客户操作系统就像一个用户程序，向操作系统(虚拟机管理程序)发起系统调用。要使用这种方式，虚拟机管理程序必须定义一套调用接口,以供客户操作系统使用。这套调用接口实际上构成了**应用编程接口(API)**，虽然接口由客户操作系统而非应用程序使用

全虚拟化和半虚拟化的区别如下所示。两台由VT硬件支持的虚拟机，一个的客户操作系统是未修改的Windows。当执行一条敏感指令时会陷入虚拟机管理程序，模拟这条指令后返回。另一个客户操作系统是修改过的Linux，不再包含任何敏感指令。当它要进行I/O操作或修改关键的内部寄存器(如指向页表的那个)时，就执行虚拟化调用来完成，像标准Linux中的应用程序执行系统调用那样

**虚拟机接口(VMI)**：只要内核需要执行敏感操作，就调用的特殊的例程，它组成了硬件及虚拟机管理程序的底层接口。这些例程在设计上保持通用性，未绑定特定硬件平台或虚拟机管理程序

## 7.6 内存虚拟化

一个计算机系统不止有CPU虚拟化，内存和I/O设备也需要虚拟化

对每台虚拟机，虚拟机管理程序都需要创建一个**影子页表**，将虚拟机使用的虚拟页表映射到它分配给虚拟机的实际物理页上。每次客户操作系统修改页表，虚拟机管理程序都需要修改影子页表。但客户操作系统只要修改内存就能修改页表。然而修改内存并不涉及敏感指令，所以虚拟机无法察觉，也就无法更新实际硬件使用的影子页表

一种可行但笨拙的解决方案是让虚拟机管理程序跟踪客户机虚拟内存中保存顶级页表的页面。当客户机首次尝试载入指向顶级页表的硬件寄存器时，因为需要使用敏感指令，所以虚拟机管理程序能获得顶级页表所在的页面信息。虚拟机管理程序可以在此时创建影子页表，并将顶级页表及其指向的下级页表设为只读。这样客户操作系统接下来如果试图修改页表就会导致缺页异常，并将控制流交给虚拟机管理程序。虚拟机管理程序能够分析指令流以了解客户操作系统的意图，并相应地修改影子页表。这种做法不够优雅,但在原则上是可行的

另一个同样笨拙的解决方案做法恰好相反。虚拟机管理程序允许客户机向页表添加任何新映射，而影子页表不做任何改动。事实上，虚拟机管理程序甚至不知道客户机页表发生了变化。然而，只要客户机试图访问新映射的页面，就会产生缺页异常，将控制流交还虚拟机管理程序。这时虚拟机管理程序就可以探测客户机页表，看看影子页表是否需要添加新的映射，如果需要就添加后重新执行触发缺页异常的指令。那么如何处理客户机从页表中删除映射的情况?显然，虚拟机管理程序不能等待缺页异常，因为不会发生缺页异常。从页表中删除映射后需要执行INVLPG(真实意图是使TLB项失效)，虚拟机管理程序可以截获此敏感指令并删除影子页表中的对应项。同样，这种做法不够优雅但是可行

这两种方法都会带来大量缺页异常，而处理缺页异常开销很大。我们要将由于客户机程序访问被换出RAM的页面导致的"正常"缺页异常和由于保证影子页表与客户机页表一致而导致的缺页异常区分开来。前者是**客户机导致的缺页异常**，虽然由虚拟机管理程序捕获，但需要交给客户机处理。后者是**虚拟机管理程序导致的缺页异常**,处理方式是更新影子页表

缺页异常的开销很大，在虚拟化环境中尤为突出，因为缺页异常会导致**虚拟机退出**，虚拟机管理程序重新获得控制流。下面看看虚拟机退出时CPU要做些什么。首先，CPU需要记录导致虚拟机退出的原因以便虚拟机管理程序能够进行相应处理。CPU还需记录导致虚拟机退出的客户机指令的地址。接下来，CPU进行上下文切换，保存所有寄存器。然后，CPU载入虚拟机管理程序的处理器状态。此后虚拟机管理程序才可以开始处理缺页异常，仅仅开始处理缺页异常的开销就很大。处理完毕后，之前的步骤还需要反过来再进行一遍。整个过程消耗的时钟周期数超过几万个，因此人们才竭尽全力减少虚拟机退出的情况

在半虚拟化操作系统中情况有所不同。客户机的半虚拟化操作系统知道，完成修改页表操作后要通知虚拟机管理程序。因此，客户操作系统首先完成对页表的全部修改,然后执行虚拟化调用通知虚拟机管理程序页表更新的情况。这样就不需要每次页表改动都触发缺页异常，只需要全部修改完成后进行一次虚拟化调用即可,显然更加高效

1. 嵌套页表的硬件支持

为了避免处理影子页表的巨大开销，芯片生产商添加了**嵌套页表**的硬件支持。嵌套页表是AMD使用的术语,Intel将其称作**EPT(扩展页表)**。两者目的相似，都是在无需陷入的情况下由硬件处理虚拟化引发的额外页表操作，以降低开销

2. 回收内存

运行在相同物理硬件上的所有虚拟机都有自己的物理内存页，并认为自己支配着整个机器。这种设计非常好，但内存需要回收时就会发生问题，特别是与内存**过量使用**功能结合时。内存过量使用是指虚拟机管理程序向所有虚拟机提供的物理内存总量会超过系统中买际的物理内存大小。一般而言，这个想法很好，虚拟机管理程序可以同时创建更多配置更高的虚拟机。例如，一台机器有32GB物理内存，可以运行三台各16GB内存的虚拟机。从数值上来看显然是不匹配的。然而，三台虚拟机可能并不会同时用到物理内存的上限，或者可能共享一些具有相同内容的页面(例如Linux内核)，这时便可使用**去重**优化技术。在这种情况下，三台虚拟机使用的物理内存总量小于16GB的三倍。去重技术后面再作讨论。目前关注的问题是随着工作负载的变化，之前合理的虚拟机物理内存分配可能变得不再合适。也许虚拟机1需要更多内存而虚拟机2需求少一些，这样虚拟机管理程序就需要将内存资源从一台虚拟机转移到另一台，以使系统整体受益。问题是，怎样安全地回收已分配给一台虚拟机的物理内存页?

原则上，可以再增加一层分页。当内存短缺时，虚拟机管理程序可以换出一些虚拟机的页，就像操作系统换出应用程序的一些页。这种方法的缺点是必须由虚拟机管理程序完成，然而它并不清楚不同页对客户机的重要性差异，因而换出的页面可能是错误的。即使虚拟机管理程序选择了正确的页(即客户操作系统也会选择的页）换出，接下来还有更多问题。例如，假设虚拟机管理程序换出页P，稍后客户操作系统也决定将P换出到磁盘。遗憾的是，虚拟机管理程序与客户操作系统的交换空间不同。也就是说，虚拟机管理程序首先要将P换入内存，然后看着客户操作系统立即又将其换出到磁盘。这太低效了

常用的解决方案是使用称作**气球**(ballooning)的技术。一个小的气球模块作为伪设备驱动程序加载到每个虚拟机中，与虚拟机管理程序通信。气球模块在虚拟机管理程序的请求下可以通过申请锁定页面来膨胀，也可以通过释放这些页面而紧缩。气球膨胀，客户机的实际可用物理内存减少,客户操作系统将以换出最不重要页面的方式响应这一变化，正如期望的那样。反过来气球紧缩,客户机可用内存增加。虚拟机管理程序让操作系统来帮它作决定，通俗地讲这叫踢皮球

## 7.7 I/O虚拟化

前面介绍了CPU和内存虚拟化，接下来研究一下I/O虚拟化。客户操作系统启动时通常会探测连接了哪些I/O设备，这些探测将陷入虚拟机管理程序，后者应该如何处理?一种方法是回复实际硬件中的磁盘、打印机等，客户机将加载这些设备的驱动程序并试图使用它们。设备驱动程序尝试进行实际IO操作时将会读写硬件设备寄存器。这些指令是敏感的，将陷入虚拟机管理程序，按照需要读取或写入相应的硬件寄存器

但这里同样有一个问题。每个客户操作系统都认为自己拥有整个磁盘分区，而虚拟机的数量可能比磁盘分区数多得多。通常，解决方案是让虚拟机管理程序在实际磁盘上创建一个文件或一块区域作为虚拟机的磁盘。由于客户操作系统试图按实际硬件中的磁盘进行控制，因此虚拟机管理程序能理解其控制方式，将访问的块编号转换成用于存储的文件或区域的偏移值，并进行I/O

1. I/O MMU

像普通MMU一样，I/O MMU用页表将设备想要使用的内存地址(设备地址)映射到物理地址。在虚拟环境中，虚拟机管理程序可以设置页表以避免设备进行DMA时影响到当前虚拟机之外的内存

I/O MMU在处理虚拟环境中的设备时有许多优势。**设备穿透**允许将物理设备直接分配给特定虚拟机。通常，设备地址空间与客户机物理地址空间完全相同比较有利，而这依赖于I/O MMU。I/O MMU可以将设备地址与虚拟机地址映射为相同的空间，并且这一映射对设备和虚拟机来说都是透明的

**设备隔离**保证设备可以直接访问其分配到的虚拟机的内存空间而不影响其他虚拟机的完整性。也就是说I/O MMU能防止错误的DMA通信，就像普通MMU能防止进程的错误内存访问一样，两者在访问未映射页面时都会导致缺页异常

除了DMA和设备地址，I/O虚拟化还需要处理中断，使设备产生的中断以正确的中断号抵达正确的虚拟机。因此，现代IO MMU还支持**中断重映射**。比如一个设备发送了中断号为1的消息，消息首先抵达I/O MMU，通过中断重映射表转换为一个新的中断，目标是正在运行指定虚拟机的CPU,中断向量号是该虚拟机想要的

I/O MMU还能帮助32位设备访问4GB以上的物理内存。通常，32位设备不能访问(如通过DMA)4GB以上的地址，但I/O MMU可以将32位的设备地址映射到更大的物理地址空间中

2. 设备域

另一种处理I/O的方法是专门指定一个虚拟机运行普通操作系统，将其他虚拟机的所有I/O调用映射过来。在半虚拟化中这种方法能发挥更大优势，发送到虚拟机管理程序的命令真实地表达了客户操作系统想做的事情，而不是一系列读写硬件寄存器的命令。如果是后者，虚拟机管理程序需要推断客户操作系的目的。Xen就是使用这种方法来处理IO的,其中专门进行1/O的虚拟机称作Dom0(domain O)

在处理I/O虚拟化时第二类虚拟机管理程序明显比第一类有优势,因为第二类虚拟机管理程序中,宿主操作系统包含了所有连接到计算机的设备的驱动程序。当应用程序试图访问一个特定的设备时，翻译后的代码可以调用现有的设备驱动程序来完成工作。而第一类虚拟机管理程序要么自己包含设备驱动程序，要么调用类似宿主操作系统的Dom0。随着虚拟机技术的成熟，未来的硬件可能允许应用程序以一种安全的方式直接访问，这意味着设备驱动程序可以直接链接到应用代码中，或者放到独立的用户态系统服务中(如MINIX3)，从而消除此问题

3. 单根I/O虚拟化

**单根I/O虚拟化(SR-IOV**)允许驱动程序与设备间绕过虚拟机管理程序进行通信。支持SR-IOV的设备能为每个使用该设备的虚拟机提供独立的地址空间、中断和DMA流。使每个虚拟机都认为自己拥有对设备的独占式访问。此设备看起来就像多个独立的设备，分别分配到不同的虚拟机。例如每个虚拟设备都有独立的基址寄存器和地址空间，虚拟机将分配给它的虚拟设备的地址空间映射到自己的地址空间中

## 7.8 虚拟装置

虚拟机能够解决一个困扰用户已久的问题:如何安装新的应用程序。解决这一问题对开源软件的用户尤为重要。许多应用程序依赖大量其他应用程序和运行库，这些应用程序和运行库又会引入更多的依赖软件包。此外，还可能有对特定版本的编译器、脚本语言、操作系统的依赖。有了虚拟机之后，软件开发人员可以精心构造一个虚拟机，装上需要的操作系统、编译器、运行库和应用程序代码，固定整个虚拟机使之可以随时运行。这个虚拟机镜像可以刻录到CD-ROM或发布到网站上让用户安装或下载。这种方法意味着只有软件开发人员需要知道所有的依赖关系。客户得到的是能实际运行的完整包，与他们使用的操作系统和安装的其他软件包、运行库完全无关。这类"盒装"的虚拟机通常称作**虚拟装置**

## 7.9 多核CPU上的虚拟机

虚拟机与多核CPU的结合创造了一个可用CPU数量能由软件设置的新世界。如果有4个CPU核心,每个核心最多可以运行8个虚拟机，则单个CPU可配置成32节点的多计算机系统。根据软件不同也可以配置成较少的CPU(节点)数。应用程序设计人员可以首先选择需要的CPU数量再进行设计，这一前所未有的进步开启了计算机技术的新阶段

此外，虚拟机之间可以共享内存。这项技术的一个典型用例是在服务器上运行多个相同客户操作系统的实例。虚拟机内存共享只需将物理页映射到多个虚拟机的地址空间中，这项技术已经用于去重的解决方案中。**去重**技术避免了重复保存相同的数据，在存储系统中是相当常见的技术，现在也应用到了虚拟化里。一般来说，这项技术反复扫描主机上每个虚拟机的内存并计算内存页的散列。如果某些页面散列值相同，那么系统首先检查它们的内容是否完全相同，相同的话就进行去重:创建一个包含实际内容的页面，其他页面引用此页面。虚拟机管理程序控制了嵌套(或影子)页表，因而这种映射并不复杂。当然，任意一个客户机修改共享页时，应当使修改操作对其他虚拟机不可见。这时可以使用写时复制技术让修改的页面为写者所私有

如果虚拟机能共享内存，单个计算机就能成为虚拟的多处理器系统由于多核芯片上的所有核心共享相同的RAM,因此单一的四核芯片根据需要可以很容易地配置成32节点多处理器或多计算机系统

## 7.11 云

美国国家标准与技术研究院列出了云的五条必要特征：

1. **按需自助服务**：无需人为操作就能自动为用户提供资源

2. **普适的网络访问**：所有资源都可以通过网络用标准化的机制访问,以支持各种异构设备

3. **资源池**：云提供商拥有的资源可以服务多个用户并动态再分配,用户通常不知道他们使用的资源的具体位置

4. **快速可伸缩**：能根据用户需求弹性甚至是自动地获取和释放资源

5. **服务可计量**：云提供商按服务类型计量用户使用的资源

### 7.11.1 云即服务

本节讨论虚拟化和操作系统在云中的作用。我们认为云的功能是提供一个用户可以直接访问并任意使用的虚拟机。因而，同一个云中可能运行着不同的操作系统(这些操作系统很叮能运仃住问个物理机上)。这种云称作**基础设施即服务(IAAS)**，与**平台即服务**(PAAS,提供包含特定操作系统、数据库、Web服务益等软件的功境)、**软件即服务**(SAAS,提供特定软件的访问服务，如Microsoft Office 365和Google Apps等)及其他种类的"……即服务"相对

### 7.11.2 虚拟机迁移

虚拟机管理程序将虚拟机与物理硬件解耦。也就是说，虚拟机运行在哪台机器上并不重要。因此，在一台机器需要检修时，管理员可以简单地关闭所有虚拟机并在另一台机器上重新启动它们。然而，这样做会带来显著的停机时间。挑战在于不关闭虚拟机就将其从需要检修的硬件迁移到新的机器上

一个小的改进是迁移时暂停而非关闭虚拟机。在暂停过程中，将虚拟机使用的内存页尽快复制到新机器上，在新的虚拟机管理程序上配置好并恢复执行。除了内存之外，还需要迁移存储和网络连接，如果物理机器距离较近，则迁移过程也会相对较快。首先可以使用基于网络的文件系统，以使虚拟机运行在哪个机架上变得无关紧要。类似地，IP地址可以简单地转换到新位置。不过，仍然需要将虚拟机暂停一段时间,可能比关机迁移时间短一些,但还是比较耗时的

现代虚拟化解决方案提供的是**热迁移**，虚拟机迁移时仍能运转。例如，使用**内存预复制迁移**，能在虚拟机提供服务的同时复制内存页。大多数内存页的写入并不频繁，直接复制是安全的。但是，虚拟机仍在运行，所以页面复制之后可能会被修改。页面修改时将其标记为脏的，以确保最新版本复制到目标机器。脏页面会重新复制。当大多数页面复制完成后，只剩少量脏页面。短暂地暂停虚拟机以复制它们，然后在目标机器上恢复虚拟机执行。虽然仍有暂停,但时间很短，应用程序通常不会受到影响。若停机时间不算太耗时，就称作**无缝热迁移**

### 7.11.3 检查点

虚拟机与物理硬件的解耦还有其他优势，尤其是可以暂停一个虚拟机，这很有用。如果暂停的虚拟机的状态(例如CPU状态、内存页、存储状态)保存在磁盘上，就成为运行中的虚拟机的快照。当软件导致运行中的虚拟机崩溃时，就可以回滚到快照保存的状态,若无其事地继续运行

保存快照的最直接方式是复制所有状态，包括完整的文件系统。然而，即使磁盘速度很快，复制上TB的磁盘内容也会花点时间。和前面的虚拟机迁移相同，我们不想暂停太久。解决方案是使用**写时复制**技术，数据只有在绝对必需时才进行复制

快照相当好用，但还有些问题。如果虚拟机正在与远程机器交互怎么办?可以保存系统快照并稍后重新启动，但通信连接早就断开了。显然，这是一个无法解决的问题

## 7.12 案例研究：VMware

VMware Workstation是首个x86平台的第二类虚拟机管理程序

ESX Server是VMware的第一类虚拟机管理程序

### 7.12.3 将虚拟化引入x86的挑战

回忆对虚拟机和虚拟机管理程序的定义，虚拟机管理程序将著名的**添加间接层原则**应用到计算机硬件领域，将硬件抽象为虚拟机器:底层硬件的多个复制品，每个都运行独立的操作系统。虚拟机之间互相隔离，每个都像是底层硬件的复制品,理想情况下与物理机运行速度相同。

* VMware将下面这些虚拟机的核心特征适配到x86平台:

	1. **兼容性**：虚拟机提供本质上与物理机相同的环境，这意味着任何x86操作系统和所有应用程序都能无需修改就能运行在虚拟机上。虚拟机管理程序需要在硬件层面提供足够的兼容性，以使用户能不受限制地运行任意(版本的）操作系统

	2. **性能**：虚拟机管理程序的性能开销要足够低，以使用户能将虚拟机作为主要工作环境。以此为目标，VMware的设计者们希望能以接近本地执行的速度运行相关的工作负载。在最坏的情况下，虚拟机运行于最新一代处理器上的性能要与前一代处理器的本地性能相同。这是基于"大多数x86软件不会设计成只能运行在最新一代处理器上"的观察经验

	3. **隔离**：虚拟机管理程序必须保证虚拟机的隔离，不能对其中运行的软件做任何假设。也就是说虚拟机管理程序需要完全掌控所有资源，避免运行在虚拟机中的软件访问任何可能对其造成破坏的资源。类似地，虚拟机管理程序还要保证不属于虚拟机的所有数据的隐私。虚拟机管理程序必须假设客户操作系统可能会感染未知的恶意代码(比大型机时代重要得多)

这三个需求间不可避免地存在冲突。例如，某些领域的完全兼容性可能对性能造成不利影响，这种情况下VMware的设计者们需要在兼容性上让步。然而，他们不会在虚拟机隔离上让步，不会将虚拟机管理程序暴露在恶意客户机的攻击之下

* 总体来说有四大挑战:

	1. **x86体系结构不可虚拟化**：其中包含虚拟化敏感的非特权指令，违背了严格虚拟化准则。例如,POPF指令根据当前运行的软件是否被允许关中断而具有不同(且不会陷人)的语义。这个特点排除了传统的陷入并模拟的虚拟化方法。甚至Intel公司的工程师们都确信自己的处理器在实际意义上不可虚拟化

	2. **x86体系结构的高度复杂性**：它是一个众所周知相当复杂的CISC体系结构，包含了几十年的向后兼容性支持。这些年来，x86一共引人了四个主要的运行模式(实模式保护模式、虚拟8086模式和系统管理模式)，每种模式具有不同的硬件分段寻址模型、分页机制、特权级别设置和安全特征(例如调用门)

	3. **x86机器具有多种周边设备**：虽然只有两个主要的x86处理器生产商，但是个人计算机可能包含许多种类的扩展卡和设备，每个都有自己的驱动程序。虚拟化所有这些周边设备是不可行的，无论前端(虚拟机中的虚拟硬件)还是后端(虚拟机管理程序需要控制的真实硬件)

	4. **需要有简单的用户体验**：以前的经典虚拟机管理程序是在工厂中安装好的，类似于今天计算机中的固件程序。由于VMware刚起步，因此用户需要在现有的硬件上进行安装。VMware需要一种具有简单安装体验的软件交付模型,以利于推广

### 7.12.4 VMware Workstation解决方案概览

VMware Workstation是一个包含了多个模块的第二类虚拟机管理程序。一个重要模块是VMM,负责执行虚拟机的指令。另一个重要模块是VMX,负责与宿主操作系统交互

1. 虚拟化x86体系结构

首先，陷入并模拟式的直接执行虽然不能用来虚拟化整个x86体系结构，但在某些时候确实可用于x86虚拟化，例如执行用户态程序的时间，这占了相关工作负载的大多数执行时间。这是因为这些虚拟化敏感指令并不总是敏感的，它们只在特定情况下是敏感的

第二个关键点是通过适当配置硬件，特别是精心使用x86段保护机制，动态二进制翻译的系统代码也能以接近原生的速度执行

当然，VMware VMM中还有一些复杂且精妙之处。其设计的一个重要方面就是保证虚拟化沙盒的完整性，即确保虚拟机中运行的软件(包括恶意软件)不能篡改VMM。这一问题通常称作**软件故障隔离**,如果用软件实现，会增加每次访存的运行时开销。VMware VMM同样使用了基于硬件的方式。它将地址空间分成不相交的两部分，自己使用顶部的4MB地址空间，剩下的部分虚拟机可用。VMM配置硬件段式内存管理，使得任何虚拟机指令(包括二进制翻译器生成的指令)都不能访问地址空间顶部的4MB区域

2. 以客户操作系统为中心的策略

理想情况下，VMM在设计上不用考虑虚拟机上运行的客户操作系统及其如何配置硬件。虚拟化背后的思想是让虚拟机接口与硬件接口一致，以使所有能在硬件上运行的软件也能在虚拟机上运行。可惜,这种方式只有体系结构可虚拟化且简单时才可行。而x86体系结构的极大复杂性显然是个问题。为了简化此问题，VMware的工程师们选择性地支持一些特定的客户操作系统。这一简化没有改变总体设计，VMM仍能提供底层硬件的可靠复制品。但这一简化是对开发过程的有益指导，工程师们只需要关心受支持的客户操作系统中实际用到的硬件功能

3. 虚拟硬件平台

目前为止，主要讨论了与x86处理器虚拟化相关的问题。但基于x86的计算机远不止是处理器，还有芯片组、固件以及控制磁盘、网卡、CD-ROM、键盘的I/O设备等

在x86个人计算机上，IO外围设备的多样性使虚拟硬件不可能匹配真实的底层硬件。即使市场上只有少量x86处理器，且只在指令系统级别的功能上有很小的差异，但I/O设备却成千上万，而且大多数没有公开的接口或功能文档。VMware设计的关键点不是让虚拟机匹配特定底层硬件，而是让其匹配选定的标准IO设备组成的配置。客户操作系统可以用它们自己已有的内建机制检测并操纵这些(虚拟)设备

虚拟化平台由复用的和模拟的部件组合而成。复用是指配置硬件以使其可以直接被虚拟机使用，并在多个虚拟机间(空间上或时间上)共享。模拟是指向虚拟机提供选定的标准硬件部件的软件仿真。VMware Workstation将复用应用于处理器和内存，将模拟应用于其他设备

对于复用的设备，每个虚拟机都像是拥有独占CPU及从物理地址0开始的固定大小的连续RAM

将前端、后端分离还有一个好处:VMware虚拟机可以从一台计算机复制到另一台计算机，两台计算机的硬件可以不同。而且，虚拟机不必安装新的设备驱动程序,因为它只用与前端部件打交道。这个性质称作**硬件无关封装**，在服务器环境和云计算中有巨大的好处。它带来了后续的创新，如虚拟机暂停与恢复、检查点、热迁移等。在云中，允许客户在任意可用的服务器上部署他们的虚拟机，不用担心底层硬件的细节

4. 宿主操作系统的角色

最后一个要介绍的VMware Workstation的重要设计决策是将其部署到已有操作系统之上。这一特点将其归为第二类虚拟机管理程序。这个选择有两个主要好处

首先，这解决了外围设备多样性带来的另一部分挑战(虚拟硬件平台已解决了一部分挑战)。VMware实现了不同设备的前端模拟，但后端依赖宿主操作系统的设备驱动程序。例如，VMware Workstation读写宿主机文件系统上的文件来模拟虚拟磁盘设备，在宿主机的桌面上绘制一个窗口来模拟显示。只要宿主操作系统有合适的驱动程序，VMware Workstation就能在上面运行虚拟机

其次，产品能像普通应用程序那样安装使用，对用户而言更容易接受。与其他应用程序相同,VMware Workstation安装器将组成虚拟机管理程序的文件写入现有的宿主机文件系统，不会扰乱硬件配置(不用重新格式化磁盘、创建磁盘分区或修改BIOS设置)。事实上，VMware Workstation安装完成后不用重启宿主操作系统就能开始运行虚拟机

* VMware托管体系结构虚拟化软件被拆分成三个独立组成部分，这三个部分有不同的功能,彼此独立运行:	1. 用户可以察觉到的用户态VMware程序(VMX)：VMX执行所有UI功能，启动虚拟机，并执行大部分设备模拟(前端)，向宿主操作系统发起普通系统调用以完成后端交互。通常每个虚拟机对应一个多线程VMX进程

	2. 安装在宿主操作系统的内核态设备驱动程序(VMM驱动程序)：VMM驱动程序主要用于临时暂停整个宿主操作系统以允许VMM运行。宿主操作系统通常在启动时加载VMM驱动程序

	3. 包含复用CPU与内存所需全部软件的VMM,包括异常处理程序陷入并模拟处理程序、二进制翻译器、影子页表模块：VMM运行在内核态，但并非宿主操作系统的上下文中。也就是说，VMM不能直接依赖宿主操作系统提供的服务，但它同时也不受宿主操作系统规则的约束。每个虚拟机都有一个在虚拟机启动时创建的VMM实例

两个完全独立的系统级上下文(宿主操作系统上下文与VMM上下文)之间的切换称作**系统切换**。这个名称本身强调在切换后软件环境完全不同了，与操作系统实现的普通上下文切换形成对比。进程A和B的普通上下文切换交换了地址空间的用户部分，以及两个进程的寄存器，但许多关键系统资源没有变化。例如，所有进程的内核部分地址空间相同，异常处理程序也没变化。相比之下，系统切换改变了一切:整个地址空间，所有异常处理程序，特权寄存器等。宿主操作系统的内核地址空间只有运行在宿主操作系统上下文时才予以映射，切换到VMM下文之后就完全移除了，空出来的空间用于运行VMM和虚拟机。系统切换虽然听起来复杂，但是可以很高效地实现，只需要执行45条x86机器指令

### 7.12.6 VMware的第一类虚拟机管理程序ESX Server

由于没有宿主操作系统，VMware需要直面之前描述过的外围设备多样性和用户体验问题。对于外围设备多样性，VMware限制ESX Server只运行在著名且经过认证的服务器平台上，驱动程序已经包含在ESX Server里。对于用户体验，ESX Server要求用户在启动分区上安装新的系统镜像

虽然存在不足，但在这两方面的妥协对专门部署虚拟化的数据中心是合理的，数据中心里可能有上千台服务器部署了几千个虚拟机。今天通常将此类虚拟化部署称作私有云。在私有云里，ESX Server的体系结构在性能、伸缩性、可管理性、功能等方面提供了巨大优势。优势如下：

1. CPU调度器确保每个虚拟机公平地分享CPU(以避免饥饿)，还能让多处理器虚拟机的不同虚拟CPU同时调度运行

2. 内存管理器为伸缩性进行了优化，特别是当虚拟机需要的物理内存总量超过物理机实际内存大小时，还能保证虚拟机高效运行。为了实现这一目标，ESX Server首先引入了气球和虚拟机透明页共享

3. I/O子系统为性能进行了优化。虽然VMware Workstation和ESX Server通常共享相同的前端，但是后端完全不同。在VMware Workstation中，所有I/O流经宿主操作系统及其API，常常增加额外开销,特别是对网络和存储设备而言。而在ESX Server中，设备驱动程序直接运行在虚拟机管理程序里，不需要系统切换

4. 后端通常依赖宿主操作系统提供的抽象，例如VMware Workstation将虚拟机磁盘镜像保存为宿主操作系统上的普通文件(只是体积很大)。相比之下，ESX Server具有VMFS，文件系统专门为保存虚拟机镜像和保证高I/O吞吐率优化。这能极大地提升虚拟机的性能。例如，VMware在2011年演示过单一ESX Server每秒执行100万次磁盘操作

5. ESX Server中引入新功能很容易，即使该功能需要计算机中多个部件进行特定配置与密切协作。例如，ESX Server引入的VMotion，这是首个虚拟机热迁移解决方案，能将正在运行的虚拟机从一台运行ESX Server的机器迁移到另一台运行着ESX Server的机器。这项工作需要内存管理器、CPU调度器和网络栈的相互配合