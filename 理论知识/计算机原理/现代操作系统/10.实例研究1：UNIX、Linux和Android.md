- [10. 实例研究1：UNIX、Linux和Android](#10-实例研究1unixlinux和android)
	- [10.2 Linux简介](#102-linux简介)
		- [10.2.2 到Linux的接口](#1022-到linux的接口)
		- [10.2.5 内核结构](#1025-内核结构)
	- [10.3 Linux中的进程](#103-linux中的进程)
		- [10.3.1 基本概念](#1031-基本概念)
		- [10.3.2 Linux中进程管理相关的系统调用](#1032-linux中进程管理相关的系统调用)
		- [10.3.3 Linux中进程与线程的实现](#1033-linux中进程与线程的实现)
		- [10.3.4 Linux中的调度](#1034-linux中的调度)
		- [10.3.5 启动Linux系统](#1035-启动linux系统)
	- [10.4 Linux中的内存管理](#104-linux中的内存管理)
		- [10.4.1 基本概念](#1041-基本概念)
		- [10.4.3 Linux中内存管理的实现](#1043-linux中内存管理的实现)
		- [10.4.4 Linux中的分页](#1044-linux中的分页)
	- [10.5 Linux中的I/O系统](#105-linux中的io系统)
		- [10.5.1 基本概念](#1051-基本概念)
		- [10.5.2 网络](#1052-网络)
		- [10.5.4 I/O在linux中的实现](#1054-io在linux中的实现)
		- [10.5.5 Linux中的模块](#1055-linux中的模块)
	- [10.6 Linux文件系统](#106-linux文件系统)
		- [10.6.3 Linux文件系统的实现](#1063-linux文件系统的实现)
		- [10.6.4 NFS：网络文件系统](#1064-nfs网络文件系统)
	- [10.7 Linux的安全性](#107-linux的安全性)
		- [10.7.1 基本概念](#1071-基本概念)
		- [10.7.3 Linux中的安全实现](#1073-linux中的安全实现)
	- [10.8 Android](#108-android)
		- [10.8.1 Android与Google](#1081-android与google)
		- [10.8.3 设计目标](#1083-设计目标)
		- [10.8.4 Android体系结构](#1084-android体系结构)
		- [10.8.5 Linux扩展](#1085-linux扩展)
		- [10.8.6 Dalvik](#1086-dalvik)
		- [10.8.7 Binder IPC](#1087-binder-ipc)
		- [10.8.8 Android应用](#1088-android应用)
		- [10.8.9 意图](#1089-意图)
		- [10.8.10 应用程序沙箱](#10810-应用程序沙箱)
		- [10.8.11 安全性](#10811-安全性)
		- [10.8.12 进程模型](#10812-进程模型)
	- [10.9 小结](#109-小结)

# 10. 实例研究1：UNIX、Linux和Android

## 10.2 Linux简介

### 10.2.2 到Linux的接口

|Linux系统中的层次结构|
|:-:|
|用户|
|标准实用程序(shell、编辑器、编译器等)(用户态)|
|标准库函数(open、close、read、write、fork等)(用户态)|
|Linux操作系统(进程管理、存储管理、文件系统、I/O等)(内核态)|
|硬件(CPU、内存、磁盘、终端等)|

最底层的是**硬件**，包括CPU、内存、磁盘、显示器、键盘以及其他设备

运行在硬件之上的是**操作系统**。它的作用是控制硬件并且为其他程序提供系统调用接口。这些系统调用允许用户程序创立并管理进程、文件以及其他资源

程序通过把参数放入寄存器(有时是栈)来调用系统调用，并发出陷入指令从用户模式切换到内核模式。由于不能用C语言写一条陷入指令，因此系统提供了一个**库**，每个函数对应一个系统调用。这些函数是用汇编语言写的，不过可以从C中调用。每一个函数首先将参数放到合适的地方，然后执行陷阱命令。因此，为了执行read系统调用，一个C程序需要调用read库函数。值得一提的是，由POSIX(可移植操作系统接口)指定的是库接口,而不是系统调用接口。换句话说，POSIX规定哪些库函数是一个符合标准规范的系统必须提供的，它们的参数是什么，它们的功能是什么，以及它们返回什么样的结果。POSIX根本没有提到真正的系统调用

除了操作系统和系统调用库，所有版本的Linux必须提供大量的**标准程序**，其中一些是由POSIX1003.2标准指定的，其他的根据不同版本的Linux而有所不同。它们包括命令处理器(shell)、编译器、编辑器、文本处理程序以及文件操作工具。用户使用键盘调用的是上述这些程序。因此我们可以说Linux具有三种不同的接口:真正的系统调用接口、库函数接口和由标准应用程序构成的接口

### 10.2.5 内核结构

内核坐落在硬件之上,负责实现与I/O设备和存储管理单元的交互，并控制CPU对前述设备的访问。

* 在最底层，内核包含**中断处理程序**，它们是与设备交互的主要方式，以及底层的**分派机制**。这种分派在中断时发生。底层的代码中止正在运行的进程，将其状态存储在内核进程结构中，然后启动相应的驱动程序。进程分派也在内核完成某些操作，并且需要再次启动一个用户进程时发生。进程分派的代码是汇编代码，并且和进程调度代码有很大不同

* 接下来将内核子系统分为三个主要部件。
	* **I/O部件**包含所有负责与设备交互以及实现联网和存储的I/O功能的内核部件。在最高层，这些I/O功能全部整合在一个虚拟文件系统层中。也就是说，从顶层来看，对一个文件进行读操作，不论是在内存还是磁盘中，都和从终端输入中读取一个字符是一样的。从底层来看，所有的I/O操作都要通过某一个设备驱动器。所有的Linux驱动程序都可以被分类为**字符驱动程序**或**块驱动程序**，两者之间的主要区别是块设备允许查找和随机访问而字符设备不允许。从技术上讲，**网络设备**实际上是字符设备，不过它们的处理和其他字符设备不太一样。在设备驱动程序之上，每个设备类型的内核代码都不一样。
	* **字符设备**有两种不同的使用方式。有些程序，如可视编辑器vi,emacs等，需要每一个键盘输入。原始的终端(tty)I/O可以实现这种功能。其他程序，比如shell等，是面向行的，因此允许用户在输入回车并将字符串发送给程序之前整行地进行编辑。在这种情况下，由终端流出的字符流需要通过一个所谓的行规则，其中的内容被相应地格式化
		* **网络软件**通常是模块化的，由不同的设备和协议来支持。网络设备的上一个层次负责一种常规程序，确保每一个包被送到正确的设备或协议处理器。大多数Linux系统在内核中包含一个完整的硬件路由器的功能，尽管其性能比硬件路由器的性能差一些。在路由器代码之上的是实际的协议栈，它总是包含IP和TCP协议，也包含一些其他协议。在整个网络之上的是socket接口，它允许程序来为特定的网络和协议创建socket，并为每一个socket返回一个待用的文件描述符
		* 在磁盘驱动器之上是I/O调度器，它负责排序和分配磁盘读写操作,以尽可能减少磁头的无用移动或者满足一些其他的系统原则为方法。块设备列的最顶层是文件系统。Linux中可能有多个文件系统同时存在。为了向文件系统的实现隐藏不同硬件设备体系之间的区别，一个通用的块设备层提供了一个可以被所有文件系统使用的抽象

	* **内存管理部件**的任务包括维护虚拟内存到物理内存的映射,维护最近被访问页面的缓存以及实现一个好的页面置换算法，并且根据需要把需要的数据和代码页读入内存中。**进程管理部件**的最主要任务是进程的创建和终止。它还包括一个进程调度器，负责选择下一步运行哪个进程或线程。我们将在下一节看到，Linux把进程和线程简单地看作可运行的实体，并使用统一的调度策略对它们进行调度。最后,信号处理的代码也属于进程管理部件
	* 尽管这三个部件被分开描述,实际上它们高度相互依赖。文件系统一般通过块设备进行文件访问。然而为了隐藏磁盘读取的严重延迟，文件被复制到内存中的页缓存中。有些文件甚至可能是动态创建的并且只在内存中存在，比如提供运行时资源使用情况的文件。另外当需要清空一些页时，虚拟存储系统可能依靠一个磁盘分区或者文件内的交换区来备份内存的一部分，因此依赖于I/O部件。当然,还存在着很多其他的组件之间的相互依赖
	* 除了内核内的静态部件外，Linux支持动态可装载模块。这些模块可以用来补充或者替换缺省的设备驱动程序、文件系统、网络或者其他内核代码

* 处在最顶层的是到内核的系统调用接口。所有系统调用都来自这里，其触发一个陷入，并将系统从用户态转换到受保护的内核态，继而将控制权交给上述的内核部件之一

## 10.3 Linux中的进程

### 10.3.1 基本概念

在大多数单用户的工作站里，即使用户已经退出登录，仍然会有很多后台进程，即**守护进程**在运行。在系统启动的时候，这些守护进程就已经被shell脚本开启。计划任务是一个典型的守护进程。它每分钟运行一次来检查是否有工作需要它完成。如果有工作要做，它就会将之完成，然后进入休眠状态，直到下一次检查时刻来到

在Linux系统中，进程通过非常简单的方式**创建**。系统调用fork将会创建一个与原始进程完全相同的进程副本。调用fork函数的进程称为父进程，新的进程称为子进程。父进程和子进程都拥有自己的私有内存映像。如果在调用fork函数之后，父进程修改了属于它的一些变量，这些变化对于子进程来说是不可见的,反之亦然。但是父进程和子进程可以共享已经打开的文件。也就是说，如果某一个文件在父进程调用fork函数之前就已经打开了，那么在父进程调用fork函数之后，对于父进程和子进程来说，这个文件也是打开的。如果父、子进程中任何一个进程对这个文件进行了修改，那么对于另一个进程而言，这些修改都是可见的。这是唯一合理的做法，因为该文件的修改对其他无关进程也是可见的。fork系统调用给子进程返回一个零值，而给父进程返回一个非零值。这个非零值是子进程的**进程标识符(PID)**

**进程间通信**：

**管道**：Linux系统中的进程可以通过一种消息传递的方式进行通信。在两个进程之间，可以建立一个通道，一个进程向这个通道里写入字节流，另一个进程从这个通道中读取字节流。这些通道称为**管道**。管道是同步的，因为如果一个进程试图从一个空的管道中读取数据，这个进程就会被挂起直到管道中有可用的数据为止

**信号**：除了管道这种方式,进程还可以通过另一种方式通信:软中断。一个进程可以给另一个进程发送**信号**。进程可以告诉操作系统当信号到来时它们希望发生什么事件。相关的选择有忽略这个信号、抓取这个信号或者被信号杀死，终止进程是处理信号的默认操作。如果一个进程希望获取所有发送给它的信号,它就必须指定一个信号处理函数。当信号到达时,控制立即切换到信号处理函数。当信号处理函数结束并返回之后,控制像硬件I/O中断一样返回到陷入点处。一个进程只可以给它所在**进程组**中的其他进程发送信号，这个进程组包括它的父进程(以及远祖进程)、兄弟进程和子进程(以及后裔进程)。同时，一个进程可以利用系统调用给它所在的进程组中所有的成员发送信号。信号还可以用于其他用途。比如说，如果一个进程正在进行浮点运算，但是不慎除数为0，它就会得到一个SIGFPE信号(浮点运算异常信号)。POSIX系统定义了许多信号，很多Linux系统会有自己添加的额外信号，但是使用了这些信号的程序一般情况下将没有办法移植到Linux的其他版本或者UNIX系统上

### 10.3.2 Linux中进程管理相关的系统调用

如果一个进程退出但是它的父进程并没有在等待它，这个进程进入**僵死状态**。最后当父进程等待它时,这个进程才会结束

### 10.3.3 Linux中进程与线程的实现

Linux系统中每一个进程都有一个运行用户程序的用户模式。但是当它的某一个线程调用系统调用之后，进程会陷入内核模式并且运行在内核上下文中，它将使用不同的内存映射并且拥有对所有机器资源的访问权。它还是同一个线程，但是现在拥有更高的权限，同时拥有自己的内核堆栈以及内核程序计数器。这几点非常重要，因为一个系统调用可能会因为某些原因陷入阻塞态，比如说，等待一个磁盘操作的完成。这时程序计数器和寄存器内容会被保存下来使得不久之后线程可以在内核模式下继续运行

在Linux系统内核中，进程通过数据结构task_struct被表示成**任务**。不像其他的操作系统会区别进程、轻量级进程和线程,Linux系统用任务的数据结构来表示所有的执行上下文。所以一个单线程的进程只有一个任务数据结构，而一个多线程的进程将为每一个用户级线程分配一个任务数据结构。最后Linux的内核是多线程的，并且它所拥有的是与任何用户进程无关的内核级线程，这些内核级线程执行内核代码

对于每一个进程，一个类型为task_struct的进程描述符是始终存在于内存当中的。它包含了内核管理全部进程所需的重要信息，如调度参数、已打开的文件描述符列表等。进程描述符从进程被创建开始就一直存在于内核堆栈之中

为了与其他UNIX系统兼容，Linux还通过**进程标识符(PID**)来区分进程。内核将所有进程的任务数据结构组织成一个双向链表。不需要遍历这个链表来访问进程描述符，PID可以直接被映射成进程的任务数据结构所在的地址，从而立即访问进程的信息

任务数据结构包含非常多的分量。其中一些分量包含指向其他数据结构或段的指针，比如说包含关于已打开文件的信息。有些段只与进程用户级的数据结构有关，当用户进程没有运行的时候，它们是不被关注的。所以当不需要它们的时候，这些段可以被交换出去或重新分页以达到不浪费内存的目的。举个例子，尽管对于一个进程来说，当它被交换出去的时候，可能会有其他进程给它发送信号，但是这个进程本身却不会要求读取一个文件。正因为如此，关于信号的信息才必须永远保存在内存里，即使这个进程已经不在内存当中了。另一方面，关于文件描述符的信息可以被保存在用户级的数据结构里，当进程存在于内存当中并且可以执行的时候，这些信息才需要被调入内存

* 进程描述符的信息可以大致归纳为以下几大类：
	1. 调度参数：进程优先级，最近消耗的CPU时间，最近睡眠的时间。上面几项内容结合在一起决定了下一个要运行的进程是哪一个
	2. 内存映射：指向代码、数据、堆栈段或页表的指针。如果代码段是共享的，代码指针指向共享代码表。当进程不在内存当中时，关于如何在磁盘上找到这些数据的信息也被保存在这里
	3. 信号：掩码显示了哪些信号被忽略、哪些信号需要被捕捉、哪些信号被暂时阻塞以及哪些信号在传递当中
	4. 机器寄存器：当内核陷阱发生时，机器寄存器的内容(也包括被使用了的浮点寄存器的内容)会被保存
	5. 系统调用状态：关于当前系统调用的信息，包括参数和返回值
	6. 文件描述符表：当一个与文件描述符有关的系统调用被调用的时候，文件描述符作为索引在文件描述符表中定位相关文件的i节点数据结构
	7. 统计数据：指向记录用户、进程占用系统CPU时间的表的指针。一些系统还保存一个进程最多可以占用CPU的时间、进程可以拥有的最大堆栈空间、进程可以消耗的页面数等
	8. 内核堆栈：进程的内核部分可以使用的固定堆栈
	9. 其他：当前进程状态。如果有的话，包括正在等待的事件、距离警报时钟超时的时间、PID、父进程的PID以及其他用户标识符、组标识符等

理论上在fork之后就应该为子进程的数据段、堆栈段分配内存，并且对父进程的段进行复制，因为fork函数意味着父、子进程之间不共享内存。其中如果代码段是只读的，可以复制也可以共享。然后子进程就可以运行了。但是复制内存的代价相当昂贵，所以现代Linux系统都使用了"欺骗"的手段来代替。它们赋予子进程属于它的页表，但是这些页表都指向父进程的页面，同时把这些页面标记成只读。当进程(可以是子进程或父进程)试图向某一页面中写入数据的时候，它会收到写保护的错误。内核发现进程的写入行为之后，会为进程分配一个该页面的新副本，并将这个副本标记为可读、可写。通过这种方式，使得只有需要写入数据的页面才会被复制。这种机制叫作**写时复制**。它所带来的额外好处是，不需要在内存中维护同一个程序的两个副本，从而节省了RAM5

从历史观点上说，进程是资源容器，而线程是执行单元。一个进程包含一个或多个线程，线程之间共享地址空间、已打开的文件、信号处理函数、警报信号和其他。2000年的时候，Linux系统引入了一个新的、强大的系统调用clone模糊了进程和线程的区别,甚至使得两个概念的重要性被倒置。任何其他UNIX系统的版本中都没有clone函数。传统观念上，当一个新线程被创建的时候，之前的线程和新线程共享除了寄存器内容之外的所有信息。特别是，已打开文件的文件描述符、信号处理函数、定时器信号和其他每个进程(不是每个线程)都具有的全局属性

Linux系统的线程模型带来了另一个难题。UNIX系统为每一个进程分配一个独立的PID，不论它是单线程的进程还是多线程的进程。为了能与其他的UNIX系统兼容，Linux对进程标识符(PID)和任务标识符(TID)进行了区分。这两个分量都存储在任务数据结构中。当调用clone函数创建一个新进程而不需要和旧进程共享任何信息时，PID被设置成一个新值；否则任务得到一个新的任务标识符，但是PID不变。这样一来，一个进程中所有的线程都会拥有与该进程中第一个线程相同的PID

### 10.3.4 Linux中的调度

1. Linux系统的线程是内核线程，所以Linux系统的调度是基于线程的,而不是基于进程的。为了进行调度，Linux系统将线程区分为三类：1.实时先入先出；2.实时轮转；3.分时

* **实时先入先出线程**具有最高优先级，它不会被其他线程抢占，除非那是一个刚刚准备好的、拥有更高优先级的实时先入先出线程

* **实时轮转线程**与实时先入先出线程基本相同，只是每个实时轮转线程都有一个时间量，时间到了之后就可以被抢占。如果多个实时轮转线程都准备好了，每一个线程运行它的时间量所规定的时间，然后插入到实时轮转线程列表的末尾。事实上，这两类线程都不是真正的实时线程。执行的最后期限无法确定，更无法保证最后期限前线程可以执行完毕。这两类线程比起分时线程来说只是具有更高的优先级而已。Linux系统之所以称它们为"是因为Linux系统遵循的P1003.4标准使用了这个名称。在系统内部，实时线程的优先级从0到99，0是实时线程的最高优先级，99是实时线程的最低优先级

* 传统的**非实时线程**形成单独的类并由单独的算法进行调度，这样可以使非实时线程不与实时线程竞争资源。在系统内部，这些线程的优先级从100到139，也就是说，Linux系统包含140个不同的优先级(包括实时和非实时任务)。就像实时轮转线程一样，Linux系统根据非实时线程的要求以及它们的优先级分配CPU时间片

2. 接下来讨论Linux系统的两个调度算法。它们的内部与**调度队列**的设计密切相关，该调度队列是一个关键的数据结构，可以通过调度器来跟踪系统中的所有可运行的任务，并选择下一个要运行的任务进行调度。调度队列与系统中的每一个CPU都相关

* **Linux O(1)调度器**： 是历史上一个流行的Linux系统调度程序。命名为这个名字是因为它能够在常数时间内执行任务调度，例如从执行队列中选择一个任务或将一个任务加入执行队列,这与系统中的任务总数无关。在O(1)调度器里，调度队列被组织成两个数组，一个是任务**正在活动**的数组，一个是任务**过期失效**的数组。每个数组都包含了140个链表头，每个链表具有不同的优先级。链表头指向给定优先级的双向进程链表
	* **基本操作**：调度器从正在活动数组中选择一个优先级最高的任务。如果这个任务的时间片(时间量)过期失效了，就把它移动到过期失效数组中(可能会插入到优先级不同的列表中)。如果这个任务阻塞了，比如说正在等待I/O事件，那么在它的时间片过期失效之前，一旦所等待的事件发生，任务就可以继续运行，它将被放回到之前正在活动的数组中，时间片根据它所消耗的CPU时间相应的减少。一旦它的时间片消耗殆尽，它也会被放到过期失效数组中。当正在活动数组中没有其他的任务了，调度器交换指针，使得正在活动数组变为过期失效数组，过期失效数组变为正在活动数组。这种方法可以保证低优先级的任务不会被饿死(除非实时先入先出线程完全占用CPU，但是这种情况是不会发生的)
	* **时间片分配**：不同的优先级被赋予不同的时间片长度，高优先级的进程拥有较长的时间片
	* **思想**：为了使进程更快地出入内核。如果一个进程试图读取一个磁盘文件，在调用read函数之间等待一秒钟的时间显然会极大地降低进程的效率。每个请求完成之后让进程立即运行的做法会好得多，同时这样做也可以使下一个请求更快完成。相似地，如果一个进程因为等待键盘输入而阻塞，那么它明显是一个交互进程，这样的进程只要准备好运行后就应当被赋予较高的优先级，从而保证交互进程可以提供较好的服务。在这种情况下，当II/O密集型进程和交互进程被阻塞之后，CPU密集型进程基本上可以得到所有被留下的服务
	* **优先级分配**：由于Linux系统(或其他任何操作系统)事先不知道一个任务究竟是I/O密集型的，还是CPU密集的,它只是依赖于连续保持的交互启发式方法。通过这种方式,Linux系统区分静态优先级和动态优先级。线程的动态优先级不断地被重新计算，其目的在于:奖励互动进程并惩罚占用CPU的进程。在Linux O(1)调度器中，最高的优先级奖励是-5，是从调度器接收的与更高优先级相对应的较低优先级的值。最高的优先级惩罚是+5。调度器给每一个任务维护一个名为sleep_avg的变量。每当任务被唤醒时，这个变量会增加;当任务被抢占或时间量过期时，这个变量会相应地减少。减少的值用来动态生成优先级奖励，奖励的范围从-5到+5。当一个线程从正在活动数组移动到过期失效数组中时，调度器会重新计算它的优先级
	* **缺点**：O(1)调度算法指的是2.6内核版本中所流行的调度器，最初引入这个调度算法的是不稳定的2.5版本内核。早期的调度算法在多处理器环境中所表现的性能十分低下，并且当任务的数量大量增长时，不能很好地进行调度。由于上面描述的内容说明了通过访问正在活动数组就可以做出调度决定，那么调度可以在一个固定的时间O(1)内完成，而与系统中进程的数量无关。然而除了常数时间操作表现出的高性能之外，O(1)调度器有显著的缺点。最值得注意的是，利用启发式方法来确定一个任务的交互性，会使该任务的优先级复杂且不完善，从而导致在处理交互任务时性能很糟糕

* **完全公平调度器(CFS)**：CFS借鉴Con Kolivas最初为一个早期的调度器所设计的思路，并在2.6.23版本中首次被集成到内核中。它仍然是处理非实时任务的默认调度器
	* **主要思想**：使用一棵红黑树作为调度队列的数据结构。根据任务在CPU上运行的时间长短而将其有序地排列在树中，这种时间称为虚拟运行时间。CFS采用ns级的粒度来说明任务的运行时间。树中的每个内部节点对应于一个任务。左侧的子节点对应于在CPU上运行时间更少的任务，因此左侧的任务会更早地被调度，右侧的子节点是那些迄今消耗CPU时间较多的任务，叶子节点在调度器中不起任何作用
	* **基本操作**：该算法总是优先调度那些使用CPU时间最少的任务，通常是在树中最左边节点上的任务。CFS会周期性地根据任务已经运行的时间，递增它的虚拟运行时间值，并将这个值与树中当前最左节点的值进行比较，如果正在运行的任务仍具有较小虚拟运行时间值，那么它将继续运行，否则，它将被插入红黑树的适当位置，并且CPU将执行新的最左边节点上的任务
	* **优先级**：考虑到任务有优先级的差异和"友好程度"，因而当一个任务在CPU上运行时，CFS会改变该任务的虚拟运行时间流逝的有效速率。对于优先级较低的任务，时间流逝更快，它的虚拟运行时间值也将增加得更快，考虑到系统中还有其他任务，因此有较低的优先级的任务会失去CPU的使用权，相较于优先级高的任务更快地重新插入树中。以这种方式，CFS可避免使用不同的调度队列结构来放置不同优先级的任务
	* **缺点**：选择一个树中的节点来运行的操作可以在常数时间内完成，然而在调度队列中插入一个任务需要O(log(N))的时间，其中N是系统中的任务数。考虑到当前系统的负载水平，这仍然是可以接受的,但随着节点计算能力以及它们所能运行的任务数的增加，尤其是在服务器领域，未来可能会有新的调度算法被提出

除了基本的任务调度算法外，Linux的调度器还包含了对于**多处理器和多核平台**而言非常有益的特性。首先，在多处理器平台上，每一个运行队列数据结构与一个处理器相对应，调度器尽量进行亲和调度，即将之前在某个处理器上运行过的任务再次调入该处理器。其次，为了更好地描述或修改一个选定的线程对亲和性的要求，有一组系统调用可供使用。最后，在满足特定性能和亲和要求的前提下，调度器实现在不同处理器上阶段性的加载平衡，从而保证整个系统的加载是平衡的

调度器只考虑可以运行的任务，这些任务被放在适当的调度队列当中。不可运行的任务和正在等待各种I/O操作或内核事件的任务被放入另一个数据结构当中，即**等待队列**。每一种任务可能需要等待的事件对应了一个等待队列。等待队列的头包含一个指向任务链表的指针及一枚自旋锁。为了保证等待队列可以在主内核代码、中断处理函数或其他异步处理请求代码中进行并发操作，自旋锁是非常必要的

3. Linux系统中的同步

上一节中提到Linux系统使用自旋锁来防止对数据结构的并发修改，比如等待队列。事实上，内核代码在很多地方都含有同步变量。后面会简要总结一下Linux系统所实现的同步机制

早期的Linux内核只有一个**大内核锁**。由于它阻止了不同的处理器并发运行内核代码，因此使得内核的效率非常低下，特别是在多处理器平台上。所以，很多新的同步点被更加细粒度地引入了

Linux提供了若干不同类型的同步变量，这些变量既能在内核里面使用，也提供给用户级应用程序和库使用。在最底层，Linux系统通过像atomic_set和atomic_read这样的操作为硬件支持的原子指令提供了封装。此外，现代的硬件重新排序了内存操作，这样Linux就提供了内存屏障。使用像rmb和wmb这样的操作保证了所有领先于屏障调用的读/写存储器操作在任何后续的访问发生之前就已经完成

具有较高级别的同步构造更为常用。不想被阻止(考虑到性能或正确性)的线程使用自旋锁并旋转读/写锁。当前的Linux版本实现了所谓的"基于门票"自旋锁它在SMP和多核系统上具有优秀的表现。被允许或需要阻塞的线程可使用像互斥量和信号量这样的机制。Linux支持像mutex_trylock和sem trywait这样的非阻塞调用，用于在无需阻塞下判断同步变量的状态。Linux也支持其他的同步变量，如futexes、completions,read-copy-update(RCU)锁等。最后，对于内核以及由中断处理事务所执行的代码之间的同步，可以通过动态地禁用和启用相应的中断来实现

### 10.3.5 启动Linux系统

每个平台的细节都有不同，但是整体来说，下面的步骤代表了启动的过程

当计算机启动时,BIOS加电自检(POST)，并对硬件进行检测和初始化，这是因为操作系统的启动过程可能会依赖于磁盘访问、屏幕、键盘等。接下来，启动磁盘的第一个扇区，即**主引导记录(MBR)**，被读入到一个固定的内存区域并且执行。这个分区中含有一个很小的程序(只有512字节)，这个程序从启动设备中，比如SATA磁盘或SCSI磁盘，调入一个名为**boot**的独立程序。boot程序将自身复制到高地址的内存当中从而为操作系统释放低地址的内存

复制完成后，boot程序读取启动设备的根目录。为了达到这个目的,boot程序必须能够理解文件系统和目录格式，这个工作通常由引导程序，如**GRUB(多系统启动管理器**)来完成。其他流行的引导程序，如Intel的LILO，不依赖于任何特定的文件系统。相反，它们需要一个块映射图和低层地址，它们描述了物理扇区、磁头和磁道，可以帮助找到相应的需要被加载的扇区

然后boot程序读入操作系统内核，并把控制交给内核。从这里开始，boot程序完成了它的任务，系统内核开始运行

内核的启动代码是用汇编语言写成的，具有较高的机器依赖性。主要的工作包括创建内核堆栈、识别CPU类型、计算可用内存、禁用中断、启用内存管理单元，最后调用C语言写成的main函数开始执行操作系统的主要部分

C语言代码也有相当多的初始化工作要做，但是这些工作更逻辑化(而不是物理化)。C语言代码开始的时候会分配一个消息缓冲区来帮助调试启动出现的问题。随着初始化工作的进行，信息被写入消息缓冲区，这些信息与当前正在发生的事件相关，所以如果出现启动失败的情况，这些信息可以通过一个特殊的诊断程序调出来

接下来，内核数据结构得到分配。大部分内核数据结构的大小是固定的，但是一少部分，如页面缓存和特殊的页表结构，依赖于可用内存的大小

从这里开始，系统进行自动配置。使用描述何种设备可能存在配置文件，系统开始探测哪些设备是确实存在的。如果一个被探测的设备给出了响应，这个设备就会被加入到已连接设备表中。如果它没有响应，就假设它未连接或直接忽略掉它。不同于传统的UNIX版本,Linux系统的设备驱动程序不需要被静态链接至内核中，它们可以被动态加载(就像所有的MS-DOS和Windows版本一样)

**动态加载驱动程序优点**：同样的二进制文件可以分发给具有不同系统配置的用户，这个二进制文件可以自动加载它所需要的驱动程序，甚至可以通过网络加载。**动态加载驱动程序缺点**：安全。如果正在一个安全的环境中运行计算机，比如说银行的数据库系统或者公司的网络服务器，那肯定不希望其他人向内核中插入随机代码。系统管理员可以在一个安全的机器上保存系统的源文件和目标文件，在这台机器上完成系统的编译链接,然后通过局域网把内核的二进制文件分发给其他的机器。如果驱动程序不能被动态加载，这就阻止了那些知道超级用户密码的计算机使用者或其他人向系统内核注入恶意或漏洞代码。而且在大的站点中,系统编译链接的时候硬件配置都是已知的。需要重新链接系统的变化非常罕见，即使是在系统中添加一个硬件设备也不是问题

一旦所有的硬件都配置好了，接下来要做的事情就是细心地手动运行进程0，建立它的堆栈，运行它。进程0继续进行初始化，做如下的工作:配置实时时钟,挂载根文件系统，创建init进程(进程1)和页面守护进程(进程2)

init进程检测它的标志以确定它应该为单用户还是多用户服务。前一种情况，它调用fork函数创建一个shell进程，并且等待这个进程结束。后一种情况，它调用fork函数创建一个运行系统初始化shell脚本(即/etc/rc)的进程,这个进程可以进行文件系统一致性检测、挂载附加文件系统、开启守护进程等。然后这个进程从/etc/ttys中读取数据，其中/etc/ttys列出了所有的终端和它们的属性。对于每一个启用的终端，这个进程调用fork函数创建一个自身的副本，进行内部处理并运行一个名为getty的程序

getty程序为每条连线设置传输速率和其他属性(比如，有一些可能是调制解调器)，然后在终端的屏幕上输出:`login:`，等待用户从键盘键入用户名。当有人坐在终端前，提供了一个用户名后，getty程序就结束了，登录程序/bin/login开始运行。login程序要求输入密码，给密码加密，并与保存在密码文件/etc/passwd中的加密密码进行对比。如果是正确的，login程序以用户shell程序替换自身，等待第一个命令。如果是不正确的，login程序要求输入另一个用户名

## 10.4 Linux中的内存管理

### 10.4.1 基本概念

|进程地址空间|备注|
|:-:|:-:|
|与进程相关的数据结构(例如页表、task和mm结构，内核栈)|对每个进程都不相同|
|物理内存|对每个进程都相同|
|内核代码和数据|对每个进程都相同|
||以上为内核虚拟内存，以下为进程虚拟内存|
|用户栈(运行时创建)↓|
||
|%esp(栈指针)|
|共享库的内存映射区域↑|
||
|←brk|
|运行时堆(由malloc创建)↑|
||未初始化数据(.bss)|从可执行文件中加载|
|已初始化数据(.data)|从可执行文件中加载|
|只读代码段(.init，.text，.rodata)|从可执行文件中加载|
||0x0040 0000|
||0|

每个Linux进程都有一个地址空间，逻辑上有三段组成:代码、数据和堆栈段。

**只读代码段**包含了形成程序可执行代码的机器指令。它是由编译器和汇编器把C、C++或者其他程序源码转换成机器代码而产生的。通常，代码段是只读的。由于难以理解和调试,自修改程序早在大约1950年就不再时兴了。因此,代码段既不增长也不减少,总之不会发生改变。当两个用户运行同样的程序，比如编辑器，可以在内存中立刻保持该编辑器程序代码的两个副本，但是并不高效。相反地，大多数Linux系统支持**共享代码段**。多个进程共享了同样的代码片段。这种映射是通过虚拟内存硬件来实现的

**数据段**包含了所有程序变量、字符串、数字和其他数据的存储。它有两部分，已初始化数据(.data)和未初始化数据(.bss)。跟代码段不一样，数据段可以改变。程序总是修改它的变量。而且许多程序需要在执行时动态分配空间。Linux允许数据段随着内存的分配和回收而增长和缩减，通过这种机制来解决动态分配的问题。有一个系统调用brk，允许程序设置其数据段的大小。那么为了分配更多的内存，一个程序可以增加数据段的大小。C库函数malloc通常被用来分配内存，它就大量使用这个系统调用。进程地址空间描述符包含信息：**进程动态分配的内存空间(堆**)的范围

**已初始化数据(.data)** 包括编译器常量和那些在程序启动时就需要一个初始值的变量。所有BSS部分中的变量在加载后被初始化为0。例如，在C语言中可以在声明一个字符串的同时初始化它。当程序启动的时候，字符串要拥有其初始值。为了实现这种构造，编译器在地址空间给字符串分配一个位置，同时保证在程序启动的时候该位置包含了合适的字符串。从操作系统的角度来看，初始化数据跟程序代码并没有什么不同---二者都包含了由编译器产出的位串，它们必须在程序启动的时候加载到内存

**未初始化数据(.bss)** 的存在实际上仅仅是个优化。如果一个全局变量未显式地初始化，那么C语言的语义说明它的初始值是0。实际上,大部分全局变量并没有显式初始化,因此都是0。这些可以简单地通过设置可执行文件的一个段来实现，其大小刚好等于数据所需的字节数,同时初始化包括缺省值为零的所有量。然而，为了节省可执行文件的空间，并没有这样做。取而代之的是，跟随在程序代码之后，文件包含所有显式初始化的变量。那些未初始化的变量都被收集在初始化数据之后，因此编译器要做的就是在文件头部放入一个字段说明要分配的字节数。例如代码段的大小是8KB，初始化数据段的大小也是8KB。未初始化数据(BSS)是4KB。可执行文件仅有16KB(代码＋初始化数据)，加上一个很短的头部来告诉系统在初始化数据后另外再分配4KB，同时在程序启动之前把它们初始化为0。这个技巧避免了在可执行文件中存储4KB的0。为了避免分配一个全是0的物理页框，在初始化的时候，Linux就分配了一个静态零页面，即一个全0的写保护页面。当加载程序的时候，未初始化数据区域被设置为指向该零页面。当一个进程真正要写这个区域的时候，写时复制的机制就开始起作用，一个实际的页框被分配给该进程

第三段是**栈段**。在大多数机器里，它从虚拟地址空间的顶部或者附近开始，并且向低地址空间延伸。例如在32位x86平台上，栈的起始地址是0xC0000000，这是在用户态下对进程可见的3GB虚拟地址限制。如果栈生长到了栈段的底部以下，就会产出一个硬件错误同时操作系统把栈段的底部降低一个页面。程序并不显式地控制栈段的大小。当一个程序启动的时候，它的栈并不是空的。相反它包含了所有的环境变量以及为了调用它而向shell输入的命令行。这样一个程序就可以发现它的参数了

数据段和栈段从来不共享，除非是同一个父进程下的子进程，并且仅仅是那些没有被修改的页面。如果二者之一要增长但是没有邻近的空间来增长，这并不会产生问题，因为在虚拟地址空间中邻近的页面并不一定要映射到邻近的物理页面上

在有些计算机上，硬件支持指令和数据拥有不同的地址空间。如果有这个特性，Linux就可以利用它。例如在一个32位地址的计算机上如果有这个特性，那么就有22字节的指令地址空间和22字节的数据地址空间。一条跳转到地址0的指令跳入到代码段的地址0，而一条从地址0取数据的move指令使用数据空间的地址0。这使得可用的数据空间加倍

除了动态分配更多的内存，Linux中的进程可以通过**内存映射文件**来访问文件数据。这个特性使我们可以把一个文件映射到进程空间的一部分而该文件就可以像位于内存中的字节数组一样被读写。把一个文件映射进来使得随机读写比使用read和write之类的I/O系统调用要容易得多。共享库的访问就是用这种机制映射进来后进行的。一个文件可以被同时映射到两个进程中，但在不同的虚拟地址上。把一个文件映射进来的一个附加的好处是两个或者更多的进程可以同时映射相同的文件。其中一个进程对文件的写可以被其他进程马上看到。实际上通过映射一个临时文件(所有的进程退出之后就被丢弃)，这种机制可以为多进程共享内存提供高带宽。在最极限的情况下，两个(或者更多)进程可以映射一个文件覆盖整个地址空间，从而提供了一种不同进程之间和线程之间的共享方式。这样地址空间是共享的(类似于线程)，但是每个进程维护其自身的打开文件和信号，这些不同于线程。实际上，从来没有两个完全相同的地址空间

### 10.4.3 Linux中内存管理的实现

32位机器上的每个Linux进程通常有3GB的虚拟地址空间，还有1GB留给其页表和其他内核数据。在用户态下运行时，内核的1GB是不可见的，但是当进程陷入到内核时是可以访问的。内核内存通常驻留在低端物理内存中，但是被映射到每个进程虚拟地址空间顶部的1GB中，在地址0xC0000000和OxFFFFFFFF(3~4GB)之间。在目前的64位x86机器上，最多只有48位用于寻址，这意味着寻址存储器的大小的理论极限值为256TB。Linux区分内核和用户空间之间的内存，从而导致每个进程最大的虚拟地址空间为128TB。当进程创建的时候，进程地址空间被创建，并且当发生一个exec系统调用时被重写

为了允许多个进程共享物理内存，Linux监视物理内存的使用，在用户进程或者内核构件需要时分配更多的内存，把物理内存动态映射到不同进程的地址空间中去，把程序的可执行体、文件和其他状态信息移入移出内存来高效地利用平台资源并且保障程序执行的进展性。接下来描述在Linux内核中负责这些操作的各种机制的实现

1. 物理内存管理

Linux的内存由三部分组成。前两部分是**内核**和**内存映射**，被**固定**在内存中(页面从来不换出)。内存的其他部分被划分成页框，每一个页框都可以包含一个代码、数据或者栈页面，一个页表页面，或者在空闲列表中

内核维护内存的一个映射，该映射包含了所有系统物理内存使用情况的信息，比如区域、空闲页框等。这些信息是如下组织的

首先，Linux维护一个**页描述符**数组，称为mem_map，其中页描述符是page类型的，而且系统当中的每个物理页框都有一个页描述符。每个页描述符都有个指针，在页面非空闲时指向它所属的地址空间,另有一对指针可以使得它跟其他描述符形成双向链表，来记录所有的空闲页框和一些其他的域。页描述符的大小是32字节，因此整个mem_map消耗了不到1%的物理内存(对于4KB的页框)

因为物理内存被分成区域，所以Linux为每个区域维护一个**区域描述符**。区域描述符包含了每个区域中内存利用情况的信息，例如活动和非活动页的数目，页面置换算法(本章后面介绍)所使用的高低水印位,还有许多其他相关信息等

此外，区域描述符包含一个空闲区数组。该数组中的第i个元素标记了$2^i$个空闲页的第一个块的第一个页描述符。既然可能有多块$2^i$个空闲页，Linux使用页描述符的指针对把这些页面链接起来。这个信息在Linux的内存分配操作中使用。

最后，由于Linux可以移植到NUMA体系结构(不同的内存地址有不同的访问时间)，Linux使用节点描述符来区分不同节点上的物理内存(同时避免跨节点分配数据结构)。每个节点描述符包含内存使用的信息和这个特定节点的区域信息。在UMA平台上,Linux用一个节点描述符记录所有的内存的使用情况。每个页描述符的最初一些位是用来指定该页框所属的节点和区域的

为了使分页机制在32位和64位体系结构下都能高效工作，Linux采用了一个四级分页策略。每个虚拟地址划分成五个域：全局页目录、上级页目录、中间页目录、页表和页面。目录域是页目录的索引，每个进程都有一个私有的页目录。找到的值是指向其中一个下一级目录的一个指针，该目录也可以从虚拟地址进行索引。中级页目录表中的表项指向最终的页表，它是由虚拟地址的页表域索引的。页表的表项指向所需要的页面。在Pentium处理器(使用两级分页)上，每个页的上级和中级目录仅有一个表项，因此总目录项就可以有效地选择要使用的页表。类似地，在需要的时候可以使用三级分页，此时把上级目录域的大小设置为0就可以了

物理内存可以用于多种目的。内核自身是完全"硬连线"的，它的任何一部分都不会换出。内存的其余部分可以作为用户页面、分页缓存和其他目的。页面缓存保存最近已读的或者由于未来有可能使用而预读的文件块，或者需要写回磁盘的文件块页面，例如那些被换出到磁盘的用户进程创建的页面。用户进行操作时随时变化的页面共同竞争页面缓存这个有限的空间。分页缓存并不是一个独立的缓存，而是那些不再需要的或者等待换出的用户页面集合。如果分页缓存当中的一个页面在被换出内存之前复用,它可以被快速收回

此外，Linux支持动态加载模块，最常见的是设备驱动。它们可以是任意大小的并且必须被分配一片连续的内核内存。这些需求的一个直接结果是，Linux用这样一种方式来管理物理内存使得它可以随意分配任意大小的内存片。它使用的算法就是伙伴算法，下面给予描述

2. 内存分配机制

Linux支持多种内存分配机制

* 分配物理内存页框的主要机制是**页面分配器**，它使用了**伙伴算法**
	* **伙伴算法是分离适配的一种特例，其中每个大小类都是2的幂**：
	* **基本思路**是假设一个堆的大小为$2^m$个字，我们为每个块大小$2^k$维护一个分离空闲链表，其中0≤k≤m。请求块大小向上舍入到最接近的2的幂。最开始时，只有一个大小为$2^m$个字的空闲块。为了分配一个大小为2的块，我们找到第一个可用的、大小为$2^j$的块，其中k≤j≤m。如果j=k，那么我们就完成了。否则，我们递归地二分割这个块，直到j=k。当我们进行这样的分割时，每个剩下的半块(也叫做伙伴)被放置在相应的空闲链表中。要释放一个大小为2的块，我们继续合并空闲的伙伴。当遇到一个已分配的伙伴时，我们就停止合并。关于伙伴算法的一个**关键事实**是，给定地址和块的大小，很容易计算出它的伙伴的地址。例如，一个块,大小为32字节,地址为:`xxx...x0 0000`，它的伙伴的地址为`xxx...x1 0000`。换句话说，一个块的地址和它的伙伴的地址只有一位不相同
	* 伙伴算法分配器的主要**优点**是它的快速搜索和快速合并。主要**缺点**是要求块大小为2的幂可能导致显著的内部碎片。因此，伙伴算法分配器不适合通用目的的工作负载。然而，对于某些特定应用的工作负载，其中块大小预先知道是2的幂，伙伴算法分配器就很有吸引力了

* 为了缓解内部碎片的问题，Linux有另一个内存分配器，**slab分配器**。它使用伙伴算法获得内存块，但是之后从其中切出slab(更小的单元)并且分别进行管理。因为内核频繁地创建和撤销一定类型的对象(如task_struct)，它使用了对象缓存。这些缓存由指向一个或多个slab的指针组成，而slab可以存储大量相同类型的对象。每个slab要么是满的，要么是部分满的,要么是空的。例如，当内核需要分配一个新的进程描述符(一个新的task_struct)的时候，它在task结构的对象缓存中寻找，首先试图找一个部分满的slab并且在那里分配一个新的task_struct对象。如果没有这样的slab可用，就在空闲slab列表中查找。最后如果必要，它会分配一个新的slab，把新的task结构放在那里，同时把该slab连接到task结构对象缓存中。在内核地址空间分配连续的内存区域的kmalloc内核服务,实际上就是建立在slab和对象缓存接口之上的

* 第三个内存分配器vmalloc也是可用的，并且用于那些仅仅需要连续虚拟地址空间的请求，在物理内存中它并不适用。实际上，这一点对于大部分内存分配是成立的。一个例外是设备，它位于内存总线和内存管理单元的另一端，因此并不理解虚拟地址。然而，由于vmalloc的使用导致一些性能的损失，因此它主要被用于分配大量连续虚拟地址空间，例如动态插入内核模块。所有这些内存分配器都是继承自System V中的那些分配器

3. 虚拟地址空间表示

虚拟地址空间被分割成同构连续页面对齐的区域。也就是说，每个区域由一系列连续的具有相同保护和分页属性的页面组成。代码段和映射文件就是区(area)的例子。在虚拟地址空间的区之间可以有空隙。所有对这些空隙的引用都会导致一个严重的页面故障，页大小是确定的

在内核中，每个区是用vm_area_struct项来描述的。一个进程的所有vm_area_struct用一个链表链接在一起，并且按照虚拟地址排序以便可以找到所有的页面。当这个链表太长时(多于32项)，就创建一个树来加速搜索。vm_area_struct项列出了该区的属性。这些属性包括:保护模式(如，只读或者可读可写)、是否固定在内存中(不可换出)、朝向哪个方向生长(数据段向上长，栈段向下长)

vm_area_struct也记录该区是私有的还是跟一个或多个其他进程共享的。fork之后,Linux为子进程复制一份区链表，但是让父子进程指向相同的页表。区被标记为可读/可写，但是页面自己却被标记为只读。如果任何一个进程试图写页面，就会产生一个保护故障，此时内核发现该内存区逻辑上是可写的,但是页面却不是可写入的，因此它把该页面的一个副本给当前进程同时标记为可读可写。这个机制就明了写时复制是如何实现的。

vm_area_struct也记录该区是否在磁盘上有备份存储，如果有，在什么地方。代码段把可执行二进制文件作为备份存储,内存映射文件把磁盘文件作为备份存储。其他区(如栈)直到它们不得不被换出,否则没有备份存储被分配

一个顶层内存描述符mm_struct收集属于一个地址空间的所有虚拟内存区相关的信息，还有关于不同段(代码，数据，楼)和用户共享地址空间的信息等。一个地址空间的所有vm_area_struct元素可以通过内存描述符用两种方式访问。首先它们是按照虚拟地址顺序组织在链表中的。这种方式的有用之处是:当所有的虚拟地址区需要被访问时,或者当内核查找分配一个指定大小的虚拟内存区域时。此外,vm_area_struct项目被组织成二叉红黑树。这种方法用于访问一个指定的虚拟内存地址。为了能够用这两种方法访问进程地址空间的元素，Linux为每个进程使用了更多的状态，但是却允许不同的内核操作来使用这些访问方法，这对进程而言更加高效

### 10.4.4 Linux中的分页

早期的UNIX系统，每当所有的活动进程不能容纳在物理内存中时就用一个**交换进程**在内存和磁盘之间移动整个进程。Linux跟其他现代UNIX版本一样，不再移动整个进程了。内存管理单元是一个页,并且几乎所有的内存管理部件以页为操作粒度。交换子系统也是以页为操作粒度的，并且跟页框回收算法紧耦合在一起。这个后面会给予描述

Linux分页背后的**基本思想**是简单的:为了运行，一个进程并不需要完全在内存中。实际上所需要的是用户结构和页表。如果这些被换进内存，那么进程被认为是"在内存中"，可以被调度运行了。代码、数据和栈段的页面是动态载入的，仅仅是在它们被引用的时候。如果用户结构和页表不在内存中，直到交换器把它们载入内存进程才能运行

分页是一部分由内核实现而一部分由一个新的进程---**页面守护进程**实现的。页面守护进程是进程2(进程0是idle进程，传统上称为交换器，而进程1是init)。跟所有守护进程一样，页面守护进程周期性地运行。一旦唤醒，它主动查找是否有工作要干。如果它发现空闲页面数量太少，就开始释放更多的页面

Linux是一个请求换页系统，没有预分页和工作集的概念(不过存在一个系统调用，其中用户可以给系统一个提示将要使用某个页面，希望需要的时候页面在内存中)。代码段和映射文件换页到它们各自在磁盘上的文件中。所有其他的都被换页到分页分区(如果存在)或者一个固定长度的分页文件，叫作**交换区**。分页文件可以被动态地添加或者删除，并且每个都有一个优先级。换页到一个独立的分区并且像一个原始设备那样访问的这种方式要比换页到一个文件的方式更加高效。之所以这么说是有多重原因的:首先,文件块和磁盘块的映射不需要了(节省了磁盘I/O读间接块)；其次物理写可以是任意大小的,并不仅仅是文件块大小；第三，一个页总是被连续地写到磁盘，用一个分页文件，就并一定是这样

页面只有在需要的时候才在分页设备或者分区上被分配。每个设备和文件由一个位图开始说明哪些页面是空闲的。当一个没有备份存储的页面必须换出的时候，仍有空闲空间的最高优先级的分页分区或者文件被选中并且在其上面分配一个页面。正常情况下，分页分区(若存在)拥有比任何分页文件更高的优先级。页表被及时更新以反映页面已经不在内存了同时磁盘位置被写入到页表项

* 页面置换算法

页面替换是这样工作的。Linux试图保留一些空闲页面，这样可以在需要的时候分配它们。当然，这个页面池必须不断地加以补充。**PFRA(页框回收算法**)算法展示了它是如何发生的

首先，Linux区分四种不同的页面:**不可回收的**、**可交换的**、**可同步的**、**可丢弃的**。不可回收页面包括保留或者锁定页面、内核态栈等，不会被换出。可交换页必须在回收之前写回到交换区或者分页磁盘分区。可同步的页面如果被标记为dirty就必须要写回到磁盘。最后可丢弃的页面可以被立即回收

在启动的时候,init开启一个页面守护进程kswapd(每个内存节点都有一个)，并且配置它们能周期性运行。每次kswapd被唤醒，它通过比较每个内存区域的高低水位和当前内存的使用来检查是否有足够的空闲页面可用。如果有足够的空闲页面，它就继续睡眠。当然它也可以在需要更多页面时被提前唤醒。如果任何内存区域的可用空间低于一个阈值，kswapd初始化页框回收算法。在每次运行过程中，仅有一个确定数目的页面被回收，典型值是最大值32。这个值是受限的，以控制I/O压力(由PFRA操作导致的磁盘写的次数)。回收页面的数量和扫描页面的总数量都是可配置的参数

正如人们都会按照先易后难的顺序做事一样，每次PFRA执行时，它首先回收容易的页面，然后处理更难的。可丢弃页面和未被引用的页面都可以把它们添加到区域的空闲链表中从而立即回收。接着它查找有备份存储同时近期未被使用的页面，使用一个类似于时钟的算法。再后来就是用户使用不多的共享页面。共享页面带来的挑战是，如果一个页面被回收，那么所有共享了该页面的所有地址空间的页表都要同步更新。Linux维护高效的类树数据结构来方便地找到一个共享页面的所有使用者。接下来是普通用户页面,如果被选中换出，它们必须被调度写入交换区。系统的**swappiness**，即有备份存储的页面和在PFRA中被换出的页面的比率,是该算法的一个可调参数。最后，如果一个页是无效的、不在内存、共享、锁定在内存或者拥有DMA,那么它被跳过

PFRA用一个类似时钟的算法来选择旧页面换出。这个算法的核心是一个循环，它扫描每个区域的活动和非活动列表，试图按照不同的紧迫程度回收不同类型的页面。紧迫性数值作为一个参数传递给该过程，说明花费多大的代价来回收一些页面。通常这意味着在放弃之前检查多少个页面

内存管理系统的一个方面是另一个守护进程pdflush，实际上就是一组后台守护线程。pdflush线程要么周期性醒来(通常是每500ms)，把非常旧的"脏"(dirty)页面写回到磁盘,要么当可用的内存水平下降到一个阙值时由内核显式唤醒，把页面缓存的"脏"页面写回到磁盘在**便携模式**下，为了保留电池寿命，每次pdflush线程醒来，"脏"页面就被写到磁盘。"脏"页面也可以通过显式的同步请求写出到磁盘，比如通过系统调用sync、 fsync或者fdatasync。更早的Linux版本使用两个单独的守护进程:kupdate用于写回旧页面；bdflush用于在低内存的情况下写回页面。在2.4版本内核中这个功能被整合到pdflush线程当中了。选择多线程是为了隐藏长的磁盘延迟

## 10.5 Linux中的I/O系统

Linux和其他的UNIX系统一样，I/O系统都相当的简单明了。通常情况下，所有的I/O设备都被当作文件来处理，并且通过与访问所有文件同样的read和write系统调用来访问。在某些情况下，必须通过一个特殊的系统调用来设置设备的参数

### 10.5.1 基本概念

，Linux把设备当作一种**特殊文件**整合到文件系统中。每个I/O设备都被分配了一条路径，通常在/dev目录下。可以用与访问其他普通文件相同的方式来访问这些特殊文件。不需要特殊的命令或者系统调用。程序能够像操作普通文件那样打开、读、写特殊文件。通过这种方法,不需要任何特殊的机制就能进行I/O。

特殊文件(设备)分为两类，块特殊文件和字符特殊文件。一个**块特殊文件**由一组具有编号的块组成。块特殊文件的主要特性是:每一个块都能够被独立地寻址和访问。也就是说，一个程序能够打开一个块特殊文件，并且不用读第0块到第123块就能够读第124块。磁盘就是块特殊文件的典型应用。**字符特殊文件**通常用于表示输入和输出字符流的设备。键盘、打印机、网络、鼠标、绘图机以及大部分接受用户数据或向用户输出数据的设备都使用字符特殊文件来表示。访问一个鼠标的第124块是不可能的(甚至是无意义的)。大部分的字符特殊文件都不能够被随机访问,因此它们通常需要用不同于块特殊文件的方式来控制

每个特殊文件都和一个处理其对应设备的设备驱动相关联。每个驱动程序都通过一个**主设备号**来标识。如果一个驱动程序支持多个设备，如相同类型的两个磁盘，每个磁盘使用一个**次设备号**来标识。主设备号和次设备号结合在一起能够唯一地确定每个I/O设备。在很少的情况下，一个单独的驱动程序处理两种关系密切的设备。比如:与"/dev/tty"联合的驱动程序同时控制着键盘和显示器，这两种设备通常被认为是一种设备，即终端

### 10.5.2 网络

**套接字(socket)**：套接字允许用户连接到网络。套接字可以被动态创建和销毁。创建一个套接字成功后,系统返回一个文件描述符。创建连接、读数据、写数据、解除连接时要用到这个文件描述符。每个套接字支持一种特定的网络类型,这在套接字创建时指定。最常用的类型是：可靠的面向连接的字节流；可靠的面向连接的数据包流；不可靠的数据包传输

**可靠的面向连接的字节流**允许在不同机器上的两个进程之间建立一个等同于管道的连接。字节从一个端点注入然后按注入的顺序从另外一个端点流出。系统保证所有被传送的字节都能够到达，并且按照发送时的顺序到达

除保留了数据包之间的分界之外，**可靠的面向连接的数据包流**和可靠的面向连接的字节流是类似的。如果发送者调用了5次写操作,每次写了512字节，而接收者要接收2560字节，那么使用第一种类型的套接字，接收者接收一次会立刻接收到所有2560个字节。要是使用第二种类型的套接字，接收者一次只能收到512个字节，而要得到剩下的数据，还需要再进行4次调用

用户可以使用**不可靠的数据包传输**套接字来访问原始网络。这种类型的套接字尤其适用于实时应用和用户想要实现特定错误处理模式的情况。数据包可能会丢失或者被网络重排序。和前两种方式不同,这种方式没有任何保证，优点是有更高的性能,而有时候它比可靠性更加重要(如在传输多媒体时,快速比正确性更有用)

在创建套接字时，有一个参数指定使用的协议。对于可靠字节流通信来说，使用最广泛的协议是**TCP(传输控制协议)**。对于不可靠数据包传输来说,**UDP(用户数据报协议**)是最常用的协议。这两种协议都位于**IP(互联网协议**)层之上。目前没有可靠数据包流类型的通用协议

在一个套接字能够用于网络通信之前，必须有一个地址与它绑定。这个地址可以是几个命名域中的一个。最常用的域为互联网命名域，它在V4(第4个版本)中使用32位整数作为其命名端点，在V6中使用128位整数(V5是一个实验系统，从未成为主流)

一旦套接字在源计算机和目的计算机都建立成功，则两个计算机之间可以建立起一个连接(对于面向连接的通信来说)。一方在本地套接字上使用一个listen系统调用，它创建一个缓冲区并且阻塞，直到数据到来。另一方使用connect系统调用，并且把本地套接字的文件描述符和远程套接字的地址作为参数传递进去。如果远程一方接受了此次调用，则系统在两个套接字之间建立起一个连接

一旦连接建立成功，它的功能就类似于一个管道。一个进程可以使用本地套接字的文件描述符来从中读写数据。当此连接不再需要时，可以用常用的方式，即通过close系统调用来关闭它

### 10.5.4 I/O在linux中的实现

在Linux中I/O是通过一系列的设备驱动来实现的，每个设备类型对应一个设备驱动。设备驱动的功能是对系统的其他部分隔离硬件的特质。通过在驱动程序和操作系统其他部分之间提供一层标准的接口，使得大部分I/O系统可以被划归到内核的机器无关部分

当用户访问一个特殊文件时，由文件系统提供此特殊文件的主设备号和次设备号，并判断它是一个块特殊文件还是一个字符特殊文件。主设备号用于索引存有字符设备或者块设备数据结构的两个内部散列表之一。定位到的数据结构包含指向打开设备、读设备、写设备等功能的函数指针。次设备号被当作参数传递。在Linux系统中添加一个新的设备类型，意味着要向这些表添加一个新的表项，并提供相应的函数来处理此设备上的各种操作

每个驱动程序都分为两部分。这两部分都是Linux内核的一部分，并且都运行在内核态。上半部分运行在调用者的上下文并且与Linux其他部分交互。下半部分运行在内核上下文并且与设备进行交互。驱动程序可以调用内存分配、定时器管理、DMA控制等内核过程。所有可以被调用的内核功能都定义在一个叫作**驱动程序-内核接口**的文档中

I/0系统被划分为两大部分:处理块特殊文件的部分和处理字符特殊文件的部分

* 处理块特殊文件

系统中**处理块特殊文件**(比如，磁盘)I/O的部分的目标是使必须要完成的传输次数最小。为了实现这个目标，Linux系统在磁盘驱动程序和文件系统之间设置了一个**高速缓存(cache)**。在2.2版本内核之前，Linux系统完整地维护着两个单独的缓存:**页面缓存(page cache**)和**缓冲器缓存(buffer cache)**，因此，存储在一个磁盘块中的文件可能会被缓存在两个缓存中。2.2版本以后的Linux内核版本只有一个统一的缓存。一个**通用数据块层**把这些组件整合在了一起,执行磁盘扇区、数据块、缓冲区和数据页面之间必要的转换，并且激活作用于这些结构上的操作

cache是内核里面用来保存数以千计的最近使用的数据块的表。不管本着什么样的目的(i节点，目录或数据)而需要一个磁盘块，系统首先检查这个块是否在cache里面。如果在cache中，就可以从cache里直接得到这个块，从而避免了一次磁盘访问，这可以在很大程度上提高系统性能

如果页面cache中没有这个块，系统就会从磁盘中把这个块读入到cache中，然后再从cache中复制到请求它的地方。由于页面cache的大小是固定的，因此前面介绍的[页面置换算法](#1044-linux中的分页)在这里也是需要的

页面cache也支持写数据块，就像读数据一样。一个程序要回写一个块时，它被写到cache里，而不是直接写到磁盘上。当cache增长到超过一个指定值时，pdflush守护进程会把这个块写回到磁盘上。另外为了防止数据块被写回到磁盘之前在cache里存留太长时间，每隔30秒系统会把所有的"脏块"都写回到磁盘上

Linux依靠一个**I/O调度器**来保证磁头反复移动以减少延迟。I/O调度器的作用是对块设备的读写请求重新排序或对这些读写请求进行合并。有很多调度器变种，它们是根据不同类型的工作负载进行优化的结果。基本的Linux I/O调度器基于最初的**Linus电梯调度器**。电梯调度器的操作可以这样总结:按磁盘请求的扇区地址的顺序将磁盘操作在一个双向链表中排序。新的请求以排序的方式插入到双向链表中。这种方法可以有效地防止磁头重复移动。请求列表经过合并后，相邻的操作会被整合为一条单独的磁盘请求。基本电梯调度器有一个问题是会导致饥饿的情况发生。因此Linux磁盘调度器的修改版本包括两个附加的列表，维护按时限(deadline)排序的读写操作。读请求的缺省时限是0.5s，写请求的缺省时限是5s。如果最早的写操作的系统定义的时限要过期了，那么相对于任何在主双向链表中的请求来说,这个写请求会被优先服务

除了正常的磁盘文件，还有其他的块特殊文件，也被称为**原始块文件**。这些文件允许程序通过绝对块号来访问磁盘，而不考虑文件系统。它们通常被用于分页和系统维护

* 处理字符特殊文件

与字符设备的交互是很简单的。因为字符设备产生和接收的是字符流或字节数据，所以让字符设备支持随机访问是几乎没有意义的。不过**行规则**的使用是个例外。一个行规则可以和一个终端设备联合在一起，通过tty_struct结构来表示，一般作为和终端交换的数据的解释器。例如，利用行规则可以完成本地行编辑(即擦除的字符和行可以被删除)，回车可以映射为换行，以及其他的特殊处理能够被完成。然而如果一个进程要跟每个字符交互，那么它可以把行设置为原始模式，此时行规则将被忽略。另外，并不是所有的设备都有行规则

输出采用与输入类似的工作方式，如把tab扩展为空格，把换行转变为回车+换行，在慢的机械式终端的回车后面加填充字符等。像输入一样，输出可以通过(加工模式)行规则，或者忽略(原始模式)行规则。原始模式对于GUI和通过一个串行数据线发送二进制数据到其他的计算机的情况尤其有用，因为这些情况都不需要进行转换

* 处理网络设备

和网络设备的交互与前面的讨论有些不同。虽然**网络设备**也是产生或者接收字符流，但是它们的异步特性使得它们并不适合与其他的字符设备统一使用相同的接口。网络设备驱动程序产生具有多个字节的数据包和网络头。接着这些包会经过一连串的网络协议驱动程序传送，最后被发送到用户空间应用程序。套接字缓冲区skbuff是一个关键的数据结构，它用来表示填有包数据的部分内存。由于数据会被网络栈中的不同协议处理过，可能会添加或删除协议头，所以skbuff缓冲区里面的数据并不总是始于缓冲区的开始位置。用户进程通过套接字与网络设备进行交互，在Linux中支持原始的BSD的套接字API。通过raw_sockets，协议驱动程序可以被忽略，从而可以实现对底层网络设备的直接访问。只有超级用户才可以创建原始套接字

### 10.5.5 Linux中的模块

**可加载模块**：是在系统运行时可以加载到内核的代码块。大部分情况下，这些模块是字得或者块设备驱动，但是它们也可以是完整的文件系统、网络协议、性能监控工具或者其他想要添加的模块

当一个模块被加载到内核时，会发生下面几件事：1.在加载过程中，模块会被动态地重新部署；2.系统会检查这个驱动程序需要的资源是否可用(例如，中断请求级别)。如果可用，则把这些资源标记为正在使用；3.设置所有需要的中断向量；4.更新驱动转换表使其能够处理新的主设备类型；5.运行驱动程序来完成可能需要的特定设备的初始化工作。一旦上述所有的步骤都完成了，这个驱动程序就安装完成了

## 10.6 Linux文件系统



除了普通的文件之外，Linux还支持字符特殊文件和块特殊文件。字符特殊文件用来建模串行I/O设备，比如键盘和打印机。如果打开并从/dec/tty中读取内容，等于从键盘读取内容，而如果打开并向/dev/lp中写内容，等于向打印机输出内容。块特殊文件通常有类似于/dev/hd1的文件名，它用来直接向硬盘分区中读取和写人内容，而不需要考虑文件系统。原始块设备常被一些建立(如mkfs)或修补(如fsck)文件系统的程序用来进行分页和交换

许多计算机有两块或更多的磁盘。当一台机器上安装了多个磁盘的时候，就产生了如何处理它们的问题。一个解决方法是在每一个磁盘上安装自包含的文件系统，使它们之间互相独立。Linux的解决方法是允许一个磁盘挂载到另一个磁盘的目录树上。挂载之后，用户就能看见一个目录树，而不再关心文件在哪个设备上

Linux文件系统的另一个性质是**加锁**。在一些应用中会出现两个或更多的进程同时使用同一个文件的情况，可能导致竞争条件。有一种解决方法是使用临界区，但是如果这些进程属于相互不认识的独立的用户，这种解决方法是不方便的

POSIX提供了一种灵活的、细粒度的机制，允许一个进程使用一个不可分割的操作对小到一个字节、大到整个文件加锁。加锁机制要求加锁者标识要加锁的文件、开始位置以及要加锁的字节数。如果操作成功，系统会在表格中添加记录说明要求加锁的字节(如数据库的一条记录)已被锁住

系统提供了两种锁:**共享锁**和**互斥锁**。如果文件的一部分已经被加了共享锁，那么在上面尝试加共享锁是允许的，但是加互斥锁是不会成功的；如果文件的一部分已经被加了互斥锁，那么在互斥锁解除之前加任何锁都不会成功。为了成功地加锁，请求加锁的部分的所有字节都必须是可用的

在加锁时，进程必须指出当加锁不成功时是否阻塞。如果选择阻塞，则当已经存在的锁被删除时,进程被放行并在文件上加锁;如果选择不阻塞，系统调用在加锁失败时立即返回，并设置状态码表明加锁是否成功，如果不成功，由调用者决定下一步动作

多个共享锁的加锁区域可以是重叠的。但在已经加了共享锁的区域无法加互斥锁，进程将阻塞或者加锁失败并返回

### 10.6.3 Linux文件系统的实现

1. 虚拟文件系统(VFS)

为了使应用程序能够与在本地或远程设备上的不同文件系统进行交互，Linux采用了一个和其他UNIX系统相同的方法:**虚拟文件系统(VFS)**。VFS定义了一个基本的文件系统抽象以及这些抽象上允许的操作集合。调用系统调用访问VFS的数据结构，确定要访问的文件所属的文件系统，然后通过存储在VFS数据结构中的函数指针调用该文件系统的相应操作

VFS支持的四个主要的文件系统结构如下表所示↓：
|对象|描述|操作|
|:-:|:-:|:-:|
|Superlock|特定的文件系统|read_inode, sync_fs|
|i-node|特定的文件|d_compare, d_delete|
|Dentry|目录项，路径的一个组成部分|create, link|
|File|跟一个进程相关联的打开文件|read, write|

**Superlock(超级块**)包含了文件系统布局的重要信息，破坏了超级块将会导致文件系统不可读

**i-node(i节点**)表示某个确切的文件。值得注意的是，在Linux中目录和设备也被当作文件,所以它们也有自己对应的i节点。超级块和i节点都有相应的结构，由文件系统所在的物理磁盘维护

为了便于目录操作及路径(比如/usr/ast/bin) 的遍历,VFS支持**dentry**数据结构，它表示一个目录项。这个数据结构由文件系统在运行过程中创建。目录项被缓存在dentry_cache中。如果多个进程通过同一个硬连接(即相同路径)访问同一个文件，它们的文件对象都会指向这个cache中的同一个目录项

**file**数据结构是一个打开文件在内存中的表示，并且在调用open系统调用时被创建。它支持read,write、sendfile、 lock等系统调用

在VFS下层实现的实际文件系统并不需要在内部使用与VFS完全相同的抽象和操作，但是必须实现跟VFS对象所指定的操作在语义上等价的文件系统操作。这四个VFS对象中的operations数据结构的元素都是指向底层文件系统函数的指针

2. Linux ex2文件系统

ex2的磁盘分区依次为引导块、块组0、块组1、块组2...块0不被linux使用，而通常用来存放启动计算机的代码。在块0后面，磁盘分区被划分为若干个块组，划分时不考虑磁盘的物理结构

* 每个块组由超级块、组描述符、块位图、i节点位图、i节点和数据块构成
	* **超级块**包含了该文件系统的信息，包括i节点的个数、磁盘块数以及空闲块链表的起始位置(通常有几百个项)
	* **组描述符**，存放了位图的位置、空闲块数、组中的i节点数，以及组中目录数等信息，这个信息很重要，因为ext2试图把目录均匀地分散存储到磁盘上
	* **块位图**和**i节点位图**分别记录空闲块和空闲i节点，这是从MINIX1文件系统继承的(大多数UNIX文件系统不使用位图，而使用空闲列表)。每一个位图的大小是一个块。如果一个块大小是1KB，那么就限制了块数和i节点数只能是8192个。块数是一个严格的限制，但是在实际应用中，i节点数并不是。如果一个块的大小是4KB,那么i节点数量是4倍多
	* 在超级块只有是**i节点存储区域**，它们被编号为1到某个最大值。每个i节点的大小是128字节，并且每一个i节点恰好描述一个文件。i节点包含了统计信息(包含了stat系统调用能获得的所有信息，实际上stat就是从i节点读取信息的)，也包含了所有存放该文件数据的磁盘块的位置
	* 在i节点区后面是**数据块区**，所有文件和目录都存放在这个区域。对于一个包含了一个以上磁盘块的文件和目录，这些磁盘块是不需要连续的。实际上，一个大文件的块有可能遍布在整个磁盘上。

* **目录**对应的i节点散布在磁盘块组中。如果有足够的空间，ext2会把普通文件组织到与父目录相同的块组上，而把同一个块上的数据文件组织成初始文件i节点。位图用于快速确定在什么地方分配新的文件系统数据。在分配新的文件块时，ext2也会给该文件预分配许多(8个)额外的数据块，这样可以减少将来向该文件写入数据时产生的文件碎片。这种策略在整个磁盘上实现了文件系统负载平衡，而且由于对文件碎片进行了排列和缩减，使得它的性能也很好
	* 目录文件允许不超过255个字符的文件名。每一个目录都由整数个磁盘块组成，这样目录就可以整体写入磁盘。在一个目录中，文件和子目录的目录项是未排序的，并且一个紧挨着一个。目录项不能跨越磁盘块，所以通常在每个磁盘块的尾部会有部分未使用的字节
	* 每个目录项由四个固定长度的域和一个可变长度的域组成。第一个域是**i节点号**。接下来是**rec_len域**,标明该目录项的大小(以字节为单位)，可能包括名字后面的一些填充。在名字以未知长度填充时，这个域被用来寻找下一个目录项。接下来是**类型域**:文件、目录等。最后一个固定域是**文件名的长度**(以字节为单位)。最后是**文件名**，文件名以字节0结束，并被填充到32字节边界。额外的填充可以在此之后。
	* 由于目录是按线性顺序查找的，要找到一个位于大目录末尾的目录项会耗费相当长的时间。因此系统为近期访问过的目录维护一个缓存。该缓存使用文件名进行查找，如果命中，那么就可以避免费时的线性查找。组成路径的每个部分都在目录缓存中保存一个dentry对象，并且通过它的i节点查找到后续的路径元素的目录项,直到找到真正的文件i节点
	* 查找文件：例如要通过绝对路径名来查找一个文件(如:/usr/ast/file)，需要经过如下步骤：首先系统定位根目录，它通常使用2号i节点(特别是当1号i节点被用来处理磁盘坏块的时候)。系统在目录缓存中存放一条记录以便将来对根目录的查找。然后在根目录中查找字符串"usr",得到/usr目录的i节点号。/usr目录的i节点号同样也存入目录缓存。然后这个i节点被取出，并从中解析出磁盘块，这样就可读取/usr目录并查找字符串"ast"。一旦找到这个目录项，目录/usr/ast的i节点号就可以从中获得。有了/usr/ast的i节点号，就可以读取i节点并确定目录所在的磁盘块。最后从/usr/ast目录查找"file"并确定其i节点号。因此使用相对地址不仅对用户来说更加方便，而且也为系统节省了大量的工作
	* 如果文件存在，那么系统提取其i节点号并以它为索引在i节点表(在磁盘上)中定位相应的i节点，并装入内存。i节点被存放在**i节点表**中，其中i节点表是一个内核数据结构，用于保存所有当前打开的文件和目录的i节点。i节点表项的格式至少要包含stat系统调用返回的所有域，以保证stat正常运行

* 读取文件：对于调用了read系统调用的库函数的一个典型使用是:`n = read(fd, buffer, nbytes);`当内核得到控制权时，它需要从这三个参数以及内部表中与用户有关的信息开始。内部表中的项目之一是文件描述符数组。文件描述符数组用文件描述符作为索引并为每一个打开的文件保存一个表项(最多达到最大值,通常默认是32个)
	* 定位文件读写位置和i节点：在文件描述符表和i节点表之间引入一个新的表,叫作**打开文件描述表**，并将文件读写位置(以及读/写位)放到里面。父子进程指向相同的打开文件描述表的表项，新的子进程自动继承文件读写位置。然而当不相关的进程打开该文件时，它将得到自己的打开文件描述表项，以及自己的文件读写位置。因此打开文件描述表的重点是允许父进程和子进程共享一个文件读写位置，而给不相关的进程提供各自私有的值
	* 读操作：定位文件读写位置和i节点之后。i节点包含文件前12个数据块的磁盘地址。如果文件位置是在前12个块，那么这个块被读入并且其中的数据被复制给用户。对于长度大于12个数据块的文件，i节点中有一个域包含一个**一级间接块**的磁盘地址。这个块含有更多的磁盘块的磁盘地址。例如如果一个磁盘块大小为1KB而磁盘地址长度是4字节，那么这个一级间接块可以保存256个磁盘地址。因此这个方案只对于总长度在268KB以内的文件适用。除此之外，还使用一个**二级间接块**。它包含256个一级间接块的地址，每个一级间接块保存256个数据块的地址。这个机制能够处理$10+2^{16}$个块(67 119 104字节)。如果这样仍然不够，那么i节点为三级间接块留下了空间，三级间接块的指针指向许多二级间接块。这个寻址方案能够处理大小为$2^{24}$个1KB块(16GB)的文件。对于块大小是8KB的情况，这个寻址方案能够支持最大64TB的文件

* 缺点：为了防止由系统崩溃和电源故障造成的数据丢失，ext2文件系统必须在每个数据块创建之后立即将其写出到磁盘上。必需的磁盘磁头寻道操作导致的延迟是如此之长以至于性能差得无法让人接受。因此写操作被延迟，对文件的改动可能在30秒内都不会提交给磁盘，而相对于现代的计算机硬件来说，这是一段相当长的时间间隔

3. Linux ext4文件系统

为了增强文件系统的健壮性,Linux依靠**日志文件系统**。ext3是一个日志文件系统，它在ext2文件系统之上做了改进。**ext4**是ext3的改进，也是一个日志文件系统，但不同于ext3，它改变了ext3所采用的块寻址方案，从而同时支持更大的文件和更大的整体文件系统

ext4文件系统背后的**基本思想**是维护一个日志，该日志顺序记录所有文件系统操作。通过顺序写出文件系统数据或元数据(i节点，超级块等)的改动，该操作不必忍受随机磁盘访问时磁头移动带来的开销。最后这些改动将被写到适当的磁盘地址，而相应的日志项可以被丢弃。如果系统崩溃或电源故障在改动提交之前发生，那么在重启动过程中，系统将检测到文件系统没有被正确地卸载。然后系统遍历日志,并执行日志记录所描述的文件系统改动

ext4设计成与ext2和ext3**高度兼容**，尽管其核心数据结构和磁盘布局被修改过。此外一个作为ext2系统被卸载的文件系统随后可以作为ext4系统被挂载并提供日志能力

日志是一个以环形缓冲器形式组织的文件。日志可以存储在主文件系统所在的设备上也可以存储在其他设备上。由于日志操作本身不被日志记录，这些操作并不是被日志所在的ext4文件系统处理的，而是使用一个独立的**日志块设备(JBD**)来执行日志的读/写操作

JBD支持三个主要**数据结构**:日志记录、原子操作处理和事务。一个**日志记录**描述一个低级文件系统操作，该操作通常导致块内变化。鉴于系统调用包含多个地方的改动---i节点、现有的文件块、新的文件块、空闲块列表等，所以将相关的日志记录按照**原子操作**分成组。Ext3将系统调用过程的起始和结束通知JBD，这样JBD能够保证一个原子操作中的所有日志记录或者都被应用，或者没有一个被应用。最后主要从效率方面考虑，JBD将原子操作的汇集作为**事务**对待。一个事务中日志记录是连续存储的。仅当一个事务中的所有日志记录都被安全提交到磁盘后，JBD才允许日志文件的相应部分被丢弃

把每个磁盘改动的日志记录项写到磁盘可能开销很大，ext4可以配置为保存所有磁盘改动的日志或者仅仅保存文件系统元数据(i节点、超级块等)改动的日志。只记录元数据会使系统开销更小，性能更好，但是不能保证文件数据不会损坏。一些其他的日志文件系统仅仅维护关于元数据操作的日志(例如，SGI的XFS)。此外该日志的可靠性还可以进一步通过校验而改善

相比之前的文件系统，ext4的主要改动在于使用了**盘区**。盘区代表连续的存储块，例如128MB的连续4KB的块，而ext2采用的是单个存储块。ext4并不要求对每个存储块进行元数据操作，这点不像之前的文件系统。这个策略也为大型文件存储减少了碎片。其结果是，ext4可以提供更快的文件系统操作，并支持更大的文件和文件系统。例如，对于1 KB的块大小，ext4将最大的文件大小从16GB增加到16TB,最大的文件系统大小增加到1EB

4. /proc文件系统

**基本概念**是为系统中的每个进程在/proc中创建一个目录。目录的名字是进程PID的十制数值。例如，/proc/619是与PID为619的进程相对应的目录。在该目录下是进程信息的文件，如进程的命令行、环境变量和信号掩码等。事实上，这些文件在磁盘上并不存在。当读取这些文件时，系统按需从进程中抽取这些信息，并以标准格式将其返回给用户

许多Linux扩展与/proc中其他的文件和目录相关。它们包含各种各样的关于CPU、磁盘分区、设备、中断向量、内核计数器、文件系统、已加载模块等信息。非特权用户可以读取很多这样的信息，于是就可以通过一种安全的方式了解系统的行为。其中的部分文件可以被写入，以达到改变系统参数的目的

### 10.6.4 NFS：网络文件系统

本节将介绍Sun Microsystem的**NFS(网络文件系统)**。该文件系统应用于所有的现代Linux系统中，其作用是将不同计算机上的不同文件系统连接成一个逻辑整体。NFS于1994年提出第3版，于2000年提出第4版，并在前一个NFS体系结构上做了一些增强。NFS有三个方面值得关注:体系结构、协议和实现。首先介绍简化的NFS第三版，然后简要探讨第四版所做的增强

1. NFS体系结构

NFS背后的基本思想是允许任意选定的一些客户端和服务器共享一个公共文件系统。在很多情况下,所有的客户端和服务器都在同一个局域网中，但这并不是必需的。如果服务器距离客户端很远,NFS也可以在广域网上运行。简单起见还是说客户端和服务器，就好像它们位于不同的机器上，但实际上，NFS允许一台机器同时既是客户端又是服务器

每一个NFS服务器都导出一个或多个目录供远程客户端访问。当一个目录可用时，它的所有子目录也都可用，正因如此，通常整个目录树通常作为一个单元导出。服务器导出的目录列表用一个文件来维护,通常是/etc/exports。因此服务器启动后这些目录可以被自动地导出。客户端通过挂载这些导出的目录来访问它们。当一个客户端挂载了一个(远程)目录，该目录就成为客户端目录层次的一部分

如果不同的客户端将文件挂载到各自目录树中不同的位置，那么同一个文件在不同的客户端有不同的名字。对客户端来说挂载点是完全位于本地的，服务器不会知道文件在任何一个客户端中的挂载点

2. NFS协议

由于NFS的目标之一是支持异构系统，客户端和服务器可能在不同硬件上运行不同操作系统，因此对客户端和服务器之间的接口给予明确定义是很关键的。只有这样，才有可能让任何一个新的客户端能够跟现有的服务器一起正确工作,反之亦然

NFS通过定义两个客户端-服务器协议来实现这一目标。**协议**就是从客户端发送到服务器的一组请求以及从服务器返回给客户端的响应的集合

**第一个NFS协议处理挂载**：客户端可以向服务器发送路径名，请求服务器许可将该目录挂载到自己的目录层次的某个地方。由于服务器并不关心目录将被挂载到何处，因此请求消息中并不包含挂载地址

如果路径名是合法的并且该目录已被导出，那么服务器向客户端返回一个**文件句柄**。这个文件句柄中的域唯一地标识了文件系统类型、磁盘、目录的i节点号以及安全信息等。随后对已挂载目录及其子目录中文件的读写都使用该文件句柄

Linux启动时会在进入多用户之前运行shell脚本/etc/rc。可以将挂载远程文件系统的命令写入该脚本中，这样就可以在允许用户登录之前自动挂载必要的远程文件系统。此外大部分Linux版本也支持**自动挂载**。这个特性允许一组远程目录跟一个本地目录相关联。当客户端启动时，并不挂载这些远程目录(甚至不与它们所在的服务器进行联络)。相反在第一次打开远程文件时，操作系统向每个服务器发送一条信息。第一个响应的服务器胜出,其目录被挂载

相对于通过/etc/rc文件进行静态挂载，自动挂载具有两个主要**优势**：第一，如果/etc/rc中列出的某个NFS服务器出了故障，那么客户端将无法启动，或者至少会带来一些困难、延迟以及很多出错信息。如果用户当前根本就不需要这个服务器，那么刚才的工作就白费了；第二，允许客户端并行地尝试一组服务器，可以实现一定程度的容错性(因为只要其中一个是在运行的就可以了)，而且性能也可以得到提高(通过选择第一个响应的服务器一推测该服务器负载最低)

另一方面，我们默认在自动挂载时所有可选的文件系统都是完全相同的。由于NFS不提供对文件或目录复制的支持，用户需要自己确保所有这些文件系统都是相同的。因此自动挂载多数情况下被用于包含系统二进制文件和其他很少改动的文件的只读文件系统

**第二个NFS协议是为访问目录和文件设计的**：客户端可以通过向服务器发送消息来操作目录和读写文件。客户端也可以访问文件属性，如文件模式、大小、上次修改时间。NFS支持大多数的Linux系统调用,但是也许很让人惊讶的是，open和close不被支持

**不支持open和close操作**并不是一时疏忽，而纯粹是有意为之。没有必要在读一个文件之前先打开它,也没有必要在读完后关闭它。读文件时，客户端向服务器发送一个包含文件名的lookup消息，请求查询该文件并返回一个标识该文件的文件句柄(即包含文件系统标识符i节点号以及其他数据)。与open调用不同,lookup操作不向系统内部表中复制任何信息。read调用包含要读取文件的文件句柄，起始偏移量和需要的字节数。每个这样的消息都是自包含的。这个方案的优势是在两次read调用之间，服务器不需要记住任何关于已打开的连接的信息。因此如果一个服务器在崩溃之后恢复所有关于已打开文件的信息都不会丢失，因为这些信息原本就不存在。像这样不维护打开文件的状态信息的服务器称作是**无状态的**

不幸的是，NFS方法使得难以实现精确的Linux文件语义。例如在Linux中一个文件可以被打开并锁定以防止其他进程对其访问。当文件关闭时，锁被释放。在一个像NFS这样的无状态服务器中，锁不能与已打开的文件相关联，这是因为服务器不知道哪些文件是打开的。因此，NFS需要一个独立的，附加的机制来进行加锁处理

NFS使用标准UNIX保护机制，为文件属主、组和其他用户使用读写、执行位(rwx bits)。最初每个请求消息仅仅包含调用者的用户ID和组ID，NFS服务器用它们来验证访问。实际上，它信任客户端，认为客户端不会进行欺骗。若干年来的经验充分支持了这样一个假设。现在可以使用公钥密码系统建立一个安全密钥，在每次请求和应答中使用它验证客户端和服务器。启用这个选项后，恶意的客户端就不能伪装成另一个客户端了，因为它不知道其他客户端的安全密钥

3. NFS实现

尽管客户端和服务器代码实现独立于NFS协议，但大多数Linux系统使用三层实现：顶层是系统调用层，这一层处理open、read和close之类的调用。在解析调用和参数检查结束后，调用第二层---**虚拟文件系统(VFS)层**

VFS层的任务是维护一个表，每个打开的文件在该表中有一个表项。VFS层为每个打开文件保存一个**虚拟i节点(v-node)**。v节点用来说明文件是本地文件还是远程文件。对于远程文件,v节点提供足够的信息使客户端能够访问它们。对于本地文件，则记录其所在的文件系统和文件的i节点，这是因为现代Linux系统能支持多文件系统(例如ext2fs、/proc、FAT等)。尽管VFS是为了支持NFS而发明的,但多数现代Linux系统将VFS作为操作系统的一个组成部分，不管有没有使用NFS

为了理解**如何使用v节点**，我们来跟踪一组顺序执行的mount、open和read调用。要挂载一个远程文件系统，系统管理员(或/etc/rc)调用mount程序，并指明远程目录、远程目录将被挂载到哪个本地目录，以及其他信息。mount程序解析要被挂载的远程目录并找到该目录所在的NFS服务器，然后与该机器连接，请求远程目录的文件句柄。如果该目录存在并可被远程挂载，服务器就返回一个该目录的文件句柄。最后，mount程序调用mount系统调用,将该句柄传递给内核

然后内核为该远程目录创建一个v节点，并要求客户端代码在其内部表中创建一个**r节点**(remote i-node)来保存该文件句柄。v节点指向r节点。**VFS中的每一个v节点最终要么包含一个指向NFS客户端代码中r节点的指针，要么包含指向一个本地文件系统的i节点的指针**。因此我们可以从v节点中判断一个文件或目录是本地的还是远程的。如果是本地的，可以定位相应的文件系统和i节点。如果是远程的，可以找到远程主机和文件句柄

当客户端打开一个远程文件时,在解析路径名的某个时刻,内核会碰到挂载了远程文件系统的目录。内核看到该目录是远程的，并从该目录的v节点中找到指向r节点的指针,然后要求NFS客户端代码打开文件。NFS客户端代码在与该目录关联的远程服务器上查询路径名中剩余的部分，并返回一个文件句柄。它在自己的表中为该远程文件创建一个r节点并报告给VFS层。VFS层在自己的表中为该文件建立一个指向该r节点的v节点。从这里我们再一次看到，每一个打开的文件或目录有一个v节点，要么指向一个r节点,要么指向一个i节点

返回给调用者的是远程文件的一个文件描述符。VFS层中的表将该文件描述符映射到v节点。注意服务器端没有创建任何表项。尽管服务器已经准备好在收到请求时提供文件句柄，但它并不记录哪些文件有文件句柄，哪些文件没有。当一个文件句柄发送过来要求访问文件时，它检查该句柄。如果是有效的句柄，就使用它。如果安全策略被启用，验证包含对RPC头中的认证密钥的检验

当文件描述符被用于后续的系统调用时，VFS层先定位相应的v节点,然后根据它确定文件是本地的还是远程的，同时确定哪个i节点或r节点是描述该文件的。然后向服务器发送一个消息，该消息包含句柄、偏移量(由客户端维持，而不是服务器端)和字节数。出于效率方面的考虑，即使要传输的数据很少，客户端和服务器之间的数据传输也使用大数据块，通常是8192字节

当请求消息到达服务器，它被送到服务器的VFS层，在那里将判断所请求的文件在哪个本地文件系统中。然后VFS层调用本地文件系统去读取并返回请求的字节。随后这些数据被传送给客户端。客户端的VFS层接收到它所请求的这个8KB块之后，又自动发出对下一个块的请求，这样当我们需要下一个块时就可以很快地得到。这个特性称为**预读**，它极大地提高了性能

客户端向服务器写文件的过程是类似的。文件也是以8KB块为单位传输。如果一个write系统调用提供的数据少于8KB，则数据在客户端本地累积，直到8KB时才发送给服务器。当然当文件关闭时,所有的数据都立即发送给服务器

另一个用来改善性能的技术是**缓存**，与在通常的UNIX系统中的用法一样。服务器缓存数据以避免磁盘访问，但这对客户端而言是不可见的。客户端维护两个缓存:一个缓存文件属性(i节点)，另一个缓存文件数据。当需要i节点或文件块时，就在缓存中检查有无符合的数据。如果有，就可以避免网络流量了

客户端缓存对性能提升起到很大帮助的同时，也带来了一些令人讨厌的问题。假设两个客户端都缓存了同一个文件块，并且其中一个客户端修改了它。当另一个客户读该块时，它读到的是旧的数据值。这时缓存是不一致的。NFS实现做了一些事情来缓解这一问题：第一，为每个缓存了的块关联一个定时器。当定时器到期时，缓存的项目就被丢弃。通常数据块的时间是3秒，目录块的时间是30秒。这稍微减少了一些风险；另外，当打开一个有缓存的文件时，会向服务器发送一个消息来找出文件最后修改的时间。如果最后修改时间晚于本地缓存时间，那么旧的副本被丢弃，新副本从服务器取回；最后，每30秒缓存定时器到期一次，缓存中所有的"脏"块(即修改过的块)都发送到服务器。尽管并不完美，但这些修补使得系统在多数实际环境中高度可用

4. NFS第4版

网络文件系统第4版是为了简化其以前版本的一些操作而设计的。相对于上面描述的第3版NFS,第4版NFS是有状态的文件系统。这样就允许对远程文件调用open操作，因为远程NFS服务器将维护包括文件指针在内的所有文件系统相关的结构。读操作不再需要包含绝对读取范围了，而可以从文件指针上次所在的位置开始增加。这就使消息变短，同时可以在一次网络传输中捆绑多个第3版NFS的操作

第4版NFS的有状态性使得将第3版NFS中多个协议(在本节前面部分描述过)集成为一个一致的协议变得容易。这样就没有必要再为挂载、缓存、加锁或者安全操作支持单独的协议了。第4版NFS在Linux(和UNIX)和Windows文件系统语义下都工作得更好

## 10.7 Linux的安全性

### 10.7.1 基本概念

一个Linux系统的用户群体由一定数量的注册用户组成，其中每个用户拥有一个唯一的**UID(用户ID)**。UID是介干0到65535之间的一个整数。文件(进程及其他资源)都标记了它的所有者的UID。尽管可以改变文件所有权，但是默认情况下，文件的所有者是创建该文件的用户

用户可以被分组，其中每组同样由一个16位的整数标记，叫作**GID(组ID)**。给用户分组通过在系统数据库中添加一条记录指明哪个用户属于哪个组的方法手工(由系统管理员)完成。一个用户可以同时属于多个组

Linux中的基本安全机制很简单。每个进程记录它的所有者的UID和GID。当一个文件被创建时，它的UID和GID被标记为创建它的进程的UID和GID。该文件同时获得由该进程决定的一些权限。这些权限指定所有者、所有者所在组的其他用户及其他用户对文件具有什么样的访问权限。对于这三类用户而言,潜在的访问权限为读、写和执行，分别由r、w和x标记。当然执行文件的权限仅当文件是可执行二进制程序时才有意义。试图执行一个拥有执行权限的非可执行文件(即，并非由一个合法的文件头开始的文件)会导致错误。因为有三类用户，每类用户的权限由3个比特位标记，那么9个比特位就足够标记访问权限

UID为0的用户是一个特殊用户，称为**超级用户(根用户)**。超级用户能够读和写系统中的任何文件，不论这个文件为谁所有，也不论这个文件的保护模式如何。UID为0的进程拥有调用以下部分受保护的系统调用的权限，而普通用户是不能调用这些系统调用的

目录也是一种文件，并且具有普通文件一样的保护模式。不同的是，目录的x比特位表示查找权限而不是执行权限。因此，如果一个目录具有保护模式rwxr-xr-x，那么它允许所有者读、写和查找目录,但是其他人只可以读和查找，而不允许从中添加或者删除目录里的文件

与I/O相关的特殊文件拥有与普通文件一样的保护位。这种机制可以用来限制对I/O设备的访问权限。例如假设打印机是特殊文件，/dev/lp，可以被根用户或者一个叫守护进程的特殊用户拥有，具有保护模式rw------，从而阻止其他所有人对打印机的访问权限。当然让/dev/lp被守护进程以保护模式rw------拥有，意味着其他任何人都不可以使用打印机，事实上允许对I/O设备及其他系统资源进行受控访问的做法具有一个更普遍的问题

这个问题通过增加一个保护位**SETUID**到之前的9个比特位来解决。当一个进程的SETUID位打开,它的**有效UID**将变成相应可执行文件的所有者的UID，而不是当前使用该进程的用户的UID。当一个进程试图打开一个文件时，系统检查的将是它的有效UID，而不是真正的UID。将访问打印机的程序设置为被守护进程所有，同时打开SETUID位，这样任何用户都可以执行该程序，并拥有守护进程的权限(例如访问/dep/lp)，但是这仅限于运行该程序(例如给打印任务排序)

许多敏感的Linux程序通过打开SETUID位被根用户所有。例如允许用户改变密码的程序需要写password文件。允许password文件公开可写显然不是个好主意。解决的方法是，提供一个被根用户所有同时SETUID位打开的程序。虽然该程序拥有对password文件的全部权限，但是它仅仅改变调用该程序的用户的密码，而不允许其他任何的访问权限

除了SETUID位，还有一个SETGID位，工作原理同SETUID类似。它暂时性地给用户该程序的有效GID。然而在实践中,这个位很少用到

### 10.7.3 Linux中的安全实现

当用户登录时,登录程序login(为根用户所有且SETUID打开)要求输入登录名和密码。它首先计算密码的散列值，然后在/etc/passwd文件中查找，看是否有相匹配的项(网络系统工作得稍有不同)。使用散列的原因是防止密码在系统中以非加密的方式存在。如果密码正确，登录程序在/etc/passwd中读取该用户选择的shell程序的名称，例如可能是bash，但是也有可能是其他的shell，例如csh或者ksh。然后登录程序使用setuid和setgid来使自己的UID和GID变成用户的UID和GID(注意它一开始的时候是根用户所有且SETUID打开)。然后它打开键盘作为标准输入(文件描述符0)，屏幕为标准输出(文件描述符1)，屏幕为标准错误输出(文件描述符2)。最后执行用户选择的shell程序，因此终止自己

到这里，用户选择的shell已经在运行，并且被设置了正确的UID和GID，标准输入、标准输出和标准错误输出都被设置成了默认值。它创建任何子进程(也就是用户输入的命令)都将自动继承shell的UID和GID，所以它们将拥有正确的UID和GID，这些进程创建的任何文件也具有这些值

当任何进程想要打开一个文件，系统首先将文件的i节点所记录的保护位与用户的有效UID和有效GID对比，来检查访问是否被允许。如果允许访问，就打开文件并且返回文件描述符;否则不打开文件,返回-1。在接下来的read和write中不再检查权限。因此，当一个文件的保护模式在它被打开后修改，新模式将无法影响已经打开该文件的进程

Linux安全模型及其实现在本质上跟其他大多数传统的UNIX系统相同

## 10.8 Android

Android基于Linux内核，只是将少数新的概念引入Linux内核之中，使用了大多数Linux设施(进程、用户ID、文件系统、调度等)，但是Android是以与其最初意图非常不一样的方式实现使用这些设施的

Android不但在以消费者为中心的设备(例如平板电脑、电视、游戏机以及媒体播放器)上流行，在这样的设备上，第三方应用生态系统是有益的;而且Android还越来越多地用作需要**图形用户界面(GUI**)的专用设备的嵌入式OS，例如VOIP电话、智能手表、汽车仪表盘、医疗设备以及家用电器

Android操作系统的大部分是用高级语言编写的，即Java程序设计语言。内核和大量的低层库是用C和C++编写的。不但系统的大部分是用Java编写的，而且除了少量例外，整个应用程序API也是用Java编写和发布的。Android中用Java编写的部分倾向于遵循完全的面向对象设计，这正是该语言所鼓励的

### 10.8.1 Android与Google

Android是一种异于常规的操作系统，它将开源代码和闭源第三方应用程序结合在一起。Android的开源部分称为**Android开源项目(AOSP)**，它是完全开放的，任何人都可以免费使用和修改

Android的一个重要目标是支持丰富的第三方应用程序环境，这就要求Android具有稳定的实现和API,从而使应用程序得以在其上运行。然而在开源世界中每一个设备厂商都可以随其意愿定制平台,于是兼容性问题很快就产生了。这就需要有某种方法来控制这一冲突

在Android针对这一问题的解决方案中，有一部分是**兼容性定义文档(CDD)**，它描述了为了与第三方应用程序相兼容，Android所必须遵循的行为方式。这一文档本身描述了为了成为兼容的Android设备所必需的条件。然而因为缺乏某种方法来强制实施这样的兼容性，于是它经常被忽略，因此需要某种额外的机制来做这件事。

Android解决这一问题的方法是允许在开源平台之上创建额外的私有服务，以这样的方式来提供平台本身不能实现的服务(一般情况下是基于云的)。因为这些服务是私有的，所以它们可以限制包含在其中的设备,这就要求这些设备具有CDD兼容性。

Google实现的Android能够支持多种多样的私有云服务，在Google广泛的服务系列中具有代表性的案例包括Gmail、日程表和通讯录同步、云到设备的消息传递以及许多其他服务，有些服务对用户而言是可见的，有些则不可见。就发布兼容的应用程序而言，最重要的服务是Google Play

Google Play是Google的在线Android应用程序商店。一般来说，当开发商创建Android应用程序时，他们会用Google Play来发布。因为Google Play(或者任何其他应用程序商店)是一种渠道，应用程序通过这一渠道传送到Android设备上，所以私有服务负责确保应用程序在它们所传送到的设备上能够正常工作。

Google Play使用了两个主要的机制来保证兼容性。第一个并且是最重要的机制，就是要求通过它得以上市的任何设备必须按照CDD的要求具备兼容性。这就保证了跨设备的行为底线。此外Google Play必须了解应用程序要求设备所具备的任何功能特性(例如为了执行地图导航必须存在GPS)，这样一来在缺乏这些功能特性的设备上应用程序就是不可用的

### 10.8.3 设计目标

Android平台的一些关键设计目标在其开发过程中逐步演化：

1. 为移动设备提供完全开源的平台。Android的开源部分是一个自下而上的操作系统栈，包含各种应用程序，能够作为完整的产品上市

2. 通过健壮的和稳定的API强有力地支持具有专利的第三方应用。正如前面所讨论的，维护一个平台真正开源的同时使具有专利的第三方应用足够稳定是一个挑战。Android采用了一种混合技术解决方案(具体说明定义明确的SDK并且在公开的API和内部实现之间进行分隔)和策略必要条件(通过CDD)来解决这一问题

3. 允许全部第三方应用程序(包括来自Google的)，从而在公平的环境中进行竞争。Android开源代码被设计成对于建立在其上的高级系统功能尽可能保持中立，这些高级系统功能从云服务(例如数据同步或云到设备的信息发送API)到库(例如Google的地图库)和诸如应用程序商店一类的丰富的服务

4. 提供一种应用程序安全性模型，在该模型中用户不必深度信赖第三方应用程序。操作系统必须保护用户免受应用程序不端行为的危害，这不但包括可能导致系统崩溃的有缺陷的应用程序，而且还包括更为微妙的对设备和用户数据的不当使用。用户越不需要信任应用程序，他们就越拥有自由来尝试和安装这些应用程序

5. 支持典型的移动用户界面：使用户在许多应用中花费少量的时间。移动体验趋向于与应用程序进行短暂的交互：看一眼新收到的电子邮件，接收或者发送一条SMS信息或者IM,进入通讯录拨打一个电话等等。系统需要对这些情况进行优化，以期获得快速的应用启动和切换时间。Android的目标一般是用200ms冷启动一个基本的应用程序到显示完整的交互式UI

6. 为用户管理应用程序进程，简化围绕应用程序的用户体验，从而使用户在使用完应用程序之后不用想着要将其关闭。移动设备还趋向于在没有交换空间的条件下运行，交换空间能够在当前运行的应用程序需要的RAM多于物理上可用的RAM之时，使操作系统衰退得更加优雅。为了处理这两个需求，系统需要采取更加积极主动的态度来管理进程，决定何时应该启动和停止它们

7. 鼓励应用程序以丰富和安全的方式互操作和协作。移动应用程序是以某种方式返回到shell命令的：它们不是像桌面应用程序那样越来越大的单一设计,而是瞄准并聚焦于特定的需求。为帮助支持这一点，操作系统需要为这些应用程序提供新型的设施，使它们共同协作以创建更大的整体

8. 创建一个完全通用的操作系统。移动设备是通用计算的一种新的表现，而不是对传统桌面操作系统的简化。Android的设计应该足够丰富，从而使它至少能够像传统操作系统一样不断成长。

### 10.8.4 Android体系结构

Android建立在标准Linux内核之上，对内核本身只有少量重要的扩展。然而一旦进入用户空间，Android的实现与传统的Linux发行版具有相当大的不同，并且以非常不一样的方式使用Linux功能特性

如同传统的Linux系统一样，Android的第一个用户空间进程是init，它是所有其他进程的根。然而,Android的init启动的守护进程是不同的，这些守护进程更多地聚焦于底层细节(管理文件系统和硬件访问)，而不是高层用户设施。Android还有一层额外的进程，它们运行Dalvik的Java语言环境，负责执行系统中所有以Java实现的部分。init进程产生了一些底层守护进程。其中一个守护进程是zygote，它是高级Java语言进程的根

Android的init不以传统的方法运行shell,因为典型的Android设备没有本地控制台用于shell访问。作为替代，系统进程adbd监听请求shell访问的远程连接(例如通过USB)，按要求为它们创建shell进程

因为Android大部分是用Java语言编写的，所以zygote守护进程以及由它启动的进程是系统的中心。由zygote启动的第一个进程称为system_server，它包含全部核心操作系统服务，其关键部分是电源管理、包管理、窗口管理和活动管理

其他进程在需要的时候由zygote创建。这些进程中有一些是"持久的"进程，它们是基本操作系统的组成部分，例如phone进程中的电话栈，它必须保持始终运行。另外的应用程序进程将在系统运行的过程中按需创建和终止

应用程序通过调用操作系统提供的库与操作系统进行交互，这些库合起来构成**Android框架**。这些库中有一些可以在进程内部执行其工作，但是许多库需要与其他进程执行进程间通信,这通常是在system_server进程中提供服务的

### 10.8.5 Linux扩展

1. 唤醒锁

移动设备上的电源管理不同于传统的计算机系统，所以，为了管理系统如何进入睡眠，Android为Linux添加了一个新的功能，称为**唤醒锁**，也称为**悬停阻止器**

在传统的计算机系统上，系统可以处于两种电源状态之一：运行并且准备好处理用户输入；或者深度睡眠，并且如果没有诸如按下电源键一类的外部中断就不能继续执行。在运行的时候，次要的硬件设备可以按需要通电或者断电，但是CPU本身以及核心硬件部件必须保持通电状态以处理到来的网络通信以及其他类似的事件。进入低能耗睡眠状态是发生得比较少的事情：或者通过用户明确地让系统睡眠,或者由于比较长的时间间隔没有用户活动，从而系统自身进入睡眠。从这样的睡眠状态醒来需要来自外部源的硬件中断,例如按下键盘上的一个按键,在此刻设备将醒来并且点亮屏幕

移动设备的用户具有不同的期望。尽管用户可以关闭屏幕，在这样的情况下看起来好像是让设备睡眠了，但是传统的睡眠状态实际上并不是用户想得到的。当设备的屏幕关闭之时，设备仍然需要工作：它需要能够接听电话呼叫，接收并处理到来的聊天消息数据，以及许多其他事情

对于移动设备，关于打开和关闭设备屏幕的期望同样比传统的计算机具有更高的要求。移动交互趋向于在一整天中有许多次短时的突发，在这类移动应用中，恢复设备直到它能够使用的任何延迟都会对用户体验造成严重的负面影响

给定了这样的需求,一种解决方案或许仅仅是当设备的屏幕关闭之时不让CPU睡眠，这样它就总是准备好再次重新打开。归根到底，内核了解什么时候线程无需工作调度，并且Linux(以及大多数操作系统)将会自动地让CPU空闲，在这样的情况下使用较低的电能。

然而,空闲的CPU与真正的睡眠是不同的。例如：1.在许多芯片组上，空闲状态使用的电能比真正的睡眠状态要多得多；2.空闲的CPU可以在任何时刻唤醒,只要某些工作赶巧变得可用，即使该工作是不重要的；3.只是让CPU空闲并不意味着可以关闭其他硬件，而这样的硬件在真正的睡眠中是不需要的

Android上的唤醒锁允许系统进入深度睡眠模式，而不必与一个明确的用户活动(例如关闭屏幕)绑在一起。具有唤醒锁的系统的默认状态是睡眠状态。当设备在运行时，为了保持它不回到睡眠，则需要持有一个唤醒锁

当屏幕打开时，系统总是持有一个唤醒锁，这样就阻止了设备进入睡眠，所以它将保持运行，正如我们所期盼的

然而在屏幕关闭时，系统本身一般并不持有唤醒锁，所以只有在某些其他实体持有唤醒锁的条件下才能保持系统不进入睡眠。当没有唤醒锁被持有时，系统进入睡眠并且只能由于硬件中断才能将其从睡眠中唤醒

一旦系统已经进入睡眠，硬件中断可以将其再次唤醒，如同在传统操作系统中那样。这样的中断源有基于时间的警报、来自蜂窝无线电的事件(例如呼入的呼叫)、到来的网络通信以及按下特定的硬件按钮(例如电源按钮)。针对这些事件的中断处理程序要求对标准Linux做出一个改变:在处理完中断之后,它们需要获得一个初始的唤醒锁从而使系统保持运行

中断处理程序获得的唤醒锁必须持有足够长的时间，以便能够沿着栈向上将控制传递给内核中的驱动程序，由其继续对事件进行处理。然后内核驱动程序负责获得自己的唤醒锁，在此之后，中断唤醒锁可以安全地得到释放而不存在系统进入睡眠的风险

如果在这之后驱动程序将该事件向上传送到用户空间,则需要类似的握手。驱动程序必须确保继续持有唤醒锁直到它将事件传递给等待的用户进程，并且要确保存在使用户进程获得自己的唤醒锁的条件。这一流程可能还会在用户空间的子系统之间继续，只要某个实体持有唤醒锁，我们就继续执行想要的处理以便响应事件。然而一旦没有唤醒锁被持有，整个系统将返回睡眠并且所有进程停止

2. 内存不足杀手

Linux中的**内存不足杀手(out-of-memory Killer**)试图在内存极低时进行恢复。在现代操作系统上内存不足的情况是模糊的事情。由于有分页和交换，应用程序本身很难看到内存不足的错误。然而内核仍然可能进入这样一种情形，当需要的时候找不到可用的RAM页面，不但对新的分配会这样，而且在换入或者分页入某些正在使用的地址范围时也可能如此

在这样的低内存情形中，标准的Linux内存不足杀手是最后的应急手段，它试图找到RAM,使得内核能够继续处理它正在做的事情。做法是为每个进程分配一个"坏度"水平，并且简单地杀死最坏的进程。进程的环度基于进程正在使用的RAM数量、它已经运行了多长时间以及其他因素，目标是杀死大量但愿不太重要的进程

Android为内存不足杀手施加了特别的压力。它没有交换空间，所以它处于内存不足情形会更为常见：除非通过放弃从最近使用的存储器映射的干净的RAM页面，否则没有办法缓解内存压力。即便如此，Android还是使用标准Linux的配置，过度提交内存，也就是说，允许在RAM中分配地址空间而无需保证有可用的RAM对其提供后备。过度提交对于优化内存使用是一个极其重要的工具，这是因为mmap大文件(例如可执行文件)是很常见的，此处你只需要将该文件中全部数据的一小部分装入RAM

考虑到这样的情形，常备的Linux内存不足杀手工作得不太好，因为它更多地被预定为最后的应急手段，并且很难正确地识别合理的进程来杀死。事实上，正如我们在后面要讨论的，Android广泛地依赖定期运行内存不足杀手以收割(reap)进程，并且对于选择哪个进程的问题做出好的选择

为解决这一问题，Android为内核引入了自己的内存不足杀手,具有不同的语义和设计目标。Android的内存不足杀手运行得更加积极进取:只要RAM变"低"则运行。低的RAM是由一个可调整的参数标识的，该参数指示在内核中有多少空闲的和缓存的RAM是可接受的。当系统变得低于这个极限时，内存不足杀手便运行以便从别处释放RAM。目标是确保系统绝不会进入坏的分页状态，当前台应用程序竞争RAM时坏的分页状态会对用户体验造成负面影响，因为页面不断地换入换出会导致应用程序的执行变得非常缓慢

与试图猜测哪个进程应该被杀死不同，Android的内存不足杀手非常严格地依赖由用户空间提供给它的信息。传统的Linux内存不足杀手具有每个进程的oom_adj参数，通过修改进程的总体坏度得分，该参数可用来指导选择最佳的进程并将其杀死。Android的内存不足杀手使用这个相同的参数，但是具有严格的顺序:具有较高oom_adj的进程总是在那些具有较低oom_adj的进程之前被杀死

### 10.8.6 Dalvik

Dalvik在Android上实现了Java语言环境，它负责运行应用程序以及大部分系统代码。system_service进程中的几乎一切---从包管理器(package manager)，到窗口管理器(window manager)，再到活动管理器)(activity manager)---都是由Dalvik执行的Java语言代码实现的

然而Android并不是传统意义上的Java语言平台。Android应用程序中的Java代码是由Dalvik的字节代码格式提供的，这是基于寄存器机器的字节代码，而不是传统的基于栈的字节代码。Dalvik的字节代码格式允许更快的解释，与此同时仍然支持**JIT(Just-In-Time，及时)编译**。通过使用串共用和其他技术，Dalvik字节代码还更加节省空间，无论是在磁盘上还是在RAM中

编写Java应用程序时，源代码是用Java编写的，然后使用传统的Java工具将其编译成标准Java字节代码。在此之后，Android引入了一个新的步骤:将Java字节代码转换成Dalvik的更加紧凑的字节代码表示。应用程序的Dalvik字节代码版本封装成最后的应用程序二进制文件并且最终安装在设备上

Android的系统体系结构高度依赖Linux的系统原语，包括内存管理、安全以及跨安全边界的通信。对于核心操作系统概念，Android并不使用Java语言，以此试图将底层Linux操作系统这些重要的部分加以抽象

特别值得注意的是Android对于进程的使用。Android的设计并不依赖Java语言将应用程序与系统相隔离，相反它采取传统的操作系统方法进行进程隔离。这意味着，每个应用程序运行在自己的Linux进程中，具有自己的Dalvik环境，system_server和平台的其他核心部分就是用Java编写的

使用进程进行这样的隔离使得Android能够借力于Linux的功能特性来管理进程，从内存隔离到当进程结束时清除与进程相关的所有资源，都是如此。除了进程以外，Android还排他地依赖于Linux的安全特性,而不是使用Java的SecurityManager体系结构

Linux进程和安全的应用大大简化了Dalvik环境，因为它不再需要负责系统稳定性和健壮性这些关键的方面。并非偶然地，它还允许应用程序在它们的实现中自由地使用本机代码，这对于游戏特别重要,因为游戏通常建立在基于C++的引擎之上

像这般混合进程和Java语言确实引入了某些挑战。即便在现代移动硬件之上，也需要花费一秒钟启动全新的Java语言环境。Android的设计目标之一是能够以200ms为目标快速启动应用程序。要求为新的应用程序启动全新的Dalvik进程将会大大超出预算。就算是不需要初始化一个新的Java语言环境，200ms启动在移动硬件上也很难达到。这一问题的答案是zygote本机守护进程。zygote负责启动并初始化Dalvik到一个阶段，在此处已做好准备开始运行用Java写的系统或应用程序代码。所有基于Dalvik的新进程(系统或应用程序)都是从zygote创建的，使得它们能够在环境已经准备就绪的条件下开始执行

由zygote启动的不仅仅是Dalvik。zygote还预装载了Android框架的许多部分，这些部分对于系统和应用程序而言是公共的，并且zygote还装载了经常需要使用的资源和其他东西

注意从zygote创建新进程涉及Linux的fork，但是不存在exec调用。新进程是最初zygote进程的复制品，拥有已经建立好的所有预初始化状态,并且做好了运行的准备。新的Java应用程序进程与最初的zygote进程相联系：调用fork之后，新进程有了自己单独的Dalvik环境，只是它与zygote通过写时复制页面共享预装载和初始化的数据。现在让新的可运行进程准备就绪所剩下的所有事情是给它一个正确的标识(UID等)，完成Dalvik启动线程所需要的初始化工作，以及装载妥运仃的应用程序或系统代码

除了启动速度，zygote还带来了另外一个好处。因为只使用fork从zygote创建进程，所以初始化Dalvik并且预装载类和资源所需要的大量脏RAM页面可以在zygote与它的所有子进程之间共享。这样的共享对于Android环境尤其重要，因为交换是不可用的，而从"磁盘"(闪存)按需分页干净的页面(例如可执行代码)是可用的。然而任何脏页面必须在RAM中保持锁定，它们不能分页换出到"磁盘"上

### 10.8.7 Binder IPC

Android的系统设计特别围绕进程隔离，不但在应用程序之间，而且在系统本身的不同部分之间隔离进程。这就要求进行大量的进程间通信，从而在不同的进程之间实现协同，这需要做大量的工作并得到正确的结果。Android的Binder进程间通信机制是一个丰富的通用IPC设施，Android系统的大部分就建立在该设施之上

Binder体系结构分为三个层次：在栈的最底层是一个内核模块，实现了实际的跨进程交互，并且通过内核的ioctl函数将其展露(ioctl是一个通用的内核调用，用来发送定制的命令给内核驱动程序和模块。)在内核模块之上，是一个基本的面向对象的用户空间API，允许应用程序通过IBinder和Binder类创建并且与IPC端点进行交互。在顶部是一个基于接口的编程模型,应用程序在其中声明它们的IPC接口,并且不再需要关心IPC在底层是如何发生的细节问题

### 10.8.8 Android应用

Andriod提供的应用模型与Linux脚本下的普通命令行环境以及从图形用户界面启动的应用程序有很大的不同。应用程序不再是一个具有主入口的可执行文件，而是一个包含了构成应用程序的所有元素的容器：程序的代码，图形资源,对系统的声明,以及其他数据

按照约定，Andriod应用程序是一个以apk为扩展名的文件，称为**Android包**。这个文件实际上是一个普通的zip压缩文件，包含了与应用程序相关的所有内容。apk文件中的重要文件内容包括：1.一个描述应用程序是什么、做什么以及如何运行的清单。清单必须为应用程序提供一个包名称,即一个Java类型的作用域字符串，以便唯一地标识这个应用程序；2.应用程序所需要的资源，包括显示给用户的字符串，与布局等描述相关的XML数据，图形位图等等；3.代码本身,这可能是Dalvik字节码以及本地库代码；4.签名信息,以安全地标识作者

**包管理器**是Andriod中用于跟踪所有的应用程序包的部件。它解析每个应用程序的清单，收集和索引清单中的信息。利用这些信息，可以方便用户查询当前安装的应用程序，并检索与这些应用相关的信息。它还负责程序的安装(为应用程序创建存储空间并确保apk的完整性)，以及程序的卸载(清理与以前安装的应用程序相关的所有内容)

应用程序在清单中静态地声明它们的入口,因此它们在安装过程中向系统注册时并不需要执行代码。这种设计使得系统在许多方面更加健壮：安装应用程序时不需要执行任何程序代码，通过查看清单即可确定应用程序的顶层功能，不需要保留关于应用程序的功能信息的独立数据库(独立的数据库可能与应用程序的实际功能失去同步(例如跨更新)，并且可保证在卸载后不会有与应用程序相关的信息留下)。这种去中心化的方法可以避免Windows的中心化注册表所导致的这类问题

将应用程序分解为更细粒度的组件也有助于实现支持应用程序之间互操作和协作的设计目标。应用程序可以按照片段的形式发布特定的功能，其他应用程序也可以直接或者间接地利用这些功能

在包管理器之上的是另一个重要的系统服务---**活动管理器**。包管理器负责维护所有已安装的应用程序的静态信息，而活动管理器决定这些应用程序应该何时、何处和如何运行。除了它的字面意义，它实际上负责运行四种类型的应用程序组件，并实现每种组件相应的行为：

1. **活动(activity**)是应用程序通过用户界面与用户直接交互的部分。当用户在其设备上启动应用程序时，实际上应用程序中的一个活动已被指定为主入口。应用程序执行了这个活动中负责与用户交互的代码

2. **服务(service**)有两种不同的身份：1.它可以是一个自包含的长期运行的后台操作。以这种方式提供服务的常见例子是重复播放后台音乐，在用户使用其他应用时维持主动的网络连接(例如与IRC服务器)，在后台下载或上传数据等；2.它可以作为其他应用或者系统与当前应用程序发生丰富交互的连接点。这可以被应用程序用来为其他程序提供安全的API，例如执行图像或者音频的处理、提供文本到语音的转换等

3. **接收器(receiver**)是发生的(通常是外部的)事件的接收者，这些事件一般发生在后台和正常的用户交互之外。接收器在概念上与明确注册的在感兴趣事件(例如报警关闭、数据连接更改等)发生时可回调的应用程序相同，但是不需要应用程序一直运行以接收事件

4. **内容提供器(content provider)**：最后一个应用程序组件内容提供备，是应用程序之间彼此交换数据的主要机制。与内容提供器之间的所有交互都是通过"content:主题"这种URI完成的,URI的权限是用来找到正确的可交互的内容提供器

### 10.8.9 意图

< intent-filter >标签及包含它的活动和接收器的声明是Android的**意图(intent**)功能的一部分，也是不同应用程序之间能够互相识别以便进行交互和协同工作的基础

意图是Android用来发现和识别活动、接收器和服务的机制。它在某些方面与Linux shell的搜索路径比较相似。利用搜索路径，shell在多个可能的目录中进行搜索，寻找与传给它的命令名相匹配的可执行文件

意图主要分两种:显式意图和隐式意图

**显式意图**直接指定一个准确的应用程序组件，相当于在Linux shell中给一条指令提供一条绝对路径。对于显式意图，最重要的是两个用来命名组件的字符串:目标应用程序的封装名，以及该应用程序中组件的类名。用一个显式意图的封装名和类名就能获得足够信息来识别唯一的目标组件。封装管理器可以通过封装名来返回应用程序需要的任何信息，例如源码位置等。通过类名，可以得知需要执行的是哪部分源码

**隐式意图**描述所需组件的特点，而并不直接指向该组件。这相当于在Linux shell中，给shell提供一条指令名，随后shell使用搜索路径来寻找一条待运行的具体指令。这个寻找与隐式意图相匹配的组件的过程叫作**意图解析**

### 10.8.10 应用程序沙箱

应用程序其实是由其开发者作为一个访客运行在用户的设备上的。因此在没有得到用户的确切允许之前，应用程序在接触任何敏感信息时是不受信任的

在Android的实现中，这个理念通过用户ID相当直接地表达出来。当安装一个Android应用程序时,为其新创造一个独特的Linux用户ID(也称UID),该应用程序的所有源码是以该新"用户"的名义运行的。这样Linux用户ID为每个应用程序创造一个沙箱，配备各自的隔离区来储存文件系统，如同为用户在桌面系统中创造沙箱一样。换言之，Android创新地活用了Linux中已有的一个功能，造成了隔离性更好的结果

### 10.8.11 安全性

Android的应用程序安全性围绕着UID展开。在Linux中，每个进程在运行时拥有一个独特的UID,Android使用UID来识别与保护安全屏障。进程进行交互的唯一手段是利用跨进程通信(IPC)机制，携带足以使它识别调用者的信息。捆绑(binder)IPC在每个跨进程的事务中明确包含了这些信息，确保IPC的接收者能简单地请求调用者的UID

### 10.8.12 进程模型

Linux的传统进程模型是用fork指令来创建新进程，然后用exec指令使用待运行的源码初始化该进程并开始执行。shell负责实现进程执行、创建新进程、执行所需的进程来运行shell指令。当指令结束时,进程被从Linux中移除

Android使用的进程有些不同。在之前的应用程序章节中已有讨论,活动管理器是Android负责正在运行的应用程序的管理的一部分。活动管理器协调新应用程序进程的启动，决定哪些应用程序能在其中运行,哪些已不再需要

1. 启动进程：为了启动新进程，活动管理器需要与zygote通信。活动管理器首先开始，它创建一个与zygote相连的专用接口，通过接口发送一条指令，表示它需要启动一个进程。这条指令主要描述需要创建的沙箱:新进程运行所需的UID，以及需要遵守的安全性制约。zygote需要作为根来运行:创建新进程时，它合理配置运行所需的UID，最终下放根权限，将进程改为该UID

2. 进程生命周期：活动管理器也负责判断何时进程不再被需要。活动管理器记录一个进程中运行的所有活动、接收器、服务以及内容提供器,据此可判断该进程的重要程度。回想Android内核中的内存溢出强制结束指令，使用一个进程的oom_adj进行严格排序，决定哪个进程需要优先强制结束。活动管理器负责基于每个进程的状态，通过将其归类于几个主要用途，从而合理设定其oom_adj

3. 进程依赖性：现在我们已经全面了解了单个Android进程是如何管理的。然而，存在一个复杂化的问题:进程之间的依赖性。进程依赖性会影响两个关键事实:何时创建进程(以及进程内部的组件)，进程的oom_adj重要程度值是什么。回想一个进程的重要性取决于其中最重要的组件，一个进程的重要性还取决于依赖它的最重要的其他进程。为了计算每个进程的最终重要程度，系统需要维护进程之间的依赖图。每个进程都有其中正在运行的服务与内容提供器列表，而每个服务与内容提供器则有正在使用它的其他进程列表。(这些列表在活动管理器内部进行维护，所以应用程序不可能伪造列表。)遍历一个进程的依赖图时，需要遍历该进程的所有服务和内容提供器，以及使用这些服务和内容提供器的所有其他进程

## 10.9 小结

Linux一开始是一个开源的类UNIX系统，而今天它已经广泛应用于各种系统，从智能手机和笔记本到超级计算机。它有三种主要接口:shell、C函数库和系统调用。此外，通常使用图形用户界面以简化用户与系统的交互。shell允许用户输入命令来执行。这些命令可能是简单的命令、管线或者复杂的命令结构。输入和输出可以被重定向。C函数库包括了系统调用和许多增强的调用，例如用于格式化输出的printf。实际的系统调用接口是依赖于体系结构的，在x86平台上大约有250个系统调用，每个系统调用做需要做的事情,不会做多余的事情

Linux中的关键概念包括进程、内存模型、I/O和文件系统。进程可以创建子进程，形成一棵进程树。Linux中的进程管理与其他的UNIX系统不太一样，Linux系统把每一个执行体——单线程进程，或者多线程进程中的每一个线程或者内核——看做不同的任务。一个进程，或者统称为一个任务，通过两个关键的部分来表示，即任务结构和描述用户地址空间的附加信息。前者常驻内存，后者可能被换出内存。进程创建是通过复制父进程的任务结构，然后将内存映像信息设置为指向父进程的内存映像。内存映像页面的真正复制仅当在共享不允许和需要修改内存单元时发生。这种机制称为写时复制。进程调度是通过加权公平队列算法实现的，而该算法使用一个红黑树来负责任务的队列管理

每个进程的内存模型由三个部分组成:代码、数据和堆栈。内存管理采用分页式。一个常驻内存的表跟踪每一页的状态，页面守护进程采用一种修改过的双指针时钟算法保证系统有足够多的空闲页

可以通过特殊文件访问I/O设备，每个设备都有一个主设备号和次设备号。块设备I/O使用内存缓存磁盘块，以减少访问磁盘的次数。字符I/O可以工作在原始模式，或者字符流可以通过行规则加以修改。网络设备稍有不同，它关联了整个网络协议模块来处理网络数据包流

文件系统由文件和目录所组成的层次结构组成。所有磁盘都挂载到一个有唯一根的目录树中。文件可以从文件系统的其他地方连接到一个目录下。要使用文件，首先要打开文件，这会产生一个文件描述符用于接下来的读和写。文件系统内部主要使用三种表:文件描述符表、打开文件描述表和i节点表。其中i节点表是最重要的表，包含了文件管理所需要的所有信息和文件位置信息。目录和设备，以及其他特殊文件也都表示为文件

保护基于对所有者、同组用户和其他人的读、写和执行的访问控制。对目录而言，执行位指示是否允许搜索

Android是一个允许应用程序在移动设备上运行的平台。它基于Linux内核，但在Linux的上层由一个庞大的软件体组成，并对Linux的内核进行了少量的修改。Android的大部分代码是用Java写的，应用程序也是用Java写的，然后依次被编译成Java字节码和Dalvik字节码。Android应用程序的通信是通过一种受保护的消息传递实现的，这种消息传递被称为消息事务。所谓的Binder则是一种特殊的Linux内核模型，用来处理进程间的通信

Android软件包是自包含的，并含有一个用来描述包中内容的说明文件。它包含了活动(activities)、接收器(receivers)、内容提供器(content providers)和意图(intent)。Android的安全模型与Linux模型不同，它对每个应用程序都使用了沙箱技术，因为所有的应用程序均被视为不可信的