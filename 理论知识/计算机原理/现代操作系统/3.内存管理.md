- [3. 内存管理](#3-内存管理)
	- [3.1 无存储器抽象](#31-无存储器抽象)
	- [3.2 一种存储器抽象：地址空间](#32-一种存储器抽象地址空间)
		- [3.2.1 地址空间的概念](#321-地址空间的概念)
		- [3.2.2 交换技术](#322-交换技术)
		- [3.2.3 空闲内存管理](#323-空闲内存管理)
	- [3.3 虚拟内存](#33-虚拟内存)
		- [3.3.1 分页](#331-分页)
		- [3.3.2 页表](#332-页表)
		- [3.3.3 加速分页过程](#333-加速分页过程)
		- [3.3.4 针对大内存的页表](#334-针对大内存的页表)
	- [3.4 页面置换算法](#34-页面置换算法)
		- [3.4.1 最优页面置换算法](#341-最优页面置换算法)
		- [3.4.2 最近未使用页面置换算法](#342-最近未使用页面置换算法)
		- [3.4.3 先进先出页面置换算法](#343-先进先出页面置换算法)
		- [3.4.4 第二次机会页面置换算法](#344-第二次机会页面置换算法)
		- [3.4.5 时钟页面置换算法](#345-时钟页面置换算法)
		- [3.4.6 最近最少使用页面置换算法](#346-最近最少使用页面置换算法)
		- [3.4.7 用软件模拟LRU](#347-用软件模拟lru)
		- [3.4.8 工作集页面置换算法](#348-工作集页面置换算法)
		- [3.4.9 工作集时钟页面置换算法](#349-工作集时钟页面置换算法)
		- [3.4.10 页面置换算法小结](#3410-页面置换算法小结)
	- [3.5 分页系统中的设计问题](#35-分页系统中的设计问题)
		- [3.5.1 局部分配策略与全局分配策略](#351-局部分配策略与全局分配策略)
		- [3.5.2 负载控制](#352-负载控制)
		- [3.5.3 页面大小](#353-页面大小)
		- [3.5.4 分离的指令空间和数据空间](#354-分离的指令空间和数据空间)
		- [3.5.5 共享页面](#355-共享页面)
		- [3.5.6 共享库](#356-共享库)
		- [3.5.7 内存映射文件](#357-内存映射文件)
		- [3.5.8 清除策略](#358-清除策略)
		- [3.5.9 虚拟内存接口](#359-虚拟内存接口)
	- [3.6 有关实现的问题](#36-有关实现的问题)
		- [3.6.1 与分页有关的工作](#361-与分页有关的工作)
		- [3.6.2 缺页中断处理](#362-缺页中断处理)
		- [3.6.3 指令备份](#363-指令备份)
		- [3.6.4 锁定内存中的页面](#364-锁定内存中的页面)
		- [3.6.5 后备存储](#365-后备存储)
		- [3.6.6 策略和机制的分离](#366-策略和机制的分离)
	- [3.7 分段](#37-分段)
		- [3.7.1 纯分段的实现](#371-纯分段的实现)
		- [3.7.2 分段和分页的结合：MULTICS](#372-分段和分页的结合multics)
		- [3.7.3 分段和分页的结合：Intel x86](#373-分段和分页的结合intel-x86)
	- [3.9 小结](#39-小结)

# 3. 内存管理

**存储管理器**：操作系统中管理分层存储体系的部分，任务是有效地管理内存(即记录哪些内存是正在使用的，哪些内存是空闲的)；在进程需要时为其分配内存，在进程使用后释放内存

## 3.1 无存储器抽象

**BIOS**：基本输入输出系统，在ROM中的设备驱动程序

**静态重定位**：当一个使用绝对物理地址的程序被装载到地址n时，常数n被加到程序中的每一个地址上。但这不是一种通用的解决方法，同时会减慢装载速度。而且要求给所有的可执行程序提供额外的信息来区分哪些内存字中存有(可重定位的)地址

## 3.2 一种存储器抽象：地址空间

把物理地址暴露给进程带来的问题：第一，如果用户程序可以寻址内存的每个字节，他们就可以很容易地破坏操作系统，从而使系统慢慢停止运行。即使在只有一个用户进程运行的情况下，这个问题也是存在的。第二，使用这种模型，想要同时运行多个程序是很困难的

### 3.2.1 地址空间的概念

要使多个应用程序同时处于内存中并且不互相影响，需要解决两个问题：**保护**和**重定位**

**地址空间**：是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间(除了在一些特殊情况下进程需要共享它们的地址空间外)

**动态重定位**：简单地把每个进程的地址空间映射到物理内存的不同部分，给每个CPU配置**基址寄存器**和**界限寄存器**。当一个程序运行时，程序的物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中。每次一个进程访问内存,取一条指令,读或写一个数据字,CPU硬件会在把地址发送到内存总线前,自动把基址值加到进程发出的地址值上。同时,它检查程序提供的地址是否等于或大于界限寄存器里的值。如果访问的地址超过了界限,会产生错误并中止访问。

使用基址寄存器和界限寄存器重定位的缺点是,每次访问内存都需要进行加法和比较运算。比较运算可以做得很快,但是加法运算由于进位传递时间的问题,在没有使用特殊电路的情况下会显得很慢。

### 3.2.2 交换技术

有两种处理内存超载的通用方法。最简单的策略是**交换**技术,即把一个进程完整调入内存,使该进程运行一段时间,然后把它存回磁盘。空闲进程主要存储在磁盘上,所以当它们不运行时就不会占用内存。另一种策略是**虚拟内存**,该策略甚至能使程序在只有一部分被调入内存的情况下运行。

以下讨论交换技术

**内存紧缩**：交换在内存中产生了多个空闲区(hole,也称为空洞)，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合并。通常不进行这个操作，因为它要耗费大量的CPU时间

### 3.2.3 空闲内存管理

1. 使用位图的存储管理

使用位图方法时,内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位,0表示空闲,1表示占用(或者相反)

分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。若进程大大小不是分配单元的整数倍，那么在最后一个分配单元中就会有一定数量的内存被浪费了

缺点：在决定把一个占k个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有k个连续0的串。查找位图中指定长度的连续0串是耗时的操作(因为在位图中该串可能跨越字的边界)

2. 使用链表的存储管理

维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个节点或者包含一个进程，或是两个进程间的一块空闲区。链表中的每一个节点都包含以下区域：空闲区或进程的指示标志、起始地址、长度和指向下一节点的指针

为创建的进程分配内存的算法↓：

首次适配：存储管理器沿着段链表进行搜索，直到找到一个足够大的空闲区，除非空闲区大小和要分配的空间大小正好一样，否则将该空闲区分为两部分，一部分供进程使用，另一部分形成新的空闲区。首次适配算法是一种速度很快的算法，因为它尽可能少地搜索链表结点

下次适配：工作方式和首次适配算法相同，不同点是每次找到合适的空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次适配算法那样每次都从头开始。下次适配算法的性能略低于首次适配算法

最佳适配：最佳适配算法搜索整个链表，找出能够容纳进程的最小的空闲区。试图找出最接近实际需要的空闲区，以最好地匹配请求和可用空闲区，而不是先拆分一个以后可能会用到的大的空闲区

因为每次调用最佳适配算法时都要搜索整个链表，所以它要比首次适配算法慢。最佳适配算法比首次适配算法或下次适配算法浪费更多的内存，因为它会产生大量无用的小空闲区。一般情况下，首次适配算法生成的空闲区更大一些

最差适配：总是分配最大的可用空闲区，使新的空闲区比较大从而可以继续使用。仿真程序表明最差适配算法也不是一个好主意

快速适配：为那些常用大小的空闲区维护单独的链表。例如有一个n项的表，该表的第一项指向大小为4KB的空闲区链表表头的指针，第二项是指向大小为8KB的空闲区链表表头的指针，以此类推。快速适配算法寻找一个指定大小的空闲区是十分快速的，但它和所有将空闲区按大小排序的方案一样，都有一个共同的缺点，即在一个进程终止或被换出时，寻找它的相邻块并查看是否可以合并的过程是非常耗时的。如果不进行合并，内存将会很快分裂出大量的进程无法利用的小空闲区

## 3.3 虚拟内存

**覆盖**：把程序分割成许多片段。程序开始执行时，将覆盖管理程序模块装入内存，该管理模块立即装入并运行覆盖0。执行完成后,覆盖0通知管理模块装入覆盖1,或者占用覆盖0的上方位置(如果有空间),或者占用覆盖0(如果没有空间)。一些覆盖系统非常复杂,允许多个覆盖块同时在内存中。覆盖块存放在磁盘上,在需要时由操作系统动态地换入换出。

**虚拟内存**：基本思想是每个程序拥有自己的地址空间,这个空间被分割成多个块,每一块称作一页或页面。每一页有连续的地址范围。这些页被映射到物理内存,但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时,由硬件立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时,由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

虚拟内存使得整个地址空间可以用相对较小的单元映射到物理内存，而不是为正文段和数据段分别进行重定位

### 3.3.1 分页

地址可以通过索引、基址寄存器、段寄存器或其他方式产生。有程序产生的地址称为**虚拟地址**，它们构成了一个**虚拟地址空间**。在没有虚拟内存的情况下，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元(MMU)**,MMU把虚拟地址映射为物理内存地址

虚拟地址空间按照固定大小划分成被称为**页面(page**)的若干单元。在物理内存中对应的单元称为**页框(page frame)**。页面和页框的大小通常是一样的。在实际系统中的页面大小从512字节到1G。RAM和磁盘之间的交换总是以整个页面为单元进行的。很多处理器根据操作系统认为适合的方式，支持对不同大小页面的混合使用和匹配。

在实际的硬件中，用一个标志位记录页面在内存中的实际存在情况。若程序访问了一个未映射的页面，MMU注意到该页面没有被映射，于是使CPU陷入到操作系统，这个陷阱称为**缺页中断**或**缺页错误**。操作系统找到一个很少使用的页框且把它的内容写入磁盘(如果它不在磁盘上)。随后把需要访问的页面读到刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令

在16个4KB页面情况下的MMU中，输入的16位虚拟地址被分为4位的页号和12位的偏移量。4位的页号可以表示16个页面，12位的偏移可以为一页内的全部4096个字节编址。可用页号作为页表的索引，以得出对应于该虚拟页面的页框号。如果存在标志位为0，则将引起一个操作系统陷阱，如果存在标志位为1，则将在页表中查到的页框号复制到输出寄存器的高3位中，再加上输入虚拟地址中的低12位偏移量。如此就构成了15位的物理地址。输出寄存器的内存随即被作为物理地址送到内存总线

### 3.3.2 页表

页表作为一种最简单的实现，虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号(高位部分)和偏移量(低位部分)。不同的划分对应不同的页面大小

虚拟页号可用作页表的索引,以找到该虚拟页面对应的页表项。由页表项可以找到页框号(如果有的话)。然后把页框号拼接到偏移量的高位端,以替换掉虚拟页号,形成送往内存的物理地址。

页表的目的是把虚拟页面映射为页框。从数学角度说,页表是一个函数,它的参数是虚拟页号,结果是物理页框号。通过这个函数可以把虚拟地址中的虚拉页面域替换成页框域,从而形成物理地址。

在本章中,我们只关心虚拟内存和不完全虚拟化,换言之,不涉及虚拟机。我们在第7章中将会看到,每个虚拟机都需要自己的虚拟内存,因此页表组织变得很复杂,包括影子页表和嵌套页表。我们会看到,即使没有这些复杂的配置,页面调度和虚拟内存也相当复杂。

页表项的结构与机器密切相关，但不同机器的页表项存储的信息都大致相同。

* 页表项的结构

**页框号**：页映射的目的是找到这个值

**存在标志位**：这一位是1时表示该表项是有效的，可以使用；如果是0，则表示该表项对应的虚拟页面现在不在内存中，访问该页面会引起一个缺页中断

**保护位**：指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。一个更先进的方法是使用三位，各位分别对应是否启用读、写、执行该页面。

**修改位**：在写入一页时由硬件自动设置修改位。该位在操作系统重新分配页框时是非常有用的。如果一个页面已经被修改过(即它是"脏"的)，则必须把它写回磁盘。如果一个页面没有被修改过(即它是"干净"的)，则只简单地把它丢弃就可以了，因为它在磁盘上的副本仍然是有效的。这一位有时也被称为**脏位**，因为它反映了该页面的状态。

**访问位**：不论是读还是写，系统都会在该页面被访问时设置访问位。它的值被用来帮助操作系统在发生缺页中断时选择要被淘汰的页面。不再使用的页面要比正在使用的页面更适合淘汰。这一位在即将讨论的很多页面置换算法中都会起到重要的作用

**高速缓存禁止位**：最后一位用于禁止该页面被高速缓存。对那些映射到设备寄存器而不是常规内存的页面而言,这个特性是非常重要的。假如操作系统正在紧张地循环等待某个I/O设备对它刚发出的命令作出响应,保证硬件是不断地从设备中读取数据而不是访问一个旧的被高速缓存的副本是非常重要的。通过这一位可以禁止高速缓存。具有独立的I/O空间而不使用内存映射I/O的机器不需要这一位。

虚拟内存本质上是用来创造一个新的抽象概念---地址空间,这个概念是对物理内存的抽象,类似于进程是对物理处理器(CPU)的抽象。虚拟内存的实现,是将虚拟地址空间分解成页,并将每一页映射到物理内存的某个页框或者(暂时)解除映射。因此，本节的基本内容是操作系统创建的抽象，以及如何管理这个抽象

### 3.3.3 加速分页过程

在任何分页系统中，都需要考虑两个主要问题：

1. 虚拟地址到物理地址的映射必须非常快：由于每次访问内存都需要进行虚拟地址到物理地址的映射,所有的指令最终都必须来自内存,并且很多指令也会访问内存中的操作数。因此,每条指令进行一两次或更多页表访问是必要的。如果执行一条指令需要1ns,页表查询必须在0.2ns之内完成,以避免映射成为一个主要瓶颈。

2. 如果虚拟地址空间很大，页表也会很大：现代计算机使用至少32位的虚拟地址,而且64位变得越来越普遍。假设页面大小为4KB,32位的地址空间将有100万页,而64位地址空间简直多到超乎你的想象。如果虚拟地址空间中有100万页,那么页表必然有100万条表项。另外请记住,每个进程都需要自己的页表(因为它有自己的虚拟地址空间)

对大而快速的页映射的需求成为构建计算机的重要约束。最简单的设计(至少从概念上)是使用由"快速硬件寄存器"阵列组成的单一页表,每一个表项对应一个虚拟页面,虚拟页号作为索引。当启动一个进程时,操作系统把保存在内存中的进程页表的副本载入到寄存器中。在进程运行过程中,不必再为页表而访问内存。这个方法的优势是简单并且在映射过程中不需要访问内存。而缺点是在页表很大时，代价高昂。而且每一次上下文切换都必须装载整个页表,这样会降低性能。另一种极端方法是,整个页表都在内存中。那时所需的硬件仅仅是一个指向页表起始位置的寄存器。这样的设计使得在上下文切换时,进行"虚拟地址到物理地址"的映射只需重新装入一个寄存器。当然,这种做法的缺陷是在执行每条指令时,都需要一次或多次内存访问来完成页表项的读入,速度非常慢。

本节介绍加速虚拟地址到物理地址的映射方法

* 转换检测缓冲区(TLB)

解决加速分页问题：大多数优化技术都是从内存中的页表开始。该解决方案的建立基于这样一种观察：大多数程序总是对少量的页面进行多次的访问，而不是相反。因此，只有很少的页表项会被反复读取，而其他的页表项很少被访问。解决方案是为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为**转换检测缓冲区(TLB)**，有时又称为**相联存储器**或**快表**。它通常在MMU中，包含少量的表项。每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码(读/写/执行权限)和该页所对应的物理页框。除了虚拟页号(不是必须放在页表中)，这些域与页表中的域是一一对应的。另外还有一位用来记录这个表项是否有效(即是否在使用)。

**TLB的工作流程**：将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时(即并行)进行匹配，判断虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作并不违反保护位，则将页框号直接从TLB中取出而不必在访问页表。如果虚拟页号在TLB中，但指令试图在一个只读页面上进行写操作，则会产生一个保护错误，就像对页表进行非法访问一样。如果MMU检测到没有有效的匹配项，就会进行正常的页表查询。接着从TLB中淘汰一个表项，然后用新找到的页表项代替它。这样，如果这一页面很快被再次访问，第二次访问TLB时自然将会命中而不是未命中。当一个表项被清除出TLB时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项从页表中装入TLB中时，所有的值都来自内存

* 软件TLB管理

之前可以假设每一台具有虚拟内存的机器都具有由硬件识别的页表，以及一个TLB。在这种设计中，对TLB的管理和TLB的失效处理都完全由MMU硬件来实现。只有在内存中没有找到某个页面时，才会陷入到操作系统中。但是在现代的RISC机器中，几乎所有的页面管理都是在软件中实现的。在这些机器上,TLB表项被操作系统显式地装载。当发生TLB访问失效时,不再是由MMU到页表中查找并取出需要的页表项,而是生成一个TLB失效并将问题交给操作系统解决。系统必须先找到该页面,然后从TLB中删除一个项,接着装载一个新的项,最后再执行先前出错的指令。当然,所有这一切都必须在有限的几条指令中完成,因为TLB失效比缺页中断发生得更加频繁。

如果TLB达到可以减少失效率时，TLB的软件管理就会变得足够有效。这种方法的最主要的好处是获得了一个非常简单的MMU，这就在CPU芯片上为高速缓存以及其他改善性能的设计腾出了相当大的空间

无论是用硬件还是用软件来处理TLB失效,常见方法都是找到页表并执行索引操作以定位将要访问的页面。用软件做这样的搜索的问题是,页表可能不在TLB中,这就会导致处理过程中的额外的TLB失效。可以通过在内存中的固定位置维护一个大的(如4KB)TLB表项的软件高速缓存(该高速缓存的页面一直保存在TLB中)来减少TLB失效。通过首先检查软件高速缓存,操作系统能够实质性地减少TLB失效。

当使用软件TLB管理时,一个基本要求是要理解两种不同的TLB失效的区别在哪里。当一个页面访问在内存中而不在TLB中时,将产生**软失效**。那么此时所要做的就是更新一下TLB,不需要产生磁盘I/O。典型的处理需要10~20个机器指令并花费几纳秒完成操作。相反,当页面本身不在内存中(当然也不在TLB中)时,将产生**硬失效**。此刻需要一次磁盘存取以装入该页面,这个过程大概需要几毫秒。硬失效的处理时间往往是软失效的百万倍。在页表结构中查找相应的映射被称为**页表遍历**

实际中遇到的情况可能会更加复杂,未命中的情况可能既不是软失效也不是硬失效。一些未命中相比其他未命中会更"软"(或更"硬")。举例来说,假设页表遍历没有在进程的页表中找到需要的页,从而引发了一个缺页错误,那么这时有三种可能。第一种,所需的页面可能就在内存中,但却未记录在该进程的页表里。比如该页面可能已由其他进程从硬盘中调入内存,这种情况下只需要把所需的页面正确映射到页表中,而不用再从硬盘调入。这是一种典型的软失效,称为**次要缺页错误**。第二种,如果需要从硬盘重新调入页面,这就是**严重缺页错误**。第三种,程序可能访问了一个非法地址,根本不需要向TLB中新增映射。此时,操作系统一般会通过报告**段错误**来终止该程序。只有第三种缺页属于程序错误,其他缺页情况都会被硬件或操作系统以降低性能为代价而自动修复。

### 3.3.4 针对大内存的页表

在原有的内存页表的方案之上,引入TLB可以加快虚拟地址到物理地址的转换。不过这不是唯一需要解决的问题。另一个问题是怎样处理巨大的虚拟地址空间。下面将讨论两种解决方法

1. 多级页表

将虚拟地址划分为更多的域。比如将32位的虚拟地址划分为10位的PT1域、10位的PT2域和12位的Offset(偏移量)域。PT1域作为访问顶级页表的索引，得到的表项含有二级页表的地址或者页框号。PT2域作为访问二级页表的索引，得到的表项为该虚拟页面对应的页框号。如果该页面不再内存中，页表项的存在标志位将是0，引发一次缺页中断。如果该页面在内存中，从二级页表中得到的页框号将与偏移量结合型号才能物理地址。该地址被放到总线上并送到内存中

2. 倒排页表

针对页式调度层级不断增长的另一种解决方案是**倒排页表**。在这种设计中,实际内存中的每个页框对应一个表项,而不是每个虚拟页面对应一个表项。表项记录了哪一个(进程,虚拟页面)对定位于该页框。

虽然倒排页表节省了大量的空间(至少当虚拟地址空间比物理内存大得多的时候是这样的),但它也有严重的不足:从虚拟地址到物理地址的转换会变得很困难。当进程n访问虚拟页面p时,硬件不再能通过把p当作指向页表的一个索引来查找物理页框。取而代之的是,它必须搜索整个倒排页表来查找某一个表项(n,p)。此外,该搜索必须对每一个内存访问操作都要执行一次,而不仅仅是在发生缺页中断时执行。每次内存访问操作都要查找一个256K的表不是一种使机器快速运行的方法。

走出这种两难局面的办法是使用TLB。如果TLB能够记录所有频繁使用的页面,地址转换就可能变得像通常的页表一样快。但是,当发生TLB失效时,需要用软件搜索整个倒排页表。实现该搜索的一个可行的方法是建立一张散列表,用虚拟地址来散列。当前所有在内存中的具有相同散列值的虚拟页面被链接在一起。如果散列表中的槽数与机器中物理页面数一样多,那么散列表的冲突链的平均长度将会是1个表项的长度,这将会大大提高映射速度。一旦页框号被找到,新的(虚拟页号,物理页框号)对就会被装载到TLB中。

倒排页表在64位机器中很常见，因为在64位机器中即使使用了大页表，页表项的数量也还是很庞大的

## 3.4 页面置换算法

当发生缺页中断时,操作系统必须在内存中选择一个页面将其换出内存,以便为即将调入的页面腾出空间。如果要换出的页面在内存驻留期间已经被修改过,就必须把它写回磁盘以更新该页面在磁盘上的副本;如果该页面没有被修改过,那么它在磁盘上的副本已经是最新的,不需要回写。直接用调入的页面覆盖被淘汰的页面就可以了。

当发生缺页中断时,虽然可以随机地选择一个页面来置换,但是如果每次都选择不常使用的页面会提升系统的性能。如果一个被频繁使用的页面被置换出内存,很可能它在很短时间内又要被调入内存,这会带来不必要的开销。

在接下来讨论的所有页面置换算法中都存在一个问题:当需要从内存中换出某个页面时,它是否只能是缺页进程目己的页面?这个要换出的页面是否可以属于另外一个进程?当换出的页面只能是缺页进程自己的页面时,可以有效地将每一个进程限定在固定的页面数目内;当换出的页面可以属于另一个进程时则将进程限定在固定的页面数目内不能。这两种情况都是可能的。

### 3.4.1 最优页面置换算法

**最优页面置换算法**：在缺页中断发生时,有些页面在内存中,其中有一个页面(包含紧接着的下一条指令的那个页面)将很快被访问,其他页面则可能要到10、100或1000条指令后才会被访问,每个页面都可以用在该页面首次被访问前所要执行的指令数作为标记。最优页面置换算法规定应该置换标记最大的页面，从而把因需要调入这个页面而发生的缺页中断推迟到将来，越久越好。这个算法唯一的问题就是它是无法实现的。当缺页中断发生时，操作系统无法知道各个页面下一次将在什么时候被访问。用这种方式，可以通过最优页面置换算法对其他可实现算法的性能进行比较。

### 3.4.2 最近未使用页面置换算法

为使操作系统能够收集有用的统计信息,在大部分具有虚拟内存的计算机中,系统为每一页面设置了两个状态位。当页面被访问(读或写)时设置R位;当页面被写入(即修改)时设置M位。这些位包含在每个页表项中。每次访问内存时更新这些位,因此由硬件来设置它们是必要的。一旦设置某位为1,它就一直保持1直到操作系统将它复位。

如果硬件没有这些位,则可以使用操作系统的缺页中断和时钟中断机制进行以下的模拟:当启动一个进程时,将其所有的页面都标记为不在内存;一旦访问任何一个页面就会引发一次缺页中断,此时操作系统就可以设置R位(在它的内部表中),修改页表项使其指向正确的页面,并设为READ ONLY模式,然后重新启动引起缺页中断的指令;如果随后对该页面的修改又引发一次缺页中断,则操作系统设置这个页面的M位并将其改为READ/WRITE模式。

可以用R位和M位来构造一个简单的页面置换算法:当启动一个进程时,它的所有页面的两个位都由操作系统设置成0,R位被定期地(比如在每次时钟中断时)清零,以区别最近没有被访问的页面和被访问的页面

当发生缺页中断时，操作系统检查所有的页面并根据它们当前的R位和W位的值，把它们分为四类：0.没有被访问，没有被修改；1.没有被访问，已被修改；2.已被访问，没有被修改；3.已被访问，已被修改。尽管第1类初看起来似乎是不可能的,但是一个第3类的页面在它的R位被时钟中断清零后就成了第1类。时钟中断不清除M位是因为在决定一个页面是否需要写回磁盘时将用到这个信息。清除R位而不清除M位产生了第1类页面

**最近未使用(NRU)算法**随机地从类编号最小的非空类中挑选一个页面淘汰。这个算法隐含的意思是,在最近一个时钟滴答中(典型的时间是大约20ms)淘汰一个没有被访问的已修改页面要比淘汰一个被频繁使用的"干净"页面好。NRU的主要优点是易于理解和能够有效地被实现,虽然它的性能不是最好的,但是已经够用了

### 3.4.3 先进先出页面置换算法

**先进先出(FIFO)算法**：由操作系统维护一个所有当前在内存中的页面的链表,最新进入的页面放在表尾,最早进入的页面放在表头。当发生缺页中断时,淘汰表头的页面并把新调入的页面加到表尾，但有可能会淘汰常用的页面，因此很少使用纯粹的FIFO算法

### 3.4.4 第二次机会页面置换算法

**第二次机会算法**：检查最老页面的R位，如果R位是0，那么这个页面即老又没有被使用，可以立刻置换掉；如果是1，就将R位清零，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续搜索

第二次机会算法就是寻找一个在最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过，该算法就简化为纯粹的FIFO算法

### 3.4.5 时钟页面置换算法

**时钟算法**：把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面。当发生缺页中断时,算法首先检查表针指向的页面,如果它的R位是0就淘汰该页面,并把新的页面插入这个位置,然后把表针前移一个位置;如果R位是1就清除R位并把表针前移一个位置。重复这个过程直到找到了一个R位为0的页面为止

### 3.4.6 最近最少使用页面置换算法

**最近最少使用(LRU)算法**：在缺页中断发生时，置换未使用时间最长的页面。这个对最优算法的一个很好的近似是基于这样的观察：在前面几条指令中频繁使用的页面很可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用

虽然LRU在理论上是可以实现的,但代价很高。为了完全实现LRU,需要在内存中维护一个所有页面的链表,最近最多使用的页面在表头,最近最少使用的页面在表尾。困难的是在每次访问内存时都必须要更新整个链表。在链表中找到一个页面,删除它,然后把它移动到表头是一个非常费时的操作,即使使用硬件实现也一样费时(假设有这样的硬件)。

然而,还是有一些使用特殊硬件实现LRU的方法。首先考虑一个最简单的方法,这个方法要求硬件有一个64位计数器C,它在每条指令执行完后自动加1,每个页表项必须有一个足够容纳这个计数器值的域。在每次访问内存后,将当前的C值保存到被访问页面的页表项中。一旦发生缺页中断,操作系统就检查所有页表项中计数器的值,找到值最小的一个页面,这个页面就是最近最少使用的页面。

### 3.4.7 用软件模拟LRU

**最不常用(NFU)算法**：该算法将每个页面与一个软件计数器相关联,计数器的初值为0。每次时钟中断时,由操作系统扫描内存中所有的页面,将每个页面的R位(它的值是0或1)加到它的计数器上。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时,则置换计数器值最小的页面。

NFU的主要问题是它从来不忘记任何事情。比如,在一个多次(扫描)编译器中,在第一次扫描中被频繁使用的页面在程序进入第二次扫描时,其计数器的值可能仍然很高。实际上,如果第一次扫描的执行时间恰好是各次扫描中最长的,含有以后各次扫描代码的页面的计数器可能总是比含有第一次扫描代码的页面的计数器小,结果是操作系统将置换有用的页面而不是不再使用的页面

**老化算法**：在R位被加紧之前先将计数器右移一位，然后将R位加到计数器最左端的位而不是最右端的位。发生缺页中断时，将置换计数器值最小的页面。老化算法的计数器只有优先位数，这就限制了其对以往页面的记录

### 3.4.8 工作集页面置换算法

**请求调页**：在单纯的分页系统里,刚启动进程时,在内存中并没有页面。在CPU试图取第一条指令时就会产生一次缺页中断,使操作系统装入含有第一条指令的页面。其他由访问全局数据和堆栈引起的缺页中断通常会紧接着发生。一段时间以后,进程需要的大部分页面都已经在内存了,进程开始在较少缺页中断的情况下运行。这个策略称为请求调页,因为页面是在需要时被调入的,而不是预先装入

**局部性访问**：进程运行的任何阶段，它都只访问较少的一部分页面

**工作集**：一个进程当前正在使用的页面的集合。如果整个工作集都被装入到了内存中,那么进程在运行到下一运行阶段之前,不会发生很多缺页中断。若内存太小而无法容纳下整个工作集,那么进程的运行过程中会产生大量的缺页中断,导致运行速度也会变得很缓慢,因为通常只需要几个纳秒就能执行完一条指令,而通常需要是十毫秒才能从磁盘上读入一个页面。如果一个程序每10ms只能执行一到两条指令,那么它将会需要很长时间才能运行完。若每执行几条指令程序就发生一次缺页中断,那么就称这个程序发生了**颠簸**

不少分页系统都会设法跟踪进程的工作集,以确保在让进程运行以前,它的工作集就已在内存中了。该方法称为**工作集模型**,其目的在于大大减少缺页中断率。在进程运行前预先装入其工作集页面也称为**预先调页**，工作集是随着时间变化的

当前实际运行时间：一个进程从它开始执行到当前所实际使用的CPU时间总数。通过近似的方法，进程的工作集可以被称为在过去τ秒实际运行时间中它所访问过的页面的集合

**基于工作集的页面置换算法**：基本思路就是找出一个不在工作集中的页面并淘汰它。工作方式如下：假定使用硬件来置R位和M位。同样,假定在每个时钟滴答中,有一个定期的时钟中断会用软件方法来清除R位。每当缺页中断发生时,扫描页表以找出一个合适的页面淘汰之。

在处理每个表项时,都需要检查R位。如果它是1,就把当前实际时间写进页表项的"上次使用时间"域,以表示缺页中断发生时该页面正在被使用。既然该页面在当前时钟滴答中已经被访问过,那么很明显它应该出现在工作集中,些且不应该被删除(假定τ横跨多个时钟滴答)。

如果R是0,那么表示在当前时钟滴答中,该页面还没有被访问过,则它就可以作为候选者被置换。为了知道它是否应该被置换,需要计算它的生存时间(即当前实际运行时间减去上次使用时间),然后与τ做比较。如果它的生存时间大于τ,那么这个页面就不再在工作集中,而用新的页面置换它。扫描会继续进行以更新剩余的表项

然而,如果R是0同时生存时间小于或等于,则该页面仍然在工作集中。这样就要把该页面临时保留下来,但是要记录生存时间最长("上次使用时间"的最小值)的页面。如果扫描完整个页表却没有找到适合被淘汰的页面,也就意味着所有的页面都在工作集中。在这种情况下,如果找到了一个或者多个R=0的页面,就淘汰生存时间最长的页面。在最坏情况下,在当前时间滴答中,所有的页面都被访问过了(也就是都有R=1),因此就随机选择一个页面淘汰,如果有的话最好选一个干净页面。

### 3.4.9 工作集时钟页面置换算法

当缺页中断发生后,需要扫描整个页表才能确定被淘汰的页面,因此基本工作集算法是比较费时的。有一种改进的算法,它基于时钟算法,并且使用了工作集信息,称为**工作集时钟(WSClock)算法**。由于它实现简单,性能较好,所以在实际工作中得到了广泛应用。

与时钟算法一样,所需的数据结构是一个以页框为元素的循环表。最初,该表是空的。当装入第一个页面后,把它加到该表中。随着更多的页面的加入,它们形成一个环。每个表项包含来自基本工作集算法的上次使用时间,以及R位和M位

与时钟算法一样,每次缺页中断时,首先检查指针指向的页面。如果R位被置为1,该页面在当前时钟滴答中就被使用过,那么该页面就不适合被淘汰。然后把该页面的R位置为0,指针指向下一个页面,并重复该算法。

现在来考虑指针指向的页面在R=0时会发生什么。如果页面的生存时间大于τ并且该页面是干净的,它就不在工作集中,并且在磁盘上有一个有效的副本。申请此页框,并把新页面放在其中。另一方面,如果此页面被修改过,就不能立即申请页框,因为这个页面在磁盘上没有有效的副本。为了避免由于调度写磁盘操作引起的进程切换,将该页面写回的同时指针继续向前走,算法继续对下一个页面进行操作。毕章,有可能存在一个旧的且干净的页面可以立即使用。

原则上,所有的页面都有可能因为磁盘I/O在某个时钟周期被调度。为了降低磁盘阻塞,需要设置一个限制,即最大只允许写回n个页面。一旦达到该限制,就不允许调度新的写操作。

如果指针经过一圈返回它的起始点后有两种情况：至少调度了一次写操作或者没有调度过写操作。

如果至少调度了一次写操作，指针仅仅是不停地移动,寻找一个干净页面。既然已经调度了一个或者多个写操作,最终会有某个写操作完成,它的页面会被标记为干净。置换遇到的第一个干净页面,这个页面不一定是第一个被调度写操作的页面,因为硬盘驱动程序为了优化性能可能已经把写操作重排序了。

如果没有调度过写操作,所有的页面都在工作集中,否则将至少调度了一个写操作。由于缺乏额外的信息,一个简单的方法就是随便置换一个干净的页面来使用,扫描中需要记录干净页面的位置。如果不存在干净页面,就选定当前页面并把它写回磁盘。

### 3.4.10 页面置换算法小结

|算法|注释|
|:-:|:-:|
|最优算法|不可实现，但可用作基准|
|NRU(最近未使用)算法|LRU的很粗糙的近似|
|FIFO(先进先出)算法|可能抛弃重要页面|
|第二次机会算法|比FIFO有较大的改善|
|时钟算法|现实的|
|LRU(最近最少使用)算法|很优秀，但很难实现|
|NFU(最不经常使用)算法|LRU的相对粗略的近似|
|老化算法|非常近似LRU的有效算法|
|工作集算法|实现起来开销很大|
|工作集时钟算法|好的有效算法|

最优算法在当前页面中置换最后要访问到的页面。不幸的是,没有办法来判定哪个页面是最后一个要访问的,因此实际上该算法不能使用。然而,它可以作为衡量其他算法的基准。

NRU算法根据R位和M位的状态把页面分为四类。从编号最小的类中随机选择一个页面置换。该算法易于实现,但是性能不是很好,还存在更好的算法。

FIFO算法通过维护一个页面的链表来记录它们装入内存的顺序。淘汰的是最老的页面,但是该页面可能仍在使用,因此FIFO算法不是一个好的选择。

第二次机会算法是对FIFO算法的改进,它在移出页面前先检查该页面是否正在被使用。如果该页面正在被使用,就保留该页面。这个改进大大提高了性能。

时钟算法是第二次机会算注的另一种实现。它具有相同的性能特征,而且只需要更少的执行时间。

LRU算法是一种非常优秀的算法,但是只能通过特定的硬件来实现。如果机器中沒有该硬件,那么也无法使用该算法。

NFU是一种近似于LRU的算法,它的性能不是非常好

老化算法更近似于LRU并且可以更有效地实现,是一个很好的选择。

最后两种算法都使用了工作集。工作集算法有合理的性能,但它的实现开销较大。工作集时钟算法是它的一种变体,不仅具有良好的性能,并且还能高效地实现。

总之,最好的两种算法是老化算法和工作集时钟算法,它们分别基于LRU和工作集。它们都具有良好的页面调度性能,可以有效地实现。也存在其他一些算法,但在实际应用中,这两种算法可能是最重要的。

## 3.5 分页系统中的设计问题

下面将讨论为了使分页系统达到较好的性能，操作系统设计者必须仔细考虑的一些其他问题↓

### 3.5.1 局部分配策略与全局分配策略

怎样在相互竞争的可运行进程之间分配内存？

**局部页面置换算法**：淘汰页面时只考虑当前进程的所有页面。可以有效地为每个进程分配固定的内存片段

**全局页面替换算法**：淘汰页面时考虑所有进程的页面。在可运行进程之间动态地分配页框，因此分配给各个进程的页框数是随时间变化的。

全局算法在通常情况下工作得比局部算法好,当工作集的大小随进程运行时间发生变化时这种现象更加明显。若使用局部算法,即使有大量的空闲页框存在,工作集的增长也会导致颤簸。如果工作集缩小了,局部算法又会浪费内存。

在使用全局算法时,系统必须不停地确定应该给每个进程分配多少页框。一种方法是监测工作集的大小,工作集大小由"老化"位指出,但这个方法并不能防止颤簸。因为工作集的大小可能在几微秒内就会发生改变,而老化位却要经历一定的时钟滴答数才会发生变化。另一种途径是使用一个为进程分配页框的算法。定期确定进程运行的数目并为它们分配相等的份额，或采用按照进程大小的比例来为它们分配相应数目的页面。比较明智的一个可行的做法是对每个进程都规定一个最小的页框数,这样不论多么小的进程都可以运行。

如果使用全局算法,根据进程的大小按比例为其分配页面也是可能的,但是该分配必须在程序运行时动态更新。管理内存动态分配的一种方法是使用**PFF(缺页中断率)算法**。它指出了何时增加或减少分配给一个进程的页面,但却完全没有说明在发生缺页中断时应该替换掉哪一个页面,它仅仅控制分配集的大小。

测量缺页中断率的方法是直截了当的:计算每秒的缺页中断数,可能也会将过去数秒的情况做连续平均

一些页面置换算法既适用于局部置换算法，又适用于全局置换算法，例如FIFO算法或者LRU算法等，另一方面，对于其他的页面置换算法，只有采用局部策略才有意义。特别是工作集和WSClock算法(工作集时钟算法)是针对某些特定进程的而且必须应用在这些进程的上下文中。实际上没有针对整个机器的工作集，并且试图使用所有工作集的并集作为机器的工作集可能会丢失一些局部特性，这样算法就不能达到好的性能

### 3.5.2 负载控制

即使是使用最优页面置换算法并对进程采用理想的全局页框分配,系统也可能会发生颠簸。事实上,一旦所有进程的组合工作集超出了内存容量,就可能发生颠簸。该现象的症状之一就是如PFF算法所指出的,一些进程需要更多的内存,但是没有进程需要更少的内存。在这种情况下,没有方法能够在不影响其他进程的情况下满足那些需要更多内存的进程的需要。唯一现实的解决方案就是暂时从内存中去掉一些进程。

减少竞争内存的进程数的一个好方法是将一部分进程交换到磁盘,并释放他们所占有的所有页面。例如,一个进程可以被交换到磁盘,而它的页框可以被其他处于颠簸状态的进程分享。如果颠簸停止,系统就能够这样运行一段时间。如果颠簸没有结束,需要继续将其他进程交换出去,直到颠簸结束。因此,即使是使用分页,交换也是需要的,只是现在交换是用来减少对内存潜在的需求,而不是收回它的页面。

将进程交换出去以减轻内存需求的压力是借用了两级调度的思想,在此过程中一些进程被放到磁盘,此时用一个短期的调度程序来调度剩余的进程。很明显,这两种思路可以被组合起来,将恰好足够的进程交换出去以获取可接受的缺页中断率。一些进程被周期性地从磁盘调入,而其他一些则被周期性地交换到磁盘。

不过,另一个需要考虑的因素是多道程序设计的道数。当内存中的进程数过低的时候,CPU可能在很长的时间内处于空闲状态。考虑到该因素,在决定交换出哪个进程时不光要考虑进程大小和分页率,还要考虑它的特性(如它究竟是CPU密集型还是I/O密集型)以及其他进程的特性。

### 3.5.3 页面大小

* 使用小页面的优点：
  * 随便选择一个正文段、数据段或堆栈段很可能不会恰好装满整数个页面,平均的情况下,最后一个页面中有一半是空的。多余的空间就被浪费掉了,这种浪费称为**内部碎片**
  * 考虑一个程序,它分成8个阶段顺序执行,每阶段需要4KB内存。如果页面大小是32KB,那就必须始终给程序分配32KB内存。如果页面大小是16KB,它就只需要16KB。如果页面大小是4KB或更小,那么在任何时刻它只需要4KB内存。总的来说,大尺寸页面比小尺寸页面浪费了更多内存。

* 使用大页面的优点：
	* 页面小意味着程序需要更多的页面，这也意味着需要更大的页表。内存与磁盘之间的传输一般是一次一页，传输中的大部分时间都花在了寻道和旋转延迟上，所以传输一个小页面所用的时间和传输一个大页面基本上是相同的
	* 小页面占用更多的TLB空间。由于TLB表项相对稀缺，且对于性能至关重要，因此在条件允许的情况下使用大页面是值得的
	* 在某些机器上，每次CPU从一个进程切换到另一个进程时都必须把新进程的页表装入硬件寄存器中。这样，页面越小意味着装入页面寄存器花费的时间就会越长，而且表项占用的空间也会随着页面的减小而增大

页表占用空间：假设进程平均大小是s个字节，页面大小是p个字节，每个页表项需要e个字节。那么每个进程需要的页数大约是$\frac{s}{p}$，占用了$\frac{se}{p}$个字节的页表空间，内部碎片在最后一页浪费的内存是$\frac{p}{2}$。因此，由页表和内部碎片损失造成的全部开销是以下两项之和：$开销=\frac{se}{p}+\frac{p}{2}$。当$p=\sqrt{2se}$时开销最小

为了进行必要的平衡，操作系统有时会为系统中的不同部分使用不同的页面大小。例如，内核使用大页面，而用户进程使用小页面

### 3.5.4 分离的指令空间和数据空间

为指令(程序正文)和数据设置分离的地址空间，分别称为**I空间**和**D空间**。每个地址空间都从0开始到某个最大值。链接器必须知道何时使用分离的I空间和D空间，因为当使用它们时，数据被重定位到虚拟地址0，而不是在程序之后开始

在使用这种设计的计算机中,两种地址空间都可以进行分页,而且互相独立。它们分别有自己的页表,分别完成虚拟页面到物理页框的映射。当硬件进行取指令操作时,它知道要使用I空间和I空间页表。类似地,对数据的访问必须通过D空间页表。除了这一区别,拥有分离的I空间和D空间不会引入任何复杂的设计,而且它还能使可用的地址空间加倍。

### 3.5.5 共享页面

共享页面避免了在内存中有一个页面的两份副本,效率更高。这里存在一个问题,即并不是所有的页面都适合共享。特别地,那些只读的页面(诸如程序文本)可以共享,但是数据页面则不能共享。如果系统支持分离的I空间和D空间,那么让两个或者多个进程来共享程序就变得非常简单了,这些进程使用相同的I空间页表和不同的D空间页表。在一个比较典型的使用这种方式来支持共享的实现中,页表与进程表数据结构无关。每个进程在它的进程表中都有两个指针:一个指向I空间页表,一个指向D空间页表。当调度程序选择一个进程运行时,它使用这些指针来定位合适的页表,并使用它们来设立MMU。即使没有分离的I空间和D空间,进程也可以共享程序(或者有时为库),但要使用更为复杂的机制

查找所有的页表,考察一个页面是否共享,其代价通常比较大,所以需要专门的数据结构记录共享页面,特别地,如果共享的单元是单个页面(或一批页面),而不是整个页表

共享数据要比共享代码麻烦,但也不是不可能。特别是在UNIX中,在进行fork系统调用后,父进程和子进程要共享程序文本和数据。在分页系统中,通常是让这些进程分别拥有它们自己的页表,但都指向同一个页面集合。这样在执行fork调用时就不需要进行页面复制。然而,所有映射到两个进程的数据页面都是只读的，只要这两个进程都仅仅是读数据,而不做更改,这种情况就可以保持下去。

但只要有一个进程更新了一点数据,就会触发只读保护,并引发操作系统陷阱。然后会生成一个该页的副本,这样每个进程都有自己的专用副本。两个复制都是可以读写的,随后对任何一个副本的写操作都不会再引发陷阱。这种策略意昧着那些从来不会执行写操作的页面(包括所有程序页面)是不需要复制的,只有实际修改的数据页面需要复制。这种方法称为**写时复制**,它通过减少复制而提高了性能。

### 3.5.6 共享库

**共享库**(Windows中称为**DLL**或**动态链接库**)

**链接**：当链接一个程序时，要在链接器的命令中指定一个或多个目标文件，可能还包括一些库文件。任何在目标文件中被调用了但是没有被定义的函数，都被称作**未定义外部函数**链接器会在库中寻找这些未定义外部函数。如果找到了，则将它们加载到可执行二进制文件中。任何被这些未定义外部函数调用了但是不存在的函数也会成为未定义外部函数。当链接器完成任务后，一个可执行二进制文件被写到磁盘，其中包括了所需的全部函数。在库中定义但是没有被调用的函数则不会被加载进去。当程序被装入内存执行时，它需要的所有函数都已经准备就绪了

当一个程序和共享库链接时，链接器没有加载被调用的函数,而是加载了一小段能够在运行时绑定被调用函数的存根例程。依赖于系统和配置信息,共享库或者和程序一起被装载,或者在其所包含函数第一次被调用时被装载。当然,如果其他程序已经装载了某个共享库,就没有必要再次装载它了。值得注意的是,当一个共享库被装载和使用时,整个库并不是被一次性地读入内存。而是根据需要,以页面为单位装载的,因此没有被调用到的函数是不会被装载到内存中的。

共享库优点：使可执行文件更小、节省内存空间、如果共享库中的一个函数因为修正一个bug被更新了，那么并不需要重新编译调用了这个函数的程序

共享库需要解决的问题：当有多个进程共享一个库时，如果进程将共享库定位在不同的虚拟地址上，则程序中使用的绝对地址就会冲突。一个解决方法是：在编译共享库时,用一个特殊的编译选项告知编译器,不要产生使用绝对地址的指令。相反,只能产生使用相对地址的指令。不论共享库被放置在虚拟地址空间的什么位置,这种指令都可以正确工作。通过避免使用绝对地址，这个问题就可以被解决。只使用相对便宜量的代码被称作**位置无关代码**

### 3.5.7 内存映射文件

**内存映射文件**：进程可以通过发起一个系统调用,将一个文件映射到其虚拟地址空间的一部分。在多数实现中,在映射共享的页面时不会实际读入页面的内容,而是在访问页面时才会被每次一页地读入,磁盘文件则被当作后备存储。当进程退出或显式地解除文件映射时,所有被改动的页面会被写回到磁盘文件中。共享库实际上就是内存映射文件的一个特例

内存映射文件提供了一种I/O的可选模型。可以把一个文件当作一个内存中的大字符数组来访问,而不用通过读写操作来访问这个文件。在一些情况下这个模型更加便利。

如果两个或两个以上的进程同时映射了同一个文件,它们就可以通过共享内存来通信。一个进程在共享内存上完成了写操作,此刻当另一个进程在映射到这个文件的虚拟地址空间上执行读操作时,它就可以立刻看到上一个进程写操作的结果。因此,这个机制提供了一个进程之间的高带宽通道,而且这种应用很普遍(甚至扩展到用来映射无名的临时文件)

### 3.5.8 清除策略

如果发生缺页中断时系统中有大量的空闲页框,此时分页系统工作在最佳状态。如果每个页框都被占用,而且被修改过的话,再换入一个新页面时,旧页面应首先被写回磁盘。为保证有足够的空闲页框,很多分页系统有一个称为**分页守护进程**的后台进程,它在大多数时候睡眠,但定期被唤醒以检查内存的状态。如果空闲页框过少,分页守护进程通过预定的页面置换算法选择页面换出内存。如果这些页面装入内存后被修改过,则将它们写回磁盘。

在任何情况下,页面中原先的内容都被记录下来。当需要使用一个已被淘汰的页面时,如果该页框还没有被覆盖,将其从空闲页框缓冲池中移出即可恢复该页面。保存一定数目的页框供给比使用所有内存并在需要时搜索一个页框有更好的性能。分页守护进程至少保证了所有的空闲页框是"干净"的,所以空闲页框在被分配时不必再急着写回磁盘。

一种实现清除策略的方法就是使用一个双指针时钟。前指针由分页守护进程控制。当它指向一个脏页面时,就把该页面写回磁盘,前指针向前移动。当它指向一个干净页面时,仅仅指针向前移动。后指针用于页面置换,就像在标准时钟算法中一样。现在,由于分页守护进程的工作,后指针命中干净页面的概率会增加。

### 3.5.9 虚拟内存接口

到现在为此,所有的讨论都假定虚拟内存对进程和程序员来说是透明的,也就是说,它们都可以在一台只有较少物理内存的计算机上看到很大的虚拟地址空间。对于不少系统而言这样做是对的,但对于一些高级系统而言,程序员可以对内存映射进行控制,并可以通过非常规的方法来增强程序的行为。这一节将简短地讨论一下这些问题。

**共享内存**：如果程序员可以对内存区域进行命名,那么就有可能实现共享内存。通过让一个进程把一片内存区域的名称通知另一个进程,而使得第二个进程可以把这片区域映射到它的虚拟地址空间中去。通过两个进程(或者更多)共享同一部分页面,高带宽的共享就成为可能，一个进程往共享内存中写内容而另一个进程从中读出内容

**页面共享**：可以用来实现高性能的消息传递系统。一般地,传递消息的时候,数据被从一个地址空间复制到另一个地址空间,开销很大。如果进程可以控制它们的页面映射,就可以这样来发送一条消息:发送进程清除那些包含消息的页面的映射,而接收进程把它们映射进来。这里只需要复制页面的名字,而不需要复制所有数据

**分布式共享内存**：该方法允许网络上的多个进程共享一个页面集合,这些页面可能(而不是必要的)作为单个的线性共享地址空间。当一个进程访问当前还没有映射进来的页面时,就会产生缺页中断。在内核空间或者用户空间中的缺页中断处理程序就会对拥有该页面的机器进行定位,并向它发送一条消息,请求它清除该页面的映射,并通过网络发送出来。当页面到达时,就把它映射进来,并重新开始运行引起缺页中断的指令。在第8章中将详细讨论分布式共享内存

## 3.6 有关实现的问题

### 3.6.1 与分页有关的工作

需要做与分页相关的工作的时间段：进程创建时、进程执行时、缺页中断时与进程终止时

**进程创建时**：当在分页系统中创建一个新进程时,操作系统要确定程序和数据在初始时有多大,并为它们创建一个页表。操作系统还要在内存中为页表分配空间并对其进行初始化。当进程被换出时,页表不需要驻留在内存中,但当进程运行时,它必须在内存中。另外,操作系统要在磁盘交换区中分配空间,以便在一个进程换出时在磁盘上有放置此进程的空间。操作系统还要用程序正文和数据对交换区进行初始化,这样当新进程发生缺页中断时,可以调入需要的页面。某些系统直接从磁盘上的可执行文件对程序正文进行分页,以节省磁盘空间和初始化时间。最后,操作系统必须把有关页表和磁盘交换区的信息存储在进程表中。

**进程执行时**：当调度一个进程执行时,必须为新进程重置MMU,刷新TLB,以清除以前的进程遗留的痕迹。新进程的页表必须成为当前页表,通常可以通过复制该页表或者把一个指向它的指针放进某个硬件寄存器来完成。有时,在进程初始化时可以把进程的部分或者全部页面装入内存中以减少缺页中断的发生,例如,PC(程序计数器)所指的页面肯定是需要的。

**缺页中断时**：当缺页中断发生时,操作系统必须通过读硬件寄存器来确定是哪个虚拟地址造成了缺页中断。通过该信息,它要计算需要哪个页面,并在磁盘上对该页面进行定位。它必须找到合适的页框来存放新页面,必要时还要置换老的页面,然后把所需的页面读入页框。最后还要回退程序计数器,使程序计数器指向引起缺页中断的指令,并重新执行该指令。

**进程终止时**：当进程退出的时候,操作系统必须释放进程的页表、页面和页面在硬盘上所占用的空间。如果某些页面是与其他进程共享的,当最后一个使用它们的进程终止的时候,才可以释放内存和磁盘上的页面

### 3.6.2 缺页中断处理

缺页中断发生时的事件顺序↓：

1. 硬件陷入内核,在堆栈中保存程序计数器。大多数机器将当前指令的各种状态信息保存在特殊的CPU寄存器中

2. 启动一个汇编代码例程保存通用寄存器和其他易失的信息,以免被操作系统破坏。这个例程将操作系统作为一个函数来调用

3. 当操作系统发现一个缺页中断时,尝试发现需要哪个虚拟页面。通常一个硬件寄存器包含了这一信息,如果没有的话,操作系统必须检索程序计数器,取出这条指令,用软件分析这条指令,看看它在缺页中断时正在做什么

4. 一旦知道了发生缺页中断的虚拟地址,操作系统检查这个地址是否有效,并检查存取与保护是否一致。如果不一致,向进程发出一个信号或杀掉该进程。如果地址有效且没有保护错误发生,系统则检查是否有空闲页框。如果没有空闲页框,执行页面置换算法寻找一个页面来淘汰

5. 如果选择的页框"脏"了,安排该页写回磁盘,并发生一次上下文切换,挂起产生缺页中断的进程,让其他进程运行直至磁盘传输结束。无论如何,该页框被标记为忙,以免因为其他原因而被其他进程占用

6. 一旦页框"干净"后(无论是立刻还是在写回磁盘后),操作系统查找所需页面在磁盘上的地址,通过磁盘操作将其装入。该页面正在被装入时,产生缺页中断的进程仍然被挂起,并且如果有其他可运行的用户进程,则选择另一个用户进程运行

7. 当磁盘中断发生时,表明该页已经被装入,页表已经更新可以反映它的位置,页框也被标记为正常状态

8. 恢复发生缺页中断指令以前的状态,程序计数器重新指向这条指令

9. 调度引发缺页中断的进程,操作系统返回调用它的汇编语言例程

10. 该例程恢复寄存器和其他状态信息,返回到用户空间继续执行,就好像缺页中断没有发生过一样

### 3.6.3 指令备份

当程序访问不在内存中的页面时,引起缺页中断的指令会半途停止并引发操作系统的陷阱。在操作系统取出所需的页面后,它需要重新启动引起陷阱的指令。但这并不是一件容易实现的事。在某些计算机上,CPU的设计者们提供了一种解决方法,就是通过使用一个隐藏的内部寄存器。在每条指令执行之前,把程序计数器的内容复制到该寄存器。这些机器可能会有第二个寄存器,用来提供哪些寄存器已经自动增加或者自动减少以及增减的数量等信息。通过这些信息,操作系统可以消除引起缺页中断的指令所造成的所有影响,并使指令可以重新开始执行。如果该信息不可用,那么操作系统就要找出所发生的问题从而设法来修复它。看起来硬件设计者是不能解决这个问题了,于是他们就推给操作系统的设计者来解决这个问题。

### 3.6.4 锁定内存中的页面

尽管本章对I/O的讨论不多,但计算机有虚拟内存并不意昧着I/O不起作用了。虚拟内存和I/O通过微妙的方式相互作用着。设想一个进程刚刚通过系统调用从文件或其他设备中读取数据到其地址空间中的缓冲区。在等待I/O完成时,该进程被挂起,另一个进程被允许运行,而这个进程产生一个缺页中断。如果分页算法是全局算法,包含I/O缓冲区的页面会有很小的机会(但不是没有)被选中换出内存。如果一个I/O设备正处在对该页面进行DMA传输的过程之中,将这个页面移出将会导致部分数据写入它们所属的缓冲区中,而部分数据被写入到最新装入的页面中。一种解决方法是锁住正在做I/O操作的内存中的页面以保证它不会被移出内存。锁住一个页面通常称为在内存中**钉住**页面。另一种方法是在内核缓冲区中完成所有的I/O操作,然后再将数据复制到用户页面。

### 3.6.5 后备存储

在前面讨论过的页面置换算法中,我们已经知道了如何选择换出内存的页面。但是却没有讨论当页面被换出时会存放在磁盘上的哪个位置,现在我们讨论一下磁盘管理相关的问题

一种方法是在磁盘上设置特殊的交换分区，甚至从文件系统划分一块独立的磁盘(以平衡I/O负载)。这是在磁盘上分配页面空间的最简单的算法，大多数UNIX是这样处理的。在这个分区里没有普通的文件系统,这样就消除了将文件偏移转换成块地址的开销。取而代之的是,始终使用相应分区的起始块号

当系统启动时,该交换分区为空,并在内存中以单独的项给出它的起始和大小。在最简单的情况下,当第一个进程启动时,留出与这个进程一样大的交换区块,剩余的为总空间减去这个交换分区。当新进程启动后,它们同样被分配与其核心映像同等大小的交换分区。进程结束后,会释放其磁盘上的交换区。交换分区以空闲块列表的形式组织。更好的算法在第10章里讨论

与每个进程对应的是其交换区的磁盘地址,即进程映像所保存的地方。这一信息是记录在进程表里的。写回一个页面时,计算写回地址的过程很简单:将虚拟地址空间中页面的偏移量加到交换区的开始地址。但在进程启动前必须初始化交换区,一种方法是将整个进程映像复制到交换区,以便随时可将所需内容装入,另一种方法是将整个进程装入内存,并在需要时换出

但这种简单模式有一个问题:进程在启动后可能增大,尽管程序正文通常是固定的,但数据有时会增长,堆栈也总是在随时增长。这样,最好为正文、数据和堆栈分别保留交换区,并且允许这些交换区在磁盘上多于一个块

另一种极端的方法是事先什么也不分配,在页面换出时为其分配磁盘空间,并在换入时回收磁盘空间,这样内存中的进程不必固定于任何交换空间。其缺点是内存中每个页面都要记录相应的磁盘地址。换言之,每个进程都必须有一张表,记录每一个页面在磁盘上的位置

不能保证总能够实现固定的交换分区。例如,没有磁盘分区可用时。在这种情况下,可以利用正常文件系统中的一个或多个较大的、事前定位的文件。Windows就使用这个方法。然而,可以利用优化方法减少所需的磁盘空间量。既然每个进程的程序正文来自文件系统中某个(可执行的)文件,这个可执行文件就可用作交换区。而更好的方法是,由于程序正文通常是只读的,当内存资源紧张、程序页不得不移出内存时,尽管丢弃它们,在需要的时候再从可执行文件读入即可。共享库也可以用这个方式工作

### 3.6.6 策略和机制的分离

控制系统复杂度的一种重要方法就是把策略从机制中分离出来。通过使大多数存储管理器作为用户级进程运行,就可以把该原则应用到存储管理中

一个如何分离策略和机制的简单例子如下，其中存储管理系统被分为三部分：内核空间中的一个底层MMU处理程序和一个作为内核一部分的缺页中断处理程序、运行在用户空间中的一个外部页面调度程序

所有关于MMU工作的细节都被封装在MMU处理程序中,该程序的代码是与机器相关的,而且操作系统每应用到一个新平台就要被重写一次。缺页中断处理程序是与机器无关的代码,包含大多数分页机制。策略主要由作为用户进程运行的外部页面调度程序所决定。

当一个进程启动时,需要通知外部页面调度程序以便建立进程页面映射,如果需要的话还要在磁盘上分配后备存储。当进程正在运行时,它可能要把新对象映射到它的地址空间,所以还要再一次通知外部页面调度程序。

一旦进程开始运行,就有可能出现缺页中断。缺页中断处理程序找出需要哪个虚拟页面,并发送一条消息给外部页面调度程序告诉它发生了什么问题。外部页面调度程序从磁盘中读入所需的页面,把它复制到自己的地址空间的某一位置。然后告诉缺页中断处理程序该页面的位置。缺页中断处理程序从外部页面调度程序的地址空间中清除该页面的映射,然后请求MMU处理程序把它放到用户地址空间的正确位置,随后就可以重新启动用户进程了。

这个实现方案没有给出放置页面置换算法的位置。把它放在外部页面调度程序中比较简单,但会有一些问题。这里有一条原则就是外部页面调度程序无权访问所有页面的R位和M位。这些二进制位在许多页面置换算法起重要作用。这样就需要有某种机制把该信息传递给外部页面调度程序,或者把页面置换算法放到内核中。在后一种情况下,缺页中断处理程序会告诉外部页面调度程序它所选择的要淘汰的页面并提供数据,方法是把数据映射到外部页面调度程序的地址空间中或者把它包含到一条消息中。两种方法中,外部页面调度程序都把数据写到磁盘上。

这种实现的主要优势是有更多的模块化代码和更好的适应性。主要缺点是由于多次交叉"用户-内核"边界引起的额外开销,以及系统模块间消息传递所造成的额外开销。现在看来,这一主题有很多争议,但是随着计算机越来越快,软件越来越复杂,从长远来看,对于大多数实现,为了获得更高的可靠性而牺性一些性能也是可以接受的

## 3.7 分段

到目前为止讨论的虚拟内存都是一维的,虚拟地址从0到最大地址,一个地址接着另一个地址。对许多问题来说,有两个或多个独立的地址空间可能比只有一个要好得多。比如,一个编译器在编译过程中会建立许多表,其中可能包括:1.被保存起来供打印清单用的源程序正文(用于批处理系统)；2.符号表,包含变量的名字和属性；3.包含用到的所有整型量和浮点常量的表；4.语法分析树，包含程序语法分析的结果；5.编译器内部过程调用使用的堆栈。前四个表随着编译的进行不断地增长，最后一个表在编译过程中以一种不可预计的方式增长和缩小。在一位存储器中，这五个表只能被分配到虚拟地址空间中连续的块中

需要一种能令程序员不用管理表扩张和收缩的方法，这与虚拟内存解决程序段覆盖问题所用的方法相同。一个直观并且通用的方法是在机器上提供多个互相独立的称为**段**的地址空间。每个段由一个从0到最大的线性地址序列构成。各个段的长度可以是0到某个允许的最大值之间的任何一个值。不同的段长度可以不同，并且通常情况下也都不相同。段的长度在运行期间可以动态改变，比如，堆栈段的长度在数据被压入时会增长，在数据被弹出时又会减小

因为每个段都构成了一个独立的地址空间,所以它们可以独立地增长或减小而不会影响到其他的段。如果一个在某个段中的堆栈需要更多的空间,它就可以立刻得到所需要的空间,因为它的地址空间中没有任何其他东西阻挡它增长。段当然有可能会被装满,但通常情况下段都很大,因此这种情况发生的可能性很小。要在这种分段或二维的存储器中指示一个地址,程序必须提供两部分地址,一个段号和一个段内地址

需要强调的是,段是一个逻辑实体,程序员知道这一点并把它作为一个逻辑实体来使用。一个段可能包括一个过程、一个数组、一个堆栈、一组数值变量,但一般它不会同时包含多种不同类型的内容。

除了能简化对长度经常变动的数据结构的管理之外,分段存储管理还有其他一些优点。如果每个过程都位于一个独立的段中并且起始地址是0,那么把单独编译好的过程链接起来的操作就可以得到很大的简化。当组成一个程序的所有过程都被编译和链接好以后,一个对段n中过程的调用将使用由两个部分组成的地址(n,0)来寻址到字0(入口点)。

如果随后位于段n的过程被修改并被重新编译,即使新版本的程序比老的要大,也不需要对其他的过程进行修改(因为没有修改它们的起始地址)。在一维地址中,过程被一个挨一个紧紧地放在一起,中间没有空隙,因此修改一个过程的大小会影响其他无关的过程的起始地址,而这又需要修改调用了这些被移动过的过程的所有过程,以使它们的访问指向这些过程的新地址。在一个有数百个过程的程序中,这个操作的开销可能是相当大的。

分段也有助于在几个进程之间共享过程和数据。这方面一个常见的例子就是共享库。运行高级窗口系统的现代工作站经常要把非常大的图形库编译进几乎所有的程序中。在分段系统中,可以把图形库放到一个单独的段中由各个进程共享,从而不再需要在每个进程的地址空间中都保存一份。虽然在纯的分页系统中也可以有共享库,但是它要复杂得多,并且这些系统实际上是通过模拟分段来实现的。

因为每个段是一个为程序员所知道的逻辑实体,比如一个过程或一个数组,故不同的段可以有不同种类的保护。一个过程段可以被指明为只允许执行,从而禁止对它的读出和写入,一个浮点数组可以被指明为允许读写但不允许执行,任何试图向这个段内的跳转都将被截获。这样的保护有助于找到编程错误

分页与分段的比较↓：

|问题|分页|分段|
|:-:|:-:|:-:|
|程序员需要了解<br>正在使用这种技术吗？|否|是|
|存在多少线性地址空间？|1|许多|
|整个地址空间可以超出<br>物理存储器的大小吗？|是|是|
|过程和数据可以<br>被区分并分别被保护吗？|否|是|
|其大小浮动的表<br>可以很容易提供吗？|否|是|
|用户间过程的共享方便吗？|否|是|
|为什么发明这种技术？|为了得到大的线性地址空间<br>而不必购买更大的物理存储器|为了使程序和数据可以被划分为<br>逻辑上独立的地址空间<br>并且有助于共享和保护|
|优点|统一的页面大小、<br>在只使用一部分页面时<br>不用把它们全部调入内存|易于编程、<br>模块化、<br>保护和共享|

### 3.7.1 纯分段的实现

分段和分页的实现本质上是不同的:页面是定长的而段不是。

**棋盘形碎片或外部碎片**：在系统运行一段时间后内存被划分为许多块,一些块包含着段,一些则成了空闲区，这种现象称为棋盘形碎片或外部碎片。空闲区的存在使内存被浪费了,而这可以通过内存紧缩来解决(即通过移动段在内存中的位置使段相连，将空闲区合并)

### 3.7.2 分段和分页的结合：MULTICS

如果一个段比较大,把它整个保存在内存中可能很不方便甚至是不可能的,因此产生了对它进行分页的想法。这样,只有那些真正需要的页面才会被调入内存。有几个著名的系统实现了对段的分页支持,本节将介绍第一个实现了这种支持的系统-MULTICS。下一节将介绍一个更新的例子-Intel x86到x86-64

MULTICS系统最具创新性的是虚拟存储架构

MULTICS它为每个程序提供了最多$2^{18}$个段,每个段的虚拟地址空问最长为65536个(36位)字长。为了实现它,MULTICS的设计者决定把每个段都看作一个虚拟内存并对它进行分页,以结合分页的优点(统一的页面大小和在只使用段的一部分时不用把它全部调入内存)和分段的优点(易于编程、模块化、保护和共享)

每个MULTICS程序都有一个段表,每个段对应一个描述符。因为段表可能会有25万多个表项,段表本身也是一个段并被分页。一个段描述符包含了一个段是否在内存中的标志,只要一个段的任何一部分在内存中这个段就被认为是在内存中,并且它的页表也会在内存中。如果一个段在内存中,它的描述符将包含一个18位的指向它的页表的指针。因为物理地址是24位并且页面是按照64字节的边界对齐的(这隐含着页面地址的低6位是000000),所以在描述符中只需要18位来存储页表地址。段描述符中还包含了段大小、保护位以及其他的一些条目。段在辅助存储器中的地址不在段描述符中，而是在缺段处理程序使用的另一个表中

每个段都是一个普通的虚拟地址空间,采用本章前面讨论过的非分段式分页存储方式进行分页。一般的页面大小是1024个字(尽管有一些MULTICS自己使用的段不分页或以64个字为单元进行分页以节省物理内存)

MULTICS中一个地址由两部分构成:段和段内地址。段内地址又进一步分为页号和页内的字(页内偏移量)。在进行内存访问时,执行下面的算法：1.根据段号找到段描述符；2.检查该段的页表是否在内存中。如果在,则找到它的位置;如果不在,则产生一个段错误。如果访问违反了段的保护要求就发出一个越界错误(陷阱)；3.检查所请求虚拟页面的页表项,如果该页面不在内存中则产生一个缺页中断,如果在内存就从页表项中取出这个页面在内存中的起始地址；4.把偏移量加到页面的起始地址上,得到要访问的字在内存中的地址；5.最后进行读或写操作。上述过程为了简单起见,忽略描述符段自己也要分页的事实。实际的过程是通过一个寄存器(描述符基址寄存器)找到描述符段的页表,这个页表指向描述符段的页面。一旦找到了所需段的描述符,寻址过程就如上述过程所示。

如果对于每条指令都由操作系统来运行上面所述的算法,那么程序就会运行得很慢。实际上,MULTICS硬件包含了16个字的高速TLB,对给定的关键字它能并行搜索所有的表项。当一个地址被送到计算机时,寻址硬件首先检查虚拟地址是不是在TLB中。如果在,就直接从TLB中取得页框号并生成要访问的字的实际地址,而不必到描述符段或页表中去查找。TLB中保存着16个最近访问的页的地址,工作集小于TLB容量的程序将随着整个工作集的地址被装入TLB中而逐渐达到稳定,开始高效地运行;否则将产生TLB错误。

### 3.7.3 分段和分页的结合：Intel x86

x86处理器的虚拟内存在许多方面都与MULTICS类似，其中包括既有分段机制又有分页机制。MULTICS有256K个独立的段，每个段最长可以有64K个36位字。x86处理器有16K个独立的段，每个段最多可以容纳10亿个32位字。这里虽然段的数目较少，但是相比之下x86较大的段大小特征比更多的段个数要重要得多，因为几乎没有程序需要1000个以上的段，但是有很多程序需要大段。自从x86-64起,除了在"传统模式"下，分段机制已被认为是过时的且不再被支持。虽然在x86-64的本机模式下仍然有分段机制的某些痕迹，但大多只是为了兼容，且它们不再具起到同样的作用，也不再提供真正的分段。但是X86-32依然配备了所有的处理机制，这就是我们将在这一节讨论的CPU

x86处理器中虚拟内存的核心是两张表，即**LDT(局部描述符表**)和**GDT(全局描述符表)**。每个程序都有自己的LDT,但是同一台计算机上的所有程序共享一个GDT。LDT描述局部于每个程序的段，包括其代码、数据、堆栈等;GDT描述系统段，包括操作系统本身。

为了访问一个段，一个x86程序必须把这个段的**选择子**装入机器的6个段寄存器的某一个中。在运行过程中,CS寄存器保存代码段的选择子，DS寄存器保存数据段的选择子，其他的段寄存器不太重要。每个选择子是一个16位数,最低两位取值范围为0~3，和保护有关，第二位指定是LDT还是GDT。高13位为LDT或GDT的表项编号

选择子中的一位指出这个段是局部的还是全局的(即它是在LDT中还是在GDT中)，其他的13位是LDT或GDT的表项编号。因此,这些表的长度被限制在最多容纳8K(13位)个段描述符。还有两位和保护有关，我们将在后面讨论。描述符0是禁止使用的，它可以被安全地装入一个段寄存器中用来表示这个段寄存器目前不可用，如果使用会引起一次陷阱。

选择子的格式经过合理设计，使得根据选择子定位描述符十分方便。首先根据第2位选择LDT或GDT,随后选择子被复制进一个内部擦除寄存器中并且它的低3位被清0;最后,LDT或GDT表的地址被加到它上面，得出一个直接指向描述符的指针

在选择子被装入段寄存器时，对应的描述符被从LDT或GDT中取出装入微程序寄存器中，以便快速地访问。一个描述符由8个字节构成，包括段的基址、大小和其他信息

现在跟踪一下一个描述地址的（选择子，偏移量)二元组被转换为物理地址的过程。微程序知道具体要使用哪个段寄存器后，它就能从内部寄存器中找到对应于这个选择子的完整的描述符。如果段不存在(选择子为0)或已被换出，则会发生一次陷阱。

硬件随后根据Limit(段长度)域检查偏移量是否超出了段的结尾,如果是也发生一次陷阱。从逻辑上来说，在描述符中应该简单地有一个32位的域给出段的大小,但实际上剩余20位可以使用，因此采用了一种不同的方案。如果G(粒度)位域是0，则是精确到字节的段长度,最大1MB;如果是1,段长度域以页面替代字节作为单元给出段的大小。对于4KB页面大小,20位足够最大232字节的段使用。

假设段在内存中并且偏移量也在范围内,x86处理器接着把描述符中32位的基址和偏移量相加形成**线性地址**。为了和只有24位基址的286兼容，基址被分为3片分布在描述符的各个位置。实际上，基址允许每个段的起始地址位于32位线性地址空间内的任何位置。

如果禁止分页(通过全局控制寄存器中的一位)，线性地址就被解释为物理地址并被送往存储器用于读写操作。因此在禁止分页时，我们就得到了一个纯的分段方案。各个段的基址在它的描述符中。另外，段之间允许互相覆盖，这可能是因为验证所有的段都互不重叠太麻烦太费时间的缘故。

另一方面，如果允许分页，线性地址就被解释为虚拟地址并通过页表映射到物理地址，很像前面讲过的例子。这里唯一真正复杂的是在32位虚拟地址和4KB页的情况下，一个段可能包含多达100万个页面，因此使用了两级映射,以便在段较小时减小页表大小。

每个运行程序都有一个由1024个32位表项组成的**页目录**。它通过一个全局寄存器来定位。这个目录中的每个目录项都指向一个也包含1024个32位表项的页表,页表项指向页框

线性地址被分为三个域:目录、页面和偏移量。目录域被作为索引在页目录中找到指向正确的页表的指针，随后页面域被用作索引在页表中找到页框的物理地址，最后，偏移量被加到页框的地址上得到需要的字节或字的物理地址

每个页表项是32位，其中20位是页框号。其余的位包含了由硬件设置供操作系统使用的访问位和脏位、保护位和一些其他有用的位

每个页表有描述1024个4KB页框的表项，因此一个页表可以处理4MB的内存。一个小于4MB的段的页目录中将只有一个表项，这个表项指向一个唯一的页表。通过这种方法，长度短的段的开销只是两个页面,而不是一级页表时的100万个页面

为了避免重复的内存访问，x86处理器和MULTICS一样，也有一个小的TLB把最近使用过的"目录-页面"二元组映射为页框的物理地址。只有在当前组合不在TLB中时，上述机制才被真正执行并更新TLB。只要TLB的缺失率很低，则性能就不错

还有一点值得注意，如果某些应用程序不需要分段，而是需要一个单独的、分页的32位地址空间,这样的模式是可以做到的。这时,所有的段寄存器可以用同一个选择子设置其描述符中基址设为0，段长度被设置为最大。指令偏移量会是线性地址，只使用了一个地址空间-效果上就是正常的分页。事实上，所有当前的x86操作系统都是这样工作的。OS/2是唯一一个使用Intel MMU体系结构所有功能的操作系统。

那么，英特尔为什么要剔除它支持了近30年，且源自表现良好的MULTICS存储模型的变形体呢?也许最主要的原因是UNIX和Windows都不曾使用过该模型，即使它通过在受保护的操作系统段内进行针对相关地址的过程调用而消除了系统调用，并具有很高的效率。没有哪个UNIX或Windows系统的开发人员愿意将已有的存储模型转变为针对x86使用的模型，因为这会破坏系统的可移植性。由于软件层并没有使用相关的功能，导致英特尔不愿再以牺牲芯片面积为代价来支持它，并最终从64位CPU中剔除了它。

## 3.9 小结

本章主要讲解内存管理。我们看到在最简单的系统中是根本没有任何交换或分页的。一旦程序装入内存，它将持续在内存中运行，直到结束。一些操作系统一次只允许一个进程在内存中运行，而另一些操作系统支持多道程序设计。这种模型在小型或嵌入式实时系统中仍有用武之地

接下来是交换技术。通过交换技术，系统可以同时运行总内存占用超过实际物理内存大小的多个进程。如果一个进程没有内存空间可用，它将会被交换到磁盘上。内存和磁盘上的空闲空间可以使用位图或空闲区链表来记录

现代计算机都有某种形式的虚拟内存。最简单的情况下，每一个进程的地址空间被划分为同等大小的块，称为页面，页面可以被放入内存中任何可用的页框内。有多种页面置换算法，其中两个比较好的算法是老化算法和工作集时钟算法

为了使分页系统工作良好，仅选择算法是不够的，还要关注诸多问题，例如工作集的确定、内存分配策略以及所需页面大小等。

如果要处理在执行过程中大小有变化的数据结构，分段是一个有用的选择,它还能简化链接和共享。不仅如此，分段还有利于为不同的段提供不同的保护。有时，可以把分段和分页结合起来，以提供二维的虚拟内存。MULTICS系统以及32位Intel x86即是如此，支持分段也支持分页。不过，几乎没有操作系统开发者会仔细考虑分段(因为他们更青睐其他的内存模型)，这导致分段逐渐乏人问津。如今，即使64位版本的x86也不支持真正的分段。
