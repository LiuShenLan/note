- [8. 多处理机系统](#8-多处理机系统)
	- [8.1 多处理机](#81-多处理机)
		- [8.1.1 多处理机硬件](#811-多处理机硬件)
		- [8.1.2 多处理机操作系统类型](#812-多处理机操作系统类型)
		- [8.1.3 多处理机同步](#813-多处理机同步)
		- [8.1.4 多处理机调度](#814-多处理机调度)
	- [8.2 多计算机](#82-多计算机)
		- [8.2.1 多计算机硬件](#821-多计算机硬件)
		- [8.2.2 低层通信软件](#822-低层通信软件)
		- [8.2.3 用户层通信软件](#823-用户层通信软件)
		- [8.2.4 远程过程调用](#824-远程过程调用)
		- [8.2.5 分布式共享存储器](#825-分布式共享存储器)
		- [8.2.6 多计算机调度](#826-多计算机调度)
		- [8.2.7 负载平衡](#827-负载平衡)
	- [8.3 分布式系统](#83-分布式系统)
		- [8.3.1 网络硬件](#831-网络硬件)
		- [8.3.2 网络服务和协议](#832-网络服务和协议)
		- [8.3.3 基于文档的中间件](#833-基于文档的中间件)
		- [8.3.4 基于文件系统的中间件](#834-基于文件系统的中间件)
		- [8.3.5 基于对象的中间件](#835-基于对象的中间件)
		- [8.3.6 基于协作的中间件](#836-基于协作的中间件)
	- [8.5 小结](#85-小结)

# 8. 多处理机系统

获得更高速度的一种处理方式是大规模使用并行计算机。这些机器有许多CPU，每个都以"通常"的速度(在一个给定年份中的速度)运行，但是总体上会有比单个CPU强大得多的计算能力。为了获得更高的速度，还有其他潜在的处理方式，如生物计算机等，但本章专注于有多个普通CPU的系统

在高强度的数据处理中经常采用高度并行计算机，解决这些问题需要多个CPU同时长时间运行。

在电子(或光学)部件之间的所有通信，归根结底是在它们之间发送消息-具有良好定义的位串(bit string)。其差别在于所涉及的时间范围、距离范围和逻辑组织

**共享存储器多处理机**：系统中有从2个到1000个CPU通过一个共享存储器通信。每个CPU可同样访问整个物理存储器，可使用指令LOAD和STORE读写单个的字。访问一个存储器字通常需要1~10ns。消息传递对于程序员来说是不可见的

**消息传递型多计算机**：许多CPU-存储器通过某种高速互联网络连接在一起，每个存储器局部对应一个CPU，且只能被该CPU访问。这些CPU通过互联网络发送多字消息通信。存在良好的连接时，一条短消息可在10~50μs之内发出。在这种设计中没有全局共享的存储器。多计算机消息传递系统比共享存储器多处理机系统容易构建，但是编程比较困难，属于**紧密耦合**系统

**分布式系统**：所有的计算机系统都通过一个广域网连接起来，如因特网。每台计算机有自己的存储器，通过消息传递进行系统通信。与消息传递多计算机之间真正唯一的差别是分布式系统使用了完整的计算机而且消息传递时间通常需要10~100ms。属于**松散耦合**系统

三类多CPU系统的比较↓：
|项目|多处理机|多计算机|分布式系统|
|:-:|:-:|:-:|:-:|
|节点配置|CPU|CPU、RAM、网络接口|完整的计算机|
|节点外设|全部共享|共享exc.、可能除了磁盘|每个节点全套外设|
|位置|同一机箱|同一房间|可能全球|
|节点间通信|共享RAM|专用互连|传统网络|
|操作系统|一个，共享|多个，相同|可能都不相同|
|文件系统|一个，共享|一个，共享|每个节点自有|
|管理|一个机构|一个机构|多个机构|

多计算机处于中间位置。于是一个问就是多计算机是更像多处理机还是更像分布式系统?答案取决于角度。从技术角度来看，多处理机有共享存储器而其他两类没有。这个差别导致了不同的程序设计模式和不同的思考方式。但是从应用角度来看,多处理机和多计算机都不过是在机房中的大设备机架罢了，而在全部依靠Internet连接计算机的分布式系统中显然通信要多于计算，并且以不同的方式使用着

## 8.1 多处理机

**共享存储器多处理机(简称多处理机)**：其两个或更多的CPU全部共享访问一个公用的RAM。运行在任何一个CPU上的程序都看到一个普通(通常是分页)的虚拟地址空间。这个系统唯一特别的性质是，CPU可对存储器的某个字写入某个值，然后读回该字，并得到一个不同的值(因为另一个CPU改写了它)。在进行恰当组织时，这种性质构成了处理器间通信的基础:一个CPU向存储器写入某些数据而另一个读取这些数据。多处理机操作系统只是通常的操作系统。它们处理系统调用，进行存储器管理，提供文件系统并管理I/O设备。不过，在某些领域里它们还是有一些独特的性质。这包括进程同步、资源管理以及调度

### 8.1.1 多处理机硬件

所有的多处理机都具有每个CPU可访问全部存储器的性质，而有些多处理机仍有一些其他的特性，

**UMA(统一存储器访问)多处理机**：读出每个存储器字的速度是一样快的

**NUMA(非一致存储器访问)多处理机**：读出每个存储器字的速度并不一样快

1. 基于总线的UMA多处理机体系结构

最简单的多处理机是基于单总线的。两个或更多的CPU以及一个或多个存储器模块都使用同一个总线进行通信。当一个CPU需要读一个存储器字时，它首先检查总线忙否。如果总线空闲，该CPU把所需字的地址放到总线上，发出若干控制信号，然后等待存储器把所需的字放到总线上

当某个CPU需要读写存储器时，如果总线忙，CPU只是等待，直到总线空闲。这种设计存在问题。在只有两三个CPU时，对总线的争夺还可以管理;若有32个或64个CPU时，就不可忍受了。这种系统完全受到总线带宽的限制，多数CPU在大部分时间里是空闲的。这一问题的解决方案是为每个CPU添加一个高速缓存。这个高速缓存可以位于CPU芯片的内部、CPU附近、在处理器板上或所有这三种方式的组合。由于许多读操作可以从本地高速缓存上得到满足，总线流量就大大减少了，这样系统就能够支持更多的CPU。一般而言，高速缓存不以单个字为基础，而是以32字节或64字节块为基础。当引用一个字时，它所在的整个数据块(叫作一个cache行)被取到使用它的CPU的高速缓存当中。每一个高速缓存块或者被标记为只读(在这种情况下，它可以同时存在于多个高速缓存中)，或者标记为读写(在这种情况下，它不能在其他高速缓存中存在)。如果CPU试图在一个或多个远程高速缓存中写入一个字，总线硬件检测到写，并把一个信号放到总线上通知所有其他的高速缓存。如果其他高速缓存有个"干净"的副本，也就是同存储器内容完全一样的副本，那么它们可以丢弃该副本并让写者在修改之前从存储器取出高速缓存块。如果某些其他高速缓存有"脏"(被修改过)副本，它必须在处理写之前把数据写回存储器或者把它通过总线直接传送到写者上。高速缓存这一套规则被称为**高速缓存一致性协议**，它是诸多协议之一

还有另一种可能性就是每个CPU不止有一个高速缓存，还有一个本地的私有存储器，它通过一条专门的(私有)总线访问。为了优化使用这一配置，编译器应该把所有程序的代码、字符串、常量以及其他只读数据、栈和局部变量放进私有存储器中。而共享存储器只用于可写的共享变量。在多数情况下，这种仔细的放置会极大地减少总线流量，但是这样做需要编译器的积极配合

2. 使用交叉开关的UMA多处理机

即使有最好的高速缓存，单个总线的使用还是把UMA多处理机的数量限制在16至32个CPU。要超过这个数量，就需要新的互连网络。连接n个CPU到k个存储器的最简单的电路是**交叉开关**，如把CPU放置在水平线上，把存储器放置在垂直线上，用于把一组进线以任意方式连接到一组出线上。水平线(进线)和垂直线(出线)的每个相交位置上是一个交叉点。交叉点是一个小的电子开关，具体取决于水平线和垂直线是否需要连接

交叉开关最好的一个特性是它是一个**非阻塞网络**，即不会因有些交叉点或连线已经被占据了而拒绝连接(假设存储器模块自身是可用的)。并非所有的互连方式都是非阻塞的，而且并不需要预先的规划。即使已经设置了7个任意的连接，还有可能把剩余的CPU连接到剩余的存储器上

当然，当两个CPU同时试图访问同一个模块的时候，对内存的竞争还是可能的。不过，通过将内存分为n个单元，与基于总线的UMA多处理机体系结构相比，这样的争夺概率可以降至1/n

交叉开关最差的一个特性是，交叉点的数量以$n^2$方式增长。若有1000个CPU和1000个存储器我们就需要一百万个交叉点。这样大数量的交叉开关是不可行的。不过，无论如何对于中等规模的系统而言,交叉开关的设计是可用的

3. 使用多级交换网络的UMA多处理机

有一种完全不同的、基于简单2X2开关的多处理机设计。这个2X2开关有两个输入和两个输出。到达任意一个输入线的消息可以被交换至任意一个输出线上。就我们的目标而言，消息可由四个部分组成，Module(模块)域指明使用哪个存储器。Address(地址)域指定在模块中的地址。Opcode(操作码)给定了操作,如READ或WRITE。最后,在可选的Value（值)域中可包含一个操作数,比如一个要被WRITE写入的32位字。该开关检查Module域并利用它确定消息是应该送给哪一个输出

这个2×2开关可有多种使用方式，用以构建大型的**多级交换网络**。有一种是简单经济的**omega网络**，对于n个CPU和n个存储器，我们将需要${log}_2n$级，每级n/2个开关，总数为$(n/2){log}_2n$个开关,比n个交叉点要好得多,特别是当n值很大时

Omega网络的接线模式常被称作**全混洗**，因为每一级信号的混合就像把一副牌分成两半，然后再把牌一张张混合起来

和交叉开关不同，omega网络是一种**阻塞网络**，并不是每组请求都可被同时处理。冲突可在一条连线或一个开关中发生，也可在对存储器的请求和来自存储器的应答中产生

人们希望各模块对存储器的引用是均匀的，为此通常使用一种把低位作为模块号的技术。例如,考虑一台经常访问32位字的计算机中面向字节的地址空间,低位通常是00但接下来的3位会均匀地分布。将这3位作为模块号，连续的字会放在连续的模块中。而连续字被放在不同模块里的存储器系统被称作**交叉**存储器系统。交叉存储器将并行运行的效率最大化了，这是因为多数对存储器的引用是连续编址的。设计非阻塞的交换网络也是有可能的,在这种网络中提供了多条从每个CPU到每个存储器的路径,从而可以更好地分散流量

4. NUMA多处理机

单总线UMA多处理机通常不超过几十个CPU，而交叉开关或交换网络多处理机需要许多(昂贵)的硬件，所以规模也不是那么大。要想超过100个CPU还必须做些让步。通常，一种让步就是所有的存储器模块都具有相同的访问时间。这种让步导致了NUMA多处理机的出现。像UMA一样,这种机器为所有的CPU提供了一个统一的地址空间，但与UMA机器不同的是，访问本地存储器模块快于访问远程存储器模块。因此，在NUMA 机器上运行的所有UMA程序无须做任何改变，但其性能不如UMA 机器上的性能

所有NUMA机器都具有以下三种关键特性，它们是NUMA与其他多处理机的主要区别:1.具有对所有CPU都可见的单个地址空间；2.通过LOAD和STORE指令访问远程存储器；3.访问远程存储器慢于访问本地存储器

在对远程存储器的访问时间不被隐藏时(因为没有高速缓存)，系统被称为**NC-NUMA(无高速缓存NUMA)**。在有一致性高速缓存时，系统被称为**CC-NUMA(高速缓存一致NUMA)**

目前构造大型CC-NUMA多处理机最常见的方法是**基于目录的多处理机**。其基本思想是，维护一个数据库来记录高速缓存行的位置及其状态。当一个高速缓存行被引用时,就查询数据库找出高速缓存行的位置以及它是"干净"的还是"脏"的。由于每条功问仔储器的指令都必须查询这个数据库，所以它必须配有极高速的专用硬件，从而可以在一个总线周期的几分之一内作出响应

该设计有一个明显的限制，即一行只能被一个节点高速缓存。要想允许一行能够在多个节点上被高速缓存，我们需要某种对所有行定位的方法，例如，在写操作时使其无效或更新。在多数多核处理器上，一个目录项由一个位向量组成，位向量的每位对应一个核。"1"表示该核上缓存有效，而"0"表示缓存已失效。通常每个目录项都包含多个位，这就导致了目录的内存成本大大增加

5. 多核芯片

随着芯片晶体管数量的增加，一种选择是给芯片增加高速缓存，但是到了某种程度，再增加高速缓存的大小只能将命中率从99%提高到99.5%，而这样的改进并不能显著提升应用的性能

另一个选择是将两个或者多个完整的CPU(通常称为**核**)放到同一个芯片上(技术上来说是同一个小硅片)。在多核芯片中，缓存仍然是至关重要的，并且遍布整个芯片

虽然CPU可能共享高速缓存或者不共享，但是它们都共享内存。考虑到每个内存字总是有唯一的值，这些内存是一致的。特殊的硬件电路可以确保在一个字同时出现在两个或者多个的高速缓存中的情况下，当其中某个CPU修改了该字，所有其他高速缓存中的该字都会被自动地并且原子性地删除来确保一致性。这个过程称为**窥探**

这样设计的结果是多核芯片就相当于小得多处理机。实际上，多核芯片时常被称为**片级多处理机(CMP)**。从软件的角度来看，CMP与基于总线的多处理机和使用交换网络的多处理机并没有太大的差别。不过，它们还是存在着一些不同。例如,对基于总线的多处理机,每个CPU拥有自己的高速缓存。在Intel使用的共享高速缓存的设计并没有出现在其他的多处理机中。共享二级高速缓存会影响性能。如果一个核需要很多高速缓存空间，而另一个核不需要，这样的设计允许它们各自使用所需的高速缓存。但另一方面，共享高速缓存也让一个贪婪的核损害其他核成为可能

CMP与其他更大的多处理机之间的另一个差异是容错。因为CPU之间的连接非常紧密，一个共享模块的失效可能导致许多CPU同时出错。而这样的情况在传统的多处理机中是很少出现的

除了所有核都是对等的对称多核芯片之外，还有一类常见的多核芯片被称为**片上系统(SoC)**。这些芯片含有一个或者多个主CPU，但是同时还包含若干个专用核，例如视频与音频解码器、加密芯片,网络接口等。这些核共同构成了完整的片上计算机系统

6. 众核芯片

"多核"只是简单地表示核的数量多于一个，但是当核的数目继续增加时，我们会使用另一个名称"众核"。众核芯片是指包括几十、几百甚至成千上万个核心的多核处理器。尽管并没有严格的界限来区分什么情况下叫"多核"、什么情况下叫"众核"，但一个简单的区分方式是，如果你不介意损失一两个核心,这时候你使用的就是"众核"了

超大量核带来的一个问题是，用来保持缓存一致性的机制会变得非常复杂和昂贵。许多工程师担心缓存的一致性可能无法扩展到上百个核，一些人甚至建议彻底抛弃它。他们担心硬件上保持缓存一致性的开销会很高，以至于这些新增的核并不能带来多大的性能提升，因为处理器一直忙于维护缓存状态的一致性。更糟糕的是，保持缓存目录的一致性还将会消耗大量的内存,这就是著名的**一致性壁垒**

成千上万的核心数现在已不再那么少见了，**图形处理单元(GPU**)作为当今最为常见的众核，存在于几乎任何一台非嵌入式并且有显示器的计算机系统中。GPU是一个拥有专用内存和成千上万个微小核的处理器。与通用处理器相比，GPU在运算单元的电路上预留了更多的晶体管，而在缓存和控制逻辑上则更少。因而它们十分擅长进行像图形程序渲染多边形这样的大量并行的小规模计算，而不太擅长串行任务，同时也很难对它们编程。尽管GPU对于操作系统来说很有用加密或者网络数据的处理)，但让操作系统自身的大部分任务运行在GPU上还是不太可能的

其他的计算任务正越来越多地被GPU所处理，尤其是科学计算中常见的计算型任务。用来描述GPU上的通用计算的术语是**GPGPU**。不幸的是，对GPU进行高效的编程是十分困难的，并且需要**OpenGL**或NVIDIA的**CUDA**等特殊的编程语言。对GPU编程和对通用处理器编程的一个重要不同在于，GPU的本质是单指令多数据流处理器，这意味着大量的核心在数据的不同分块上执行完全相同的指令。这样的一个编程模型对于数据并行来说非常棒，但是对于其他编程类型(比如任务并行)并不是很合适

7. 异构多核

一些芯片会把一个GPU和一些通用处理器核封装在一起，许多片上系统在通用处理器核之外还包括一个或多个特殊用涂的处理器。在一块芯片上封装了不同类型的处理器的系统被统称为异构多核处理器。GPU和通用核心可以采用不同的指令集体系结构。然而在保持相同指令集体系结构的同时引入异构多核也是可能的，比如一个CPU可以包含一些有着较深流水线和更高的时钟频率的"大"核，以及一些更简单、不那么强大、也许运行在更低频率的"小"核。那些强大的核心会在运行有快速串行处理需要的代码时派上用场，而那些小核则对于可以高效并行执行的任务很实用

### 8.1.2 多处理机操作系统类型

下面的方法除了适用于多核系统之外，同样适用于包含多个分离CPU的系统

1. 每个CPU有自己的操作系统

组织一个多处理机操作系统的可能的最简单的方法是，静态地把存储器划分成和CPU一样多的各个部分，为每个CPU提供其私有存储器以及操作系统的各自私有副本。实际上n个CPU以n个独立计算机的形式运行。

优点在于允许所有的CPU共享操作系统的代码，而且只需要提供数据的私有副本。这一机制比有n个分离的计算机要好，因为1.它允许所有的机器共享一套磁盘及其他的I/O设备；2.它还允许灵活地共享存储器。例如，即便使用静态内存分配，一个CPU也可以获得极大的一块内存，从而高效地执行代码；3.由于生产者能够直接把数据写入存储器，从而使得消费者从生产者写入的位置取出数据,因此进程之间可以高效地通信；4.从操作系统的角度看，每个CPU都有自己的操作系统非常自然

潜在的问题：1.在一个进程进行系统调用时，该系统调用是在本机的CPU上被捕获并处理的，并使用操作系统表中的数据结构；2.因为每个操作系统都有自己的表，那么它也有自己的进程集合，通过自身调度这些进程。这里没有进程共享。如果一个用户登录到CPU 1，那么他的所有进程都在CPU1上运行。因此，在CPU 2有负载运行而CPU 1空载的情形是会发生的；3.没有共享物理页面。会出现如下的情形:在CPU2不断地进行页面调度时CPU 1却有多余的页面。由于内存分配是固定的，所以CPU 2无法向CPU 1借用页面；4.也是最坏的情形，如果操作系统维护近期使用过的磁盘块的缓冲区高速缓存，每个操作系统都独自进行这种维护工作，因此，可能出现某一修改过的磁盘块同时存在于多个缓冲区高速缓存的情况，这将会导致不一致性的结果。避免这一问题的唯一途径是，取消缓冲区高速缓存。这样做并不难，但是会显著降低性能

由于这些潜在的问题，每个CPU有自己的操作系统模型实际上很少使用，尽管它在早期的多处理机中一度被采用，这是由于那时的目标是把已有的操作系统尽可能快地移植到新的多处理机上

2. 主从多处理机

**主从模型**：操作系统的一个副本及其数据表都在CPU 1上，而不是在其他所有CPU上，CPU 1是主CPU，而其他的都是从属CPU。为了在该CPU 1上进行处理，所有的系统调用都重定向到CPU 1上。如果有剩余的CPU时间，还可以在CPU 1上运行用户进程

优点：主从模型解决了在第一种模型中的多数问题：1.有单一的数据结构(如一个链表或者一组优先级链表)用来记录就绪进程。当某个CPU空闲下来时，它向CPU 1上的操作系统请求一个进程运行，并被分配一个进程。这样，就不会出现一个CPU空闲而另一个过载的情形。2.可在所有的进程中动态地分配页面，而且只有一个缓冲区高速缓存，所以绝不会出现不一致的情形

问题：如果有很多的CPU，主CPU会变成一个瓶颈。毕竟，它要处理来自所有CPU的系统调用。如果全部时间的10%用来处理系统调用，那么10个CPU就会使主CPU饱和，而20个CPU就会使主CPU彻底过载。可见，这个模型虽然简单，而且对小型多处理机是可行的，但不能用于大型多处理机

3. 对称多处理机

**对称多处理机(SMP)**：消除了上述的不对称性，在存储器中有操作系统的一个副本，但任何CPU都可以运行它。在有系统调用时，进行系统调用的CPU陷入内核并处理系统调用

这个模型动态地平衡进程和存储器，因为它只有一套操作系统数据表。它还消除了主CPU的瓶颈，因为不存在主CPU;但是这个模型也带来了自身的问题。特别是，当两个或更多的CPU同时运行操作系统代码时，就会出现灾难。想象有两个CPU同时选择相同的进程运行或请求同一个空闲存储器页面。处理这些问题的最简单方法是在操作系统中使用互斥信号量(锁)，使整个系统成为一个大临界区。当一个CPU要运行操作系统时，它必须首先获得互斥信号量。如果互斥信号量被锁住，就得等待。按照这种方式，任何CPU都可以运行操作系统，但在任一时刻只有一个CPU可运行操作系统。这一方法称为**大内核锁(BLK)**

可以把操作系统分割成互不影响的临界区。每个临界区由其互斥信号量保护，所以一次只有一个CPU可执行它。采用这种方式，可以实现更多的并行操作。而某些表格，如进程表，可能恰巧被多个临界区使用。例如，在调度时需要进程表，在系统fork调用和信号处理时也都需要进程表。多临界区使用的每个表格，都需要有各自的互斥信号量。通过这种方式，可以做到每个临界区在任一个时刻只被一个CPU执行，而且在任一个时刻每个临界表也只被一个CPU访问

为这类机器编写操作系统的困难：1.如何将其划分为可以由不同的CPU并行执行的临界区而互不干扰，即使以细小的、间接的方式；2.对于被两个或多个临界区使用的表必须通过互斥信号量分别加以保护,而且使用这些表的代码必须正确地运用互斥信号量；3.必须格外小心地避免死锁

### 8.1.3 多处理机同步

同步原语：如果一个进程在单处理机(仅含一个CPU)中需要访问一些内核临界表的系统调用,那么内核代码在接触该表之前可以先禁止中断。然后它继续工作,在相关工作完成之前，不会有任何其他的进程溜进来访问该表。在多处理机中，禁止中断的操作只影响到完成禁止中断操作的这个CPU，其他的CPU继续运行并且可以访问临界表。因此必须采用一种合适的互斥信号量协议，而且所有的CPU都遵守该协议以保证互斥工作的进行

任何实用的互斥信号量协议的核心都是一条特殊指令，该指令允许检测一个存储器字并以一种不可见的操作设置。如指令TSL (Test and Set Lock)是如何实现临界区的。这条指令做的是，读出一个存储器字并把它存储在一个寄存器中。同时，它对该存储器字写入一个1(或某些非零值)。当然，这需要两个总线周期来完成存储器的读写。在单处理机中，只要该指令不被中途中断，TSL指令就始终照常工作。在多处理机中，，TSL指令必须首先锁住总线，阻止其他的CPU访问它，然后进行存储器的读写访问，再解锁总线。对总线加锁的典型做法是，先使用通常的总线协议请求总线，并申明(设置一个逻辑值1)已拥有某些特定的总线线路，直到两个周期全部完成。只要始终保持拥有这一特定的总线线路，那么其他CPU就不会得到总线的访问权。这个指令只有在拥有必要的线路和和使用它们的(硬件)协议上才能实现

减少总线流量的一种方法是提出写请求的CPU首先进行一个纯读操作来观察锁是否空闲，只有在锁看来是空闲时，TSL才真正去获取它；另一个减少总线流量的方式是使用著名的以太网二进制指数回退算法。不是采用连续轮询，而是把一个延迟循环插入轮询之间。初始的延迟是一条指令。如果锁仍然忙，延迟被加倍成为两条指令，然后，四条指令，如此这样进行,直到某个最大值。当锁释放时，较低的最大值会产生快速的响应。但是会浪费较多的总线周期在高速缓存的颠簸上。而较高的最大值可减少高速缓存的颠簸，但是其代价是不会注意到锁如此迅速地成为空闲。二进制指数补偿算法无论在有或无TSL指令前的纯读的情况下都适用；一个更好的想法是,让每个打算获得互斥信号量的CPU都拥有各自用于测试的私有锁变量。有关的变量应该存放在未使用的高速缓存块中以避免冲突。对这种算法的描述如下:给一个未能获得锁的CPU分配一个锁变量并且把它附在等待该锁的CPU链表的末端。在当前锁的持有者退出临界区时,它释放链表中的首个CPU正在测试的私有锁(在自己的高速缓存中)。然后该CPU进入临界区。操作完成之后，该CPU释放锁。其后继者接着使用,以此类推。尽管这个协议有些复杂(为了避免两个CPU同时把它们自己加载链表的末端)，但它能够有效工作，而且消除了饥饿问题

**自旋与切换**：假设自旋和进行线程切换都是可行的选择，则可进行如下的权衡。自旋直接浪费了CPU周期。重复地测试锁并不是高效的工作。不过，切换也浪费了CPU周期，因为必须保存当前线程的状态，必须获得保护就绪链表的锁，还必须选择一个线程，必须装入其状态，并且使其开始运行。更进一步来说，该CPU高速缓存还将包含所有不合适的高速缓存块，因此在线程开始运行的时候会发生很多代价昂贵的高速缓存未命中。TLB的失效也是可能的。最后，会发生返回至原来线程的切换,随之而来的是更多的高速缓存未命中。花费在这两个线程间来回切换和所有高速缓存未命中的周期时间都浪费了

### 8.1.4 多处理机调度

进程和线程的选择并不是调度中的唯一问题。在单处理机中，调度是一维的。唯一必须(不断重复地)回答的问题是:"接下来运行的线程应该是哪一个?"而在多处理机中，调度是二维的。调度程序必须决定哪一个进程运行以及在哪一个CPU上运行。这个在多处理机中增加的维数大大增加了调度的复杂性。另一个造成复杂性的因素是，在有些系统中所有的线程是不相关的，它们属于不同的进程，彼此无关。而在另外一些系统中它们是成组的，同属于同一个应用并且协同工作

1. 分时

处理独立线程的最简单算法是，为就绪线程维护一个系统级的数据结构，它可能只是一个链表，但更多的情况下可能是对应不同优先级一个链表集合，当某个CPU将要完成其当前工作(或其线程将被阻塞)时，CPU锁住调度队列并选择优先级最高的线程c。只要线程完全无关，以这种方式调度是明智的选择并且其很容易高效地实现

优点：由所有CPU使用的单个调度数据结构分时共享这些CPU，正如它们在一个单处理机系统中那样。它还支持自动负载平衡，因为决不会出现一个CPU空闲而其他CPU过载的情况

缺点：一个是随着CPU数量增加所引起的对调度数据结构的潜在竞争，二是当线程由于I/O阻塞时所引起上下文切换的开销

在线程的时间片用完时，也可能发生上下文切换。在多处理机中它有一些在单处理机中不存在的属性。假设某个线程在其时间片用完时恰好持有一把自旋锁，在该线程被再次调度并且释放该锁之前，其他等待该自旋锁的CPU只是把时间浪费在自旋上。在单处理机中，极少采用自旋锁，因此如果持有互斥信号量的一个线程被挂起，而另一个线程启动并试图获取该互斥信号量,则该线程会立即被阻塞，这样只浪费了少量时间。为了避免这种异常情况，一些系统采用**智能调度**的方法，其中,获得了自旋锁的线程设置一个进程范围内的标志以表示它目前拥有了一个自旋锁。当它释放该自旋锁时，就清除这个标志。这样调度程序就不会停止持有自旋锁的线程，相反，调度程序会给予稍微多一些的时间让该线程完成临界区内的工作并释放自旋锁

**亲和调度**：基本思想：尽量使一个线程在它前一次运行过的同一个CPU上运行；背景：当所有CPU平等时，某些CPU更平等特别是，当线程A已经在CPU k上运行了很长一段时间时,CPU k的高速缓存装满了A的块。若A很快重新开始运行，那么如果它在CPU k上运行性能可能会更好一些，因为k的高速缓存也许还存有A的一些块。预装高速缓存块将提高高速缓存的命中率，从而提高了线程的速度。灵台TLB也可能含有正确的页面，从而减少了TLB失效

**两极调度算法**：创建亲和力调度的一种途径。在一个线程创建时，它被分给一个CPU,例如，可以基于哪一个CPU在此刻有最小的负载。这种把线程分给CPU的工作在算法的顶层进行,其结果是每个CPU获得了自己的线程集。线程的实际调度工作在算法的底层进行。它由每个CPU使用优先级或其他的手段分别进行。通过试图让一个线程在其生命周期内在同一个CPU上运行的方法，高速缓存的亲和力得到了最大化。不过，如果某一个CPU没有线程运行，它便选取另一个CPU的一个线程来运行而不是空转。两级调度算法有三个优点：1.它把负载大致平均地分配在可用的CPU上；2。它尽可能发挥了高速缓存亲和力的优势﹔3.通过为每个CPU提供一个私有的就绪线程链表，使得对就绪线程链表的竞争减到了最小因为试图使用另一个CPU的就绪线程链表的机会相对较小

2. 空间共享

**空间共享**：在多个CPU上同时调度多个线程。最简单的空间共享算法是这样工作的。假设一组相关的线程是一次性创建的。在其创建的时刻，调度程序检查是否有同线程数量一样多的空闲CPU存在。如果有，每个线程获得各自专用的CPU(非多道程序处理)并且都开始运行。如果没有足够的CPU，就没有线程开始运行，直到有足够的CPU时为止。每个线程保持其CPU直到它终止，并且该CPU被送回可用CPU池中。如果一个线程在I/O上阻塞，它继续保持其CPU，而该CPU就空闲直到该线程被唤醒。在下一批线程出现时，应用同样的算法

在任何一个时刻，全部CPU被静态地划分成若干个分区，每个分区都运行一个进程中的线程。在这个简单的分区模型中，一个线程请求一定数量的CPU,然后或者全部得到它们或者一直等到有足够数量的CPU可用为止。另一种处理方式是主动地管理线程的并行度。管理并行度的一种途径是使用一个中心服务器，用它跟踪哪些线程正在运行，哪些线程希望运行以及所需CPU的最小和最大数量。每个应用程序周期性地询问中心服务器有多少个CPU可用。然后它调整线程的数量以符合可用的数量

优点：消除了多道程序设计，从而消除了上下文切换的开销

缺点：当CPU被阻塞或根本无事可做时时间被浪费了，只有等到其再次就绪

3. 群调度

**群调度**：是协同调度的发展产物，由三部分组成：1.把一组相关线程作为一个单位，即一个群，一起调度；2.一个群中的所有成员在不同的分时CPU上同时运行；3.群中的所有成员共同开始和结束其时间片

使群调度正确工作的关键是，同步调度所有的CPU。这意味着把时间划分为离散的时间片。在每一个新的时间片开始时，所有的CPU都重新调度，在每个CPU上都开始一个新的线程。在后续的时间片开始时，另一个调度事件发生。在这之间，没有调度行为。如果某个线程被阻塞，它的CPU保持空闲,直到对应的时间片结束为止

群调度的思想是,让一个进程的所有线程在不同的CPU上同时运行，这样，如果其中一个线程向另一个线程发送请求,接受方几乎会立即得到消息,并且几乎能够立即应答

## 8.2 多计算机

**多处理机**流行和有吸引力的原因是，它们提供了一个简单的迪信模型:所有CPU共旱一个公用存储器。进程可以向存储器写消息，然后被其他进程读取。可以使用互斥信号量、信号量、管程和其他适合的技术实现同步。唯一美中不足的是，大型多处理机构造困难，因而造价高昂。规模更大的多处理机无论花费多少造价也不可能完成。所以,如果要将CPU数量进一步扩大，还需要其他办法

为了解决这个问题，人们在**多计算机**领域中进行了很多研究。多计算机是紧耦合CPU，不共享存储器。每台计算机有自己的存储器。也称为**机群计算机**以及**工作站机群(COWS)**。云计算服务都是建立在多计算机上,因为它们需要大的计算能力

多计算机容易构造，因为其基本部件只是一台配有高性能网络接口卡的PC裸机，没有键盘、鼠标或显示器。当然，获得高性能的秘密是巧妙地设计互连网络以及接口卡。这个问题与在一台多处理机中构造共享存储器是完全类似的。但是，由于目标是在微秒数量级上发送消息，而不是在纳秒数量级上访问存储器，所以这是一个相对简单、便宜且容易实现的任务

### 8.2.1 多计算机硬件

一个多计算机系统的基本节点包括一个CPU、存储器、一个网络接口，有时还有一个硬盘。节点可以封装在标准的PC机箱中，不过通常没有图像适配卡、显示器、键盘和鼠标等。有时这种配置被称为**无主工作站**，因为没有用户。有用户的工作站逻辑上应该对应地被叫作有主工作站，但实际上并没有这么叫。在某些情况下，PC机中有一块2通道或4通道的多处理机主板，可能带有双核、四核或者八核芯片而不是单个CPU,不过为了简化问题，我们假设每个节点只有一个CPU。通常成百个甚至上千个节点连接在一起组成一个多计算机系统

1. 互连技术

在每个节点上有一块网卡，带有一根或两根从网卡上接出的电缆(或光纤)。这些电缆或者连到其他的节点上，或者连到交换机上

两种交换机制：存储转发包交换和电路交换

**存储转发包交换**：每个消息首先被分解(由用户软件或网络接口进行)称为有最大长度限制的块，称为**包**。由源节点的网络接口卡注入第一个交换机的包组成。比特串一次进来一位，当整个包到达一个输入缓冲区时，它被复制到沿着其路径通向下一个交换机的队列当中。当数据包到达目标节点所连接的交换机时，该数据包被复制到目标节点的网络接口卡，并最终到达其RAM。优点：灵活且有效；缺点：存在通过互联网络时增加时延(延迟)的问题；一个解决方案是设计一个网络，其中的包可以逻辑地划分为更小的单元

**电路交换**：包括由第一个交换机建立的，通过所有交换机而到达目标交换机的一条路径。一旦该路径建立起来，比特流就从源到目的地通过整个路径不断地尽快输送。在所涉及的交换机中，没有中间缓冲。电路交换需要有一个建立阶段，它需要一点时间，但是一旦建立完成，速度就很快。在包发送完毕之后，该路径必须被拆除。电路交换的一种变种称为**虫孔路由**，它把每个包拆成子包，并允许第一个子包在整个路径还没有完全建立之前就开始流动

2. 网络接口

在多计算机中，所有节点里都有一块插卡板，它包含节点与互连网络的连接，这使得多计算机连成一体。这些板的构造方式以及它们如何同主CPU和RAM连接对操作系统有重要影响

在所有的多计算机中，接口板上都有一些用来存储进出包的RAM。通常，在包被传送到第一个交换机之前，这个要送出的包必须被复制到接口板的RAM中。这样设计的原因是许多互连网络是同步的，所以一旦一个包的传送开始，比特流必须以恒定的速率连续进行。如果包在主RAM中，由于内存总线上有其他的信息流，所以这个送到网络上的连续流是不能保证的。在接口板上使用专门的RAM,就消除了这个问题

同样的问题还出现在接收进来的包上。从网络上到达的比特流速率是恒定的，并且经常有非常高的速率。如果网络接口卡不能在它们到达的时候实时存储它们，数据将会丢失。同样，在这里试图通过系统总线(例如PCI总线）到达主RAM是非常危险的。由于网卡通常插在PCI总线上，这是一个唯一的通向主RAM的连接，所以不可避免地要同磁盘以及每个其他的I/O设备竞争总线。而把进来的包首先保存在接口板的私有RAM中，然后再把它们复制到主RAM中,则更安全些

接口板上可以有一个或多个DMA通道，甚至在板上有一个完整的CPU(乃至多个CPU)。通过请求在系统总线上的块传送, DMA通道可以在接口板和主RAM之间以非常高的速率复制包,因而可以一次性传送若干字而不需要为每个字分别请求总线。不过，准确地说，正是这种块传送(它占用了系统总线的多个总线周期）使接口板上的RAM的需要是第一位的

很多接口板上有一个完整的CPU，可能另外还有一个或多个DMA通道。它们被称为**网络处理器**，并且其功能日趋强大。这种设计意味着主CPU将一些工作分给了网卡，诸如处理可靠的传送(如果底层的硬件会丢包)、多播(将包发送到多于一个的目的地)、压缩/解压缩、加密/解密以及在多进程系统中处理安全事务等。但是，有两个CPU则意味着它们必须同步，以避免竞争条件的发生，这将增加额外的开销，并且对于操作系统来说意味着要承担更多的工作

跨层复制数据是安全的，但不一定高效。例如，从远程Web服务器请求数据的浏览器将在浏览器的地址空间中创建一个请求。该请求随后被复制到内核，以便TCP/IP可以处理它。然后，数据被复制到网络接口的内存中。在另一端的服务器中，操作将倒序执行:数据从网卡复制到内核缓冲区，又从内核缓冲区到Web服务器。这个过程有着大量的复制操作，每个复制操作都引入了额外开销，而且不仅仅是复制本身，这也对缓存、TLB等带来了压力。因此，这种网络连接的延迟很高

下一节将讨论尽可能减少由复制、缓存污染和上下文切换所带来开销的技术

### 8.2.2 低层通信软件

在多计算机系统中高性能通信的敌人是对包的过度复制。在最好的情形下，在源节点会有从RAM到接口板的一次复制，从源接口板到目的接口板的一次复制(如果在路径上没有存储和转发发生)以及从目的接口板再到目的地RAM的一次复制，这样一共有三次复制。但是，在许多系统中情况要糟糕得多。特别是，如果接口板被映射到内核虚拟地址空间中而不是用户虚拟地址空间的话，用户进程只能通过发出一个陷入到内核的系统调用的方式来发送包。内核会同时在输入和输出时把包复制到自己的存储空间去，从而在传送到网络上时避免出现缺页异常。同样接收包的内核在有机会检查包之前，可能也不知道应该把进来的包放置到哪里

如果说进出RAM的复制是性能瓶颈，那么进出内核的额外复制会将端到端的延迟加倍，并把吞吐量降低一半。为了避免这种对性能的影响，不少多计算机把接口板映射到用户空间，并允许用户进程直接把包送到卡上，而不需要内核的参与。尽管这种处理确实改善了性能，但却带来了两个问题

第一个问题是，如果在节点上有若干个进程运行而且需要访问网络以发送包，该怎么办?哪一个进程应该在其地址空间中获得接口板呢?映射拥有一个系统调用将接口板映射进出一个虚拟地址空间，其代价是很高的，但是，如果只有一个进程获得了卡，那么其他进程该如何发送包呢?如果网卡被映射进了进程A的虚拟地址空间，而所到达的包却是进程B的，又该怎么办?尤其是，如果A和B属于不同的所有者，其中任何一方都不打算协助另一方,又怎么办?一个解决方案是，把接口板映射到所有需要它的进程中去，但是这样做就需要有一个机制用以避免竞争。例如，如果A申明接口板上的一个缓冲区，而由于时间片，B开始运行并且申明同一个缓冲区,那么就会发生灾难。需要有某种同步机制,但是那些诸如互斥信号量一类的机制需要在进程会彼此协作的前提下才能工作。在有多个用户分享的环境下，所有的用户都希望其工作尽快完成，某个用户也许会锁住与接口板有关的互斥信号量而不肯释放。从这里得到的结论是，对于将接口板映射到用户空间的方案，只有在每个节点上只有一个用户进程运行时才能够发挥作用，否则必须设置专门的预防机制(例如，对不同的进程可以把接口板上RAM的不同部分映射到各自的地址空间)

第二个问题是，内核本身会经常需要访问互连网络，例如，访问远程节点上的文件系统。如果考虑让内核与任何用户共享同一块接口板，即便是基于分时方式，也不是一个好主意。假设当板被映射到用户空间，收到了一个内核的包，那么怎么办?或者若某个用户进程向一个伪装成内核的远程机器发送了一个包，又该怎么办?结论是，最简单的设计是使用两块网络接口板，一块映射到用户空间供应用程序使用，另一块映射到内核空间供操作系统使用。许多多计算机就正是这样做的

较新的网络接口通常是**多队列**的,这意味着它们有多个缓冲区可以有效地支持多个用户，可虚拟化为许多虚拟端口。除此之外，该网卡还支持核的**亲和性**。具体来说，它有自己的散列逻辑来将每个数据包引导到一个合适的进程。由于将同一TCP流中的所有段交给一个处理器处理速度更快(因为缓存中总是有数据)，因此该网卡可以使用散列逻辑来对TCP流进行散列(按照IP地址和TCP端口号)，并为TCP流中的每个段添加一个哈希值以保证它被特定的处理器处理。这对于虚拟化也很有用，因为每个虚拟机都可以拥有自己的队列

1. 节点至网络接口通信

将包送到接口板上最快的方法是使用板上的DMA芯片直接将它们从RAM复制到板上。这种方式的问题是，DMA可以使用物理地址而不是虚拟地址，并且独立于CPU运行，除非存在I/O MMU。首先，尽管一个用户进程肯定知道它打算发送的任何包所在的虚拟地址，但它通常不知道有关的物理地址。设计一个系统调用进行虚拟地址到物理地址的映射是不可取的,因为把接口板放到用户空间的首要原因就是为了避免不得不为每个要发送的包进行一次系统调用

另外，如果操作系统决定替换一个页面，而DMA芯片正在从该页面复制一个包，就会传送错误的数据。然而更加糟糕的是，如果操作系统在替换某一个页面的同时DMA芯片正在把一个包复制进该页面，结果不仅进来的包会丢失，无辜的存储器页面也会被毁坏，这可能会带来灾难性的后果

为了以避免上述问题，可采用一类将页面钉住和释放的系统调用，把有关页面标记成暂时不可交换的。但是不仅需要有一个系统调用钉住含有每个输出包的页面，还要有另一个系统调用进行释放工作，这样做的代价太大。钉住和释放页面不仅会对性能带来影响，还会增加软件的复杂性

2. 远程直接内存访问

降低数据的复制量都需要很大代价。为了应对这一问题，一些网络接口支持**远程直接内存访问(RMDA**)技术，允许一台机器直接访问另一台机器的内存。RMDA不需要操作系统的参与，直接从应用的内存空间中读取或写入数据

缺点在于就像普通的DMA一样，通信节点的操作系统必须要锁定止处在数据交换中的页面。同时，仅仅把数据放置在远程计算机的内存中，而其他程序并不知晓时，则并不会在很大程度上降低延迟。RDMA操作成功时并不会发出明确的通知，而是由接收者去轮询内存中的特定字节。发送者在传输完成时会修改该字节来通知接收者新数据的到达。尽管这个方案是可行的，但并不理想而且费时

### 8.2.3 用户层通信软件

在多计算机中，不同CPU上的进程通过互相发送消息实现通信。在最简单的情况下，这种消息传送是暴露给用户进程的，操作系统提供了一种发送和接收消息的途径，而库过程使得这些低层的调用对用户进程可用。在较复杂的情形下，通过使得远程通信看起来像过程调用的办法，将实际的消息传递对用户隐藏起来。下面将讨论这两种方法

1. 发送和接收

在最简化的情形下，所提供的通信服务可以减少到两个(库)调用，一个用于发送消息，另一个用于接收消息

一个问题是如何编址。由于多计算机是静态的，CPU数目是固定的。所以处理编址问题的最便利的办法是使addr由两部分地址组成，其中一部分是CPU编号，另一部分是在这个已编址的CPU上的一个进程或端口的编号。在这种方式中，每个CPU可以管理自己的地址而不会有潜在的冲突

2. 阻塞调用和非阻塞调用

* 发送端：

	* **阻塞调用(同步调用)**：当一个进程调用send时，它指定一个目标以及用以发送消息到该目标的一个缓冲区。当消息发送时，发送进程被阻塞(挂起)。在消息已经完全发送出去之前，不会执行跟随在调用send后面的指令。类似地，在消息真正接收并且放入由参数指定的消息缓冲区之前，对receive的调用也不会把控制返回。在receive中进程保持挂起状态，直到消息到达为止，这甚至有可能等待若干小时。在有些系统中，接收者可以指定希望从谁处接收消息,在这种情况下接收者就保持阻塞状态，直到来自那个发送者的消息到达为止

	* **非阻塞调用(异步调用)**：如果send是非阻塞的，在消息发出之前，它立即将控制返回给调用者。		* 优点：发送进程可以继续运算，与消息传送并行,而不是让CPU空闲(假设没有其他可运行的进程)。通常是由系统设计者做出在阻塞原语和非阻塞原语之间的选择(或者使用这种原语或者另一种原语)，当然也有少数系统中两种原语同时可用，而让用户决定其喜好		* 非阻塞原语所提供的性能优点被其严重的缺点所抵消了:直到消息被送出发送者才能修改消息缓冲区。进程在传输过程中重写消息的后果是如此可怕以致不得不慎重考虑。更糟的是，发送进程不知道传输何时会结束，所以根本不知道什么时候重用缓冲区是安全的。不可能永远避免再碰缓冲区		* 有三种可能的解决方案。第一种方案是，让内核复制这个消息到内部的内核缓冲区，然后让进程继续。从发送者的视角来看，这个机制与阻塞调用相同:只要进程获得控制，就可以随意重用缓冲区了。当然，消息还没有发送出去，但是发送者是不会被这种情况所妨碍的。这个方案的缺点是对每个送出的消息都必须将其从用户空间复制进内核空间。面对大量的网络接口，消息最终要复制进硬件的传输缓冲区中，所以第一次的复制实质上是浪费。额外的复制会明显地降低系统的性能		* 第二种方案是，当消息发送之后中断发送者，告知缓冲区又可以使用了。这里不需要复制。从而节省了时间，但是用户级中断使编写程序变得棘手，并可能会要处理竞争条件，这些都使得该方案难以设计并且几乎无法调试		* 第三种方案是，让缓冲区写时复制，也就是说，在消息发送出去之前将其标记为只读。在消息发送出去之前，如果缓冲区被重用，则进行复制。这个方案的问题是，除非缓冲区被孤立在自己的页面上，否则对临近变量的写操作也会导致复制。此外，需要有额外的管理，因为这样的发送消息行为隐含着对页面读/写状态的影响。最后，该页面迟早会再次被写入,它会触发一次不再必要的复制

	* 发送端的选择：1.阻塞发送(CPU在消息传输前进空闲)；2.带有复制操作的非阻塞发送(CPU时间浪费在额外的复制上)；3.带有中断操作的非阻塞发送(造成编程困难)；4.写时复制(最终可能也会需要额外的复制)

* 接收端：

	* **阻塞调用**：挂起调用者知道消息到达为止。如果有多线程可用，这是一种简单的方法

	* **非阻塞调用**：只是通知内核缓冲区所在的位置，并几乎立即返回控制。		* 可以使用中断来告知消息已经到达。但是中断方式编程困难，并且速度很慢  		* 使用一个过程poll轮询进来的消息。该过程报告是否有消息正在等待。若是，调用者可调用get_message，它返回第一个到达的消息。在有些系统中，编译器可以在代码中合适的地方插入poll调用,不过，要掌握以怎样的频度使用pollI则是需要技巧的		* **弹出式线程**：在接收者进程的地址空间中，一个消息的到达自然地引起一个新线程的创建。这个线程运行一个预定义的过程，其参数是一个指向进来消息的指针。在处理完这个消息之后，该线程直接退出并被自动撤销		** **主动消息**：弹出式线程的变种，在中断处理程序中直接运行接收者代码，从而避免了创建弹出线程的麻烦。要使这个方法更快，消息自身可以带有该处理程序的句柄，这样当消息到达时，只在少数几个指令中可以调用处理程序。这样做的最大好处在于再也不需要复制了。处理程序从接口板取到消息并且即时处理。由于每条消息中都有处理程序的句柄，主动消息方式只能在发送者和接收者彼此完全信任的条件下工作

### 8.2.4 远程过程调用

尽管消息传递模型提供了一种构造多计算机操作系统的便利方式，但是它有不可救药的缺陷:构造所有通信的范型 都是输入/输出。过程send和receive 基本上在做I/O工作，而许多人认为I/O就是一种错误的编程模型

**远程过程调用(RPC)**：允许程序调用位于其他CPU中的过程。当机器1的进程调用机器2的过程时，在机器1中的调用进程被挂起，在机器2中被调用的过程执行。可以在参数中传递从调用者到被调用者的信息，并且可在过程的处理结果中返回信息。根本不存在对程序员可见的消息传递或I/0。RPC已经成为大量多计算机的软件的基础。习惯上，称发出调用的过程为客户机，而称被调用的过程为服务器

**思想**：尽可能使远程过程调用像本地调用。在最简单的情形下，要调用一个远程过程,客户程序必须被绑定在一个称为**客户端存根**的小型库过程上，它在客户机地址空间中代表服务器过程。类似地，服务器程序也绑定在一个称为**服务器端存根**的过程上。这些过程隐藏了这样一个事实，即从客户机到服务器的过程调用并不是本地调用

**步骤**：1.客户机调用客户端存根。该调用是一个本地调用，其参数以通常方式压入栈内；2.客户端存根将有关参数打包成一条消息，并进行系统调用来发出该消息。这个将参数打包的过程称为**编排**；3.内核将该消息从客户机发给服务器；4.内核将接收进来的消息传送给服务器端存根(通常服务器端存根已经提前调用了receive)；5.是服务器端存根调用服务器过程；应答则是在相反的方向沿着同一步骤进行。需要说明的关键是由用户编写的客户机过程，只进行对客户端存根的正常(本地)调用，而客户端存根与服务器过程同名。由于客户机过程和客户端存根在同一个地址空间，所以有关参数以正常方式传递。类似地，服务器过程由其所在的地址空间中的一个过程用它所期望的参数进行调用。对服务器过程而言，一切都很正常。通过这种方式，不采用带有send和receive的IO，通过伪造一个普通的过程调用而实现了远程通信

**实现的相关问题**：1. 有关指针参数的使用。通常，给过程传递一个指针是不存在问题的。由于两个过程都在同一个虚拟地址空间中，所以被调用的过程可以使用和调用者同样的方式来运用指针。但是由于客户机和服务器在不同的地址空间中,所以用RPC传递指针是不可能的。在某些情形下，可以使用一些技巧使得传递指针成为可能。假设第一个参数是一个指针,它指向一个整数k。客户端存根可以编排k并把它发送给服务器。然后服务器端存根创建一个指向k的指针并把它传递给服务器过程，这正如服务器所期望的一样。当服务器过程把控制返回给服务器端存根后，后者把k送回客户机，这里新的k覆盖了原来旧的，只是因为服务器修改了它。实际上，通过引用调用的标准调用序列被复制-恢复所替代了。然而不幸的是，这个技巧并不是总能正常工作的，例如如果要把指针指向一幅图像或其他的复杂数据结构就不行。由于这个原因，对于被远程调用的过程而言,必须对参数做出某些限制2. 对于弱类型的语言，如C语言，编写一个过程用于计算两个矢量(数组)的内积且不规定其任何一个矢量的大小,这是完全合法的。每个矢量可以由个指定的值所终止,而只有调用者和被调用的过程掌握该值。在这样的条件下，对于客户端存根而言，基本上没有可能对这种参数进行编排:没有办法能确定它们有多大3. 参数的类型并不总是能够推导出的，甚至不论是从形式化规约还是从代码自身。这方面的一个例子是printf，其参数的数量可以是任意的(至少一个)，而且它们的类型可以是整形、短整形、长整形、字符、字符串、各种长度的浮点数以及其他类型的任意混合。试图把printf作为远程过程调用实际上是不可能的，因为C是如此的宽松。然而，如果有一条规则说假如你不使用C或者C++来进行编程才能使用RPC，那么这条规则是不会受欢迎的4. 与使用全局变量有关。通常，调用者和被调用过程除了使用参数之外，还可以通过全局变量通信。如果被调用过程此刻被移到远程机器上，代码将失效，因为全局变量不再是共享的了

这里所叙述的问题并不表示RPC就此无望了。事实上，RPC已经被广泛地使用，不过在实际中为了使RPC正常工作需要有一些限制和仔细的考虑

### 8.2.5 分布式共享存储器

|操作系统结构|
|:-:|
|应用|
|运行时系统|
|操作系统|
|硬件|

实现共享存储器的不同层次：共享存储器可以位于硬件与操作系统之间(通过硬件实现的物理共享存储器的多处理机)、位于操作系统与运行时系统之间(分布式共享存储器DSM)、运行时系统与应用之间

**分布式共享存储器(DSM)**：每个页面都位于某一个存储器中。每台机器有其自己的虚拟内存和页表。当一个CPU在一个它并不拥有的页面上进行LOAD和STORE时，会陷入到操作系统当中。然后操作系统对该页面进行定位，并请求当前持有该页面的CPU解除对该页面的映射并通过互联网络发送该页面。在该页面到达时，页面被映射进来，于是出错指令重新启动。事实上，操作系统只是从远程RAM中而不是从本地磁盘中满足了这个缺页异常。对用户而言，机器看起来拥有共享存储器

**工作细节**：在DSM系统中，地址空间被划分为页面，这些页面分布在系统中的所有节点上。当一个CPU引用一个非本地的地址时，就产生一个陷阱，DSM软件调取包含该地址的页面并重新开始出错指令。该指令现在可以完整地执行了

1. 复制

对基本系统的一个改进是复制那些只读页面，如程序代码、只读常量或其他只读数据结构，它可以明显地提高性能。另一种可能是，不仅复制只读页面，而且复制所有的页面。只要有读操作在进行，实际上在只读页面的复制和可读写页面的复制之间不存在差别。但是，如果一个被复制的页面突然被修改了，就必须采取必要的措施来避免多个不一致的副本存在。如何避免不一致性将在下面几节中进行讨论

2. 伪共享

在某些关键方式上DSM系统与多处理机类似。在这两种系统中，当引用非本地存储器字时，从该字所在的机器上取包含该字的一块内存，并放到进行引用的(分别是内存储器或高速缓存)相关机器上。一个重要的设计问题是应该调取多大一块。在多处理机中，其高速缓存块的大小通常是32字节或64字节,这是为了避免占用总线传输的时间过长。在DSM系统中，块的单位必须是页面大小的整数倍(因为MMU以页面方式工作)，不过可以是1个、2个、4个或更多个页面。事实上，这样做就模拟了一个更大尺寸的页面

DSM中使用较大页面的优点：因为网络传输的启动时间是相当长的,所以传递4096字节并不比传输1024个字节多花费多少时间。在有大量的地址空间需要移动时,通过采用大单位的数据传输，通常可减少传输的次数。这个特性是非常重要的，因为许多程序表现出引用上的局部性，其含义是如果一个程序引用了某页中的一个字，很可能在不久的将来它还会引用同一个页面中其他字

DSM中使用较大页面的缺点：大页面的传输造成网络长期占用，阻塞了其他进程引起的故障。**伪共享**：尽管这些变量是无关的，但它们碰巧在同一个页面内，所以当某个进程使用其中一个变量时，它也得到另一个。有效页面越大，发生伪共享的可能性也越高;相反，有效页面越小，发生伪共享的可能性也越少。在普通的虚拟内存系统中不存在类似的现象

3. 实现顺序一致性

如果不对可写页面进行复制，那么实现一致性是没有问题的。每个可写页面只对应有一个副本，在需要时动态地来回移动。由于并不是总能提前了解哪些页面是可写的，所以在许多DSM系统中，当一个进程试图读一个远程页面时，则复制一个本地副本，在本地和远程各自对应的MMU中建立只读副本。只要所有的引用都做读操作,那么一切正常

但是，如果有一个进程试图在一个被复制的页面上写入，潜在的一致性问题就会出现，因为只修改一个副本却不管其他副本的做法是不能接受的。这种情形与在多处理机中一个CPU试图修改存在于多个高速缓存中的一个字的情况有类似之处。在多处理机中的解决方案是，要进行写的CPU首先将一个信号放到总线上，通知所有其他的CPU丢弃该高速缓存块的副本。这里的DSM系统以同样的方式工作。在对一个共享页面进行写入之前，先向所有持有该页面副本的CPU发出一条消息，通知它们解除映射并丢弃该页面。在其所有解除映射等工作完成之后，该CPU便可以进行写操作了

在有详细约束的情况下，允许可写页面的多个副本存在是有可能的。一种方法是允许一个进程获得在部分虚拟地址空间上的一把锁，然后在被锁住的存储空间中进行多个读写操作。在该锁被释放时，产生的修改可以传播到其他副本上去。只要在一个给定的时刻只有一个CPU能锁住某个页面，这样的机制就能保持一致性

另一种方法是，当一个潜在可写的页面被第一次真正写入时，制作一个"干净"的副本并保存在发出写操作的CPU上。然后可在该页上加锁，更新页面，并释放锁。稍后当一个远程机器上的进程试图获得该页面上的锁时，先前进行写操作的CPU将该页面的当前状态与"干净"副本进行比较并构造一个有关所有已修改的字的列表，该列表接着被送往获得锁的CPU,这样它就可以更新其副本页面而不用废弃它

### 8.2.6 多计算机调度

在一台多处理机中，所有的进程都在同一个存储器中。当某个CPU完成其当前任务后，它选择一个进程并运行。理论上，所有的进程都是潜在的候选者。而在一台多计算机中，情形就大不相同了。每个节点有其自己的存储器和进程集合。CPU 1不能突然决定运行位于节点4上的一个进程，而不事先花费相当大的工作量去获得该进程。这种差别说明在多计算机上的调度较为容易，但是将进程分配到节点上的工作更为重要

多计算机调度与多处理机的调度有些类似，但是并不是后者的所有算法都能适用于前者。最简单的多处理机算法(维护就绪进程的一个中心链表)就不能工作，因为每个进程只能在其当前所在的CPU上运行。不过，当创建一个新进程时，存在着一个决定将其放在哪里的选择，例如，从平衡负载的考虑出发

由于每个节点拥有自己的进程，因此可以应用任何本地调度算法。但是，仍有可能采用多处理机的群调度，因为唯一的要求是有一个初始的协议来决定哪个进程在哪个时间槽中运行，以及用于协调时间槽的起点的某种方法

### 8.2.7 负载平衡

需要讨论的有关多计算机调度的内容相对较少。这是因为一旦一个进程被指定给了一个节点，就可以使用任何本地调度算法,除非正在使用群调度。不过一旦一个进程被指定给了某个节点，就不再有什么可控制的，因此哪个进程被指定给哪个节点的决策是很重要的。这同多处理机系统相反，在多处理机系统中所有的进程都在同一个存储器中，可以随意调度到任何CPU上运行。因此值得考察怎样以有效的方式把进程分配到各个节点上。从事这种分配工作的算法和启发式方法则是所谓的**处理器分配算法**

多年来已出现了大量的处理器(节点)分配算法。它们的差别是分别有各自的前提和目标。可知的进程属性包括CPU需求、存储器使用以及与每个其他进程的通信量等。可能的目标包括最小化由于缺少本地工作而浪费的CPU周期，最小化总的通信带宽，以及确保用户和进程公平性等。下面将讨论几个算法

1. 图论确定算法

有一类被广泛研究的算法用于下面这样一个系统，该系统包含已知CPU和存储器需求的进程，以及给出每对进程之间平均流量的已知矩阵。如果进程的数量大于CPU的数量k，则必须把若干个进程分配给每个CPU。其想法是以最小的网络流量完成这个分配工作

该系统可以用一个带权图表示，每个顶点是一个进程，而每个弧代表两个进程之间的消息流。在数学上，该问题就简化为在特定的限制条件下(如每个子图对整个CPU和存储器的需求低于某些限制)，寻找一个将图分割(切割)为k个互不连接的子图的方法。对于每个满足限制条件的解决万案，完全在单个子图内的弧代表了机器内部的通信，可以忽略。从一个子图通向另一个子图的孤代表了机器内部的通信。目标是找出可以使网络流量最小同时满足所有的限制条件的分割方法。

直观地看，我们所做的是寻找紧耦合(簇内高流量)的簇，并且与其他的簇有较少的交互(簇外低流量)

2. 发送者发起的分布式启发算法

当进程创建时，它就运行在创建它的节点上，除非该节点过载了。过载节点的度量可能涉及太多的进程，过大的工作集，或者其他度量。如果过载了，该节点随机选择另一个节点并询问它的负载情况(使用同样的度量)。如果被探查的节点负载低于某个阈值，就将新的进程送到该节点上。如果不是，则选择另一个机器探查。探查工作并不会永远进行下去。在N次探查之内，如果没有找到合适的主机，算法就终止，且进程继续在原有的机器上运行。整个算法的思想是负载较重的节点试图甩掉超额的工作

该算法的分析排队模型所建立的算法表现良好而且在包括不同的阈值、传输成本以及探查限定等大范围的参数内工作稳定。但是在负载重的条件下，所有的机器都会持续地对其他机器进行探查，徒劳地试图找到一台愿意接收更多工作的机器。几乎没有进程能够被卸载，可是这样的尝试会带来巨大的开销

3. 接受者发起的分布式启发算法

上面讨论的算法是由一个过载的发送者发起的，它的一个互补算法是由一个轻载的接收者发起的。在这个算法中，只要有一个进程结束，系统就检查是否有足够的工作可做。如果不是，它随机选择某台机器并要求它提供工作。如果该台机器没有可提供的工作，会接着询问第二台，然后是第三台机器。如果在N次探查之后，还是没有找到工作，该节点暂时停止询问，去做任何已经安排好的工作，而在下一个进程结束之后机器会再次进行询问。如果没有可做的工作，机器就开始空闲。在经过固定的时间间隔之后，它又开始探查

这个算法的优点是，在关键时刻它不会对系统增加额外的负担。发送者发起的算法在机器最不能够容忍时--此时系统已是负载相当重了，做了大量的探查工作。有了接收者发起算法，当系统负载很重时,一台机器处于非充分工作状态的机会是很小的。但是当这种情形确实发生时，它就会较容易地找到可承接的工作。当然如果没有什么工作可做，接收者发起算法也会制造出大量的探查流量，因为所有失业的机器都在拼命地寻找工作。不过在系统轻载时增加系统的负载要远远好于在系统过载时再增加负载

把这两种算法组合起来是有可能的，当机器工作太多时可以试图卸掉一些工作，而在工作不多时可以尝试得到一些工作。此外机器也许可以通过保留一份以往探查的历史记录(用以确定是否有机器经常性处于轻载或过载状态)来对随机轮询的方法进行改进。可以首先尝试这些机器中的某一台，这取决于发起者是试图卸掉工作还是获得工作

## 8.3 分布式系统

**分布式系统**：这些系统与多计算机类似，每个节点都有自己的私有存储器，整个系统中没有共享的物理存储器。但是分布式系统与多计算机相比，耦合度更加松散

在某种程度上，分布式系统中计算机的松散耦合既是优点又是缺点。它之所以是优点，是因为这些计算机可用在各种类型的应用之中，但它也是缺点，因为它由于缺少共同的底层模型而使得这些应用程序很难编程实现

分布式系统添加在其底层网络上的是一些通用范型(模型)，它们提供了一种统一的方法来观察整个系统。分布式系统想要做的是，将松散连接的大量机器转化为基于一种概念的一致系统。这些范型有的比较简单，而有的是很复杂的,但是其思想则总是提供某些东西用来统一整个系统

分布式系统面对不同硬件和操作系统实现某种统一性的途径是，在操作系统的顶部添加一层软件。这层软件称为**中间件**。这层软件提供了一些特定的数据结构和操作，从而允许散布的机器上的进程和用户用一致的方式互操作。在某种意义上，中间件像是分布式系统的操作系统。这就是为什么在一本关于操作系统的书中讨论中间件的原因。不过另一方面，中间件又不是真正的操作系统

### 8.3.1 网络硬件

分布式系统构建在计算机网络的上层，所以有必要对计算机网络这个主题做个简要的介绍。网络主要有两种，覆盖一座建筑物或一个校园的**LAN(局域网**)和可用于城市、乡村甚至世界范围的**WAN(广域网)**。最重要的LAN类型是以太网(Ethernet)，所以我们把它作为LAN的范例来考察。至于WAN的例子，我们将考察Internet，尽管在技术上Internet不是一个网络，而是上千个分离网络的联邦。但是就我们的目标而言，把Internet视为一个WAN就足够了

1. 以太网

**以太网**：由用来连接若干计算机的同轴电缆组成。从电气上看，所有的计算机都被连接起来

许多计算机连接到同一根电缆上，需要一个协议来防止混乱。要在以太网上发送包，计算机首先要监听电缆，看看是否有其他的计算机正在进行传输。如果没有，这台计算机便开始传送一个包，其中有一个短包头，随后是0到1500字节的有效信息载荷。如果电缆正在使用中，计算机只是等待直到当前的传输结束，接着该台计算机开始发送

如果两台计算机同时开始发送，就会导致冲突发生，两台机器都做检测。两机都用中断其传输来响应检测到的碰撞，然后在等待一个从0到T微秒的随机时间段之后，再重新开始。如果再一次冲突发生，所有碰撞的计算机进入0到2T微秒的随机等待。然后再尝试。在每个后续的冲突中，最大等待间隔加倍,用以减少更多碰撞的机会。这个算法称为**二进制指数回退算法**

以太网有其最大电缆长度限制，以及可连接的最多的计算机台数限制。要想超过其中一个的限制,就要在一座大建筑物或校园中连接多个以太网，然后用一种称为**桥接器**的设备把这些以太网连接起来。桥接器允许信息从一个以太网传递到另一个以太网，而源在桥接器的一边，目的地在桥接器的另一边

为了避免碰撞问题，现代以太网使用**交换机**。每个交换机有若干个端口,一个端口用于连接一台计算机、一个以太网或另一个交换机。当一个包成功地避开所有的碰撞并到达交换机时，它被缓存在交换机中并送往另一个通往目的地机器的端口。若能忍受较大的交换机成本，可以使每台机器都拥有自己的端口，从而消除掉所有的碰撞。作为一种妥协方案，在每个端口上连接少量的计算机还是有可能的

2. 因特网

Internet包括了两类计算机，主机和路由器。**主机**有PC，笔记本计算机、掌上电脑，服务器、大型计算机以及其他那些个人或公司所有且希望与Internet连接的计算机。**路由器**是专用的交换计算机，它在许多进线中的一条线上接收进来的包，并在许多个出口线中的一条线上按照其路径发送包。路由器类似于交换机，但是路由器交换机也是有差别的。在大型网络中，路由器互相连接，每台路由器都通过线缆或光缆连接到其他的路由器或主机上。电话公司和互联网服务提供商(ISP)为其客户运行大型的全国性或全球性路由器网络

在Internet上的所有通信都以包的形式传送。每个包在其内部携带着目的地的地址，而这个地址是供路由器使用的。当一个包来到某个路由器时，该路由器抽取目的地地址并在一个表格(部分)中进行查询，以找出用哪根出口线发送该包以及发送到哪个路由器。这个过程不断重复，直到这个包到达目的主机。路由表是高度动态的，并且随着路由器和链路的损坏、恢复以及通信条件的变化在连续不断地更新

### 8.3.2 网络服务和协议

1. 网络服务

**面向连接的服务**：是对电话系统的一种模仿，要使用面向连接的服务，服务用户要先建立一个连接，使用该连接，然后释放该连接。一个连接的基本作用则像一根管道:发送者在一端把物品(信息位)推入管道，而接收者则按照相同的顺序在管道的另一端取出它们

**无连接服务**：是对邮政系统的一种模仿。每个消息(信件)携带了完整的目的地地址，与所有其他消息相独立，每个消息有自己的路径通过系统。通常，当两个消息被送往同一个目的地时，第一个发送的消息会首先到达。但是，有可能第一个发送的消息会被延误，这样第二个消息会首先到达。而对于面向连接的服务而言,这是不可能发生的

每种服务可以用**服务质量**表征。有些服务就其从来不丢失数据而言是可靠的。一般来说，可靠的服务是用以下方式实现的:接收者发回一个特别的**确认包**,确认每个收到的消息，这样发送者就确信消息到达了。不过确认的过程引入了过载和延迟的问题，检查包的丢失是必要的,但是这样确实减缓了传送的速度

可靠的、面向连接的服务有两种很轻微变种:**消息序列**和**字节流**。在**消息序列**的服务中，保留着消息的边界。当两个1KB的消息发送时，它们以两个有区别的1KB的消息形式到达，决不会成为一个2KB的消息。在**字节流**的服务中，连接只是形成一个字节流，不存在消息的边界。当2K字节到达接收者时，没有办法分辨出所发送的是一个2KB消息、两个1KB消息还是2048个单字节的消息或者其他消息。

并不是所有的应用都需要连接。例如，在测试网络时，所需要的只是一种发送单个包的方法，其中的这个包具备高可达到率但不保证一定可达。不可靠的(意味着没有确认)无连接服务，常常称作**数据报服务**，它模拟了电报服务，这种服务也不为发送者提供回送确认的服务

在其他的情形下，不用建立连接就可发送短消息的便利是受到欢迎的，但是可靠性仍然是重要的。可以把**确认数据报服务**提供给这些应用使用。它类似于寄送一封挂号信并且要求得到一个返回收据。当收据回送到之后，发送者就可以绝对确信，该信已被送到所希望的地方且没有在路上丢失

还有一种服务是**请求-应答服务**。在这种服务中,发送者传送一份包含一个请求的数据报;应答中含有答复

六种不同类型的网络服务↓：
服务|是否面向连接|示例|
|:-:|:-:|:-:|
|可靠消息流|面向连接|书的页序列|
|可靠字节流|面向连接|远程登录|
|不可靠连接|面向连接|数字化语音|
|不可靠数据报|无连接|网络测试数据包|
|确认数据报|无连接|注册邮件|
|请求-应答|无连接|数据库查询|

2. 网络协议

所有网络都有高度专门化的规则，用以说明什么消息可以发送以及如何响应这些消息。用于特定计算机通信的这些规则的集合,称为**协议**。有许多种协议，包括路由器-路由器协议、主机-主机协议以及其他协议等

所有的现代网络都使用所谓的**协议栈**把不同的协议一层一层叠加起来。每一层解决不同的问题。例如处于最低层的协议会定义如何识别比特流中的数据包的起始和结束位置。在更高一层上，协议会确定如何通过复杂的网络来把数据包从来源节点发送到目标节点。再高一层上，协议会确保多包消息中的所有数据包都按照合适的顺序正确到达

大多数分布式系统都使用Internet作为基础，因此这些系统使用的关键协议是两种主要的Internet协议:IP和TCP

**IP**是一种数据报协议，发送者可以向网络上发出长达64KB的数据报,并期望它能够到达。它并不提供任何保证。当数据报在网络上传送时,它可能被切割成更小的包。这些包独立进行传输，并可能通过不同的路由。当所有的部分都到达目的地时，再把它们按照正确的顺序装配起来并提交出去。当前有两个版本的IP在使用，即v4和v6。当前v4仍然占有支配地位，所以我们这里主要讨论它，但是，v6是未来的发展方向。每个v4包以一个40字节的包头开始，其中包含32位源地址和32位目标地址。这些地址就称为**IP地址**，它们构成了Internet中路由选择的基础。通常IP地址写作4个由点隔开的十进制数，每个数介于0~255之间，例如192.31.231.65。当一个包到达路由器时，路由器会解析出IP目标地址,并利用该地址选择路由

既然IP数据报是非应答的，所以对于Internet的可靠通信仅仅使用IP是不够的。为了提供可靠的通信，通常在IP层之上使用另一种协议，**TCP(传输控制协议)**。TCP使用IP来提供面向连接的数据流。为了使用TCP,进程需要首先与一个远程进程建立连接。被请求的进程需要通过机器的IP地址和机器的端口号来指定，而对进入的连接感兴趣的进程监听该端口。这些工作完成之后，只需把字节流放入连接，那么就能保证它们会从另一端按照正确的顺序完好无损地出来。TCP的实现是通过序列号、校检和、出错重传来提供这种保证的。所有这些对于发送者和接收者进程都是透明的。它们看到的只是可靠的进程间通信，就像UNIX管道一样

为了与远程机器建立连接(或者仅仅是给它发送一个数据包)，需要知道它的IP地址。因为对于人们来说管理32位的IP地址列表是很不方便的，所以就产生了一种称为**DNS(域名系统**)的方案，它作为一个数据库把主机的ASCII名称映射为对应的IP地址。因此就可以用DNS名称(如star.cs.vu.nl)来代替对应的IP地址（如130.37.24.6)。由于Internet电子邮件地址采用"用户名@DNS主机名"的形式命名，所以DNS名称广为人知。该命名系统允许发送方机器上的邮件程序在DNS数据库中查找目标机器的IP地址，并与目标机上的邮件守护进程建立TCP连接，然后把邮件作为文件发送出去。用户名一并发送,用于确定存放消息的邮箱

### 8.3.3 基于文档的中间件

Web背后的原始范型是非常简单的:每个计算机可以持有一个或多个文档，称为**Web页面**。在每个页面中有文本、图像、图标、声音、电影等，还有到其他页面的**超链接**(指针)。当用户使用一个称为**Web浏览器**的程序请求一个Web页面时，该页面就显示在用户的屏幕上。点击一个超链接会使得屏幕上的当前页面被所指向的页面替代。尽管近来在Web上添加了许多的花哨名堂，但是其底层的范型仍旧很清楚地存在着:Web是一个由文档构成的巨大有向图，其中文档可以指向其他的文档

每个Web页面都有一个唯一的地址，称为**URL(统一资源定位符)**，其形式为protocol:/DNS-name/file-name。 http协议(超文本传输协议)是最常用的，不过ftp和其他协议也在使用。协议名后面是拥有该文件的主机的DNS名称。最后是一个本地文件名，用来说明需要使用哪个文件。因此，URL唯一指定一个单个文件

整个系统按如下方式结合在一起:Web根本上是一个客户机---服务器系统，用户是客户端，而Web站点则是服务器。当用户给浏览器提供一个URL时(或者键入URL,或者点击当前页面上的某个超链接),浏览器则按照一定的步骤调取所请求的Web页面。作为一个例子，假设提供的URL是http://www.minix3.org/getting-started/index.html。浏览器按照下面的步骤取得所需的页面：1.浏览器向DNS询问www.minix3.org的IP地址；2.DNS的回答是66.147.238.215；3.浏览器建立一个到66.147.238.215上端口80的TCP连接；4.接着浏览器发送对文件getting-started/index.html的请求；5.www.acm.org服务器发送文件getting-started/index.html；6.浏览器显示getting-started/index.html文件中的所有内容；7.同时，浏览器获取并显示页面中的所有图像；8.释放TCP连接。大体上，这就是Web的基础以及它是如何工作的。许多其他的功能已经添加在了上述基本Web功能之上了，包括样式表、可以在运行中生成的动态网页、带有可在客户机上执行的小程序或脚本的页面等

### 8.3.4 基于文件系统的中间件

隐藏在Web背后的基本思想是，使一个分布式系统看起来像一个巨大的、超链接的集合。另一种处理方式则是使一个分布式系统看起来像一个大型文件系统。在这一节中，我们将考察一些与设计一个广域文件系统有关的问题。分布式系统采用一个文件系统模型意味着只存在一个全局文件系统，全世界的用户都能够读写他们各自具有授权的文件。通过一个进程将数据写入文件而另一个进程把数据读出的办法可以实现通信。由此产生了标准文件系统中的许多问题，但是也有一些与分布性相关的新问题

1. 传输模式

第一个问题是，在**上传/下载模式**和**远程访问模式**之间的选择问题。在**上传/下载模式**中，通过把远程服务器上的文件复制到本地的方法，实现进程对远程文件的访问。如果只是需要读该文件，考虑到高性能的需要，就在本地读出该文件。如果需要写入该文件,就在本地写入。进程完成工作之后，把更新后的文件送回原来的服务器。在**远程访问模式**中,文件停留在服务器上，而客户机向服务器发出命令并在服务器上完成工作

上传/下载模式的**优点**是简单，而且一次性传送整个文件的方法比用小块传送文件的方法效率更高。**缺点**是为了在本地存放整个文件，必须拥有足够的空间，即使只需要文件的一部分也要移动整个文件这样做显然是一种浪费，而且如果有多个并发用户则会产生一致性问题

2. 目录层次

文件只是所涉及的问题中的一部分。另一部分问题是目录系统。所有的分布式系统都支持有多个文件的目录。接下来的设计问题是，是否所有的用户都拥有该目录层次的相同视图。所有的客户(以及其他机器)对该分布式文件系统拥有相同的视图或者不同的机器有该文件系统的不同视图。

不同的机器有该文件系统的不同视图既灵活又可直接实现，但是其缺点是，不能使得整个系统行为像单一的、旧式分时系统。在分时系统中，文件系统对任何进程都是一样的，这个属性显然使得系统容易编程和理解

一个密切相关的问题是，是否存在一个所有的机器都承认的全局根目录。获得全局根目录的一个方法是，让每个服务器的根目录只包含一个目录项。在这种情况下，路径取/server/path的形式，这种方式有其缺点，但是至少做到了在系统中处处相同

3. 命名透明性

这种命名方式的主要问题是，它不是完全透明的。这里涉及两种类型的透明性，并且有必要加以区分。第一种，**位置透明性**，其含义是路径名没有隐含文件所在位置的信息。类似于/server1/dir1/dir2/x的路径告诉每个人，x是在服务器1上，但是并没有说明该服务器在哪里。在网络中该服务器可以随意移动，而该路径名却不必改动。所以这个系统具有位置透明性

但是，假设文件非常大而在服务器1上的空间又很紧张。进而，如果在服务器2上有大量的空间,那么系统也许会自动地将x从1移到服务器2上。不幸地，当整个路径名的第一个分量是服务器时，即使dir1和dir2在两个服务器上都存在，系统也不能将文件自动地移动到其他的服务器上。问题在于让文件自动移动就得将其路径名从/server1/dir1/dir2/x变为/server2/dir1/dir2/x。如果路径改变了,那么在内部拥有前一个路径字符串的程序就会停止工作。如果在一个系统中文件移动时文件的名称不会随之改变,则称为具有**位置独立性**。将机器或服务器名称嵌在路径名中的分布式系统显然不具有位置独立性。一个基于远程安装(挂载)的系统当然也不具有位置独立性，因为在把某个文件从一个文件组(安装单元)移到另一个文件组时，是不可能仍旧使用原来的路径名的。可见位置独立性是不容易实现的,但它是分布式系统所期望的一个属性

这里把前面讨论过的内容加以简要的总结，在分布式系统中处理文件和目录命名的方式通常有以下三种：1.机器+路径名,如/machine/path 或machine:path；2.将远程文件系统安装在本地文件层次中；3.在所有的机器上看来都相同的单一名字空间。前两种方式很容易实现，特别是作为将原本不是为分布式应用而设计的已有系统连接起来的方式时是这样。而第三种方式的实现则是困难的，并且需要仔细的设计，但是它能够减轻了程序员和用户的负担

4. 文件共享的语义

当两个或多个用户共享同一个文件时，为了避免出现问题有必要精确地定义读和写的语义。在单处理器系统中，通常，语义是如下表述的，一个write系统调用后面跟随着一个read系统调用时，则read返回刚才写入的值。类似地，当两个write连续出现，后跟随一个read时，则读出的值是后一个写操作所存入的值。实际上，系统强制所有的系统调用有序，并且所有的处理器都看到同样的顺序。我们将这种模型称为**顺序一致性**

在分布式系统中，只要只有一个文件服务器而且客户机不缓存文件那么顺序一致性是很容易实现的。所有的read和write直接发送到这个文件服务器上，而该服务器严格地按顺序执行它们。不过实际情况中，如果所有的文件请求都必须送到单台文件服务器上处理，那么这个分布式系统的性能往往会很糟糕。这个问题可以用如下方式来解决，即让客户机在其私有的高速缓存中保留经常使用文件的本地副本。但是如果客户机1修改了在本地高速缓存中的文件，而紧接着客户机2从服务器上读取该文件，那么客户机2就会得到一个已经过时的文件

走出这个困局的一个途径是，将高速缓存文件上的改动立即传送回服务器。尽管概念上很简单，但这个方法却是低效率的。另一个解决方案是放宽文件共享的语义。一般的语义要求一个读操作要看到其之前的所有写操作的效果，我们可以定义一条新规则来取代它:"在一个打开文件上所进行的修改，最初仅对进行这些修改的进程是可见的。只有在该文件关闭之后，这些修改才对其他进程可见。"采用这样一个规则不会改变发生的事件，但是这条规则确实重新定义了所谓正确的具体操作行为。实际上，这个规则就是上传/下载模式。这种语义已经得到广泛的实现，即所谓的**会话语义**

使用会话语义产生了新的问题，即如果两个或更多的客户机同时缓存并修改同一个文件，应该怎么办?一个解决方案是，当每个文件依次关闭时，其值会被送回给服务器所以最后的结果取决于哪个文件最后关闭。一个不太令人满意的、但是较容易实现的替代方案是，最后的结果是在各种候选中选择一个，但并不指定是哪一个。对会话语义的另一种处理方式是，使用上传/下载模式，但是自动对已经下载的文件加锁。其他试图下载该文件的客户机将被挂起直到第一个客户机返回。如果对某个文件的操作要求非常多，服务器可以向持有该文件的客户机发送消息，询问是否可以加快速度，不过这样做可能没有作用。总而言之，正确地实现共享文件的语义是一件棘手的事情，并不存在一个优雅和有效的解决方案

### 8.3.5 基于对象的中间件

现在让我们考察第三种范型。这里不再说一切都是文档或者一切都是文件，取而代之，我们会说一切都是对象。**对象**是变量的集合，这些变量与一套称为方法的访问过程绑定在一起。进程不允许直接访问这些变量。相反，要求它们调用方法来访问

有一些程序设计语言，如C++和Java，是面向对象的，但这些对象是语言级的对象，而不是运行时刻的对象。一个知名的基于运行时对象的系统是**CORBA(公共对象请求代理体系结构)**。CORBA是一个客户机---服务器系统，其中在客户机上的客户进程可以调用位于(可能是远程)服务器上的对象操作。CORBA是为运行不同硬件平台和操作系统的异构系统而设计的，并且用各种语言编写。为了使在一个平台上的客户有可能使用在不同平台上的服务器，将**ORB(对象请求代理)**插入到客户机和服务器之间，从而使它们相互匹配。ORB在CORBA中扮演着重要的角色，以至于连该系统也采用了这个名称

### 8.3.6 基于协作的中间件

1. Linda

Linda是用于通信和同步的新系统。在Linda系统中，相互独立的进程之间通过一个抽象的**元组空间**进行通信。对整个系统而言,元组空间是全局性的,在任何机器上的进程都可以把元组插入或移出元组空间，而不用考虑它们是如何存放的以及存放在何处。对于用户而言，元组空间像一个巨大的全局共享存储器

2. 发布/订阅

**发布/订阅**：基于协作的模型的一个例子。它由大量通过广播网网络互联的进程组成。每个进程可以是一个信息生产者、信息消费者或两者都是

当一个信息生产者有了一条新的信息后，它就把该信息作为一个元组在网络上广播。这种行为称为**发布**。在每个元组中有一个分层的主题行，其中有多个用圆点(英文句号)分隔的域。对特定信息感兴趣的进程可以**订阅**特定的专题，这包括在主题行中使用通配符。在同一台机器上，只要通知一个元组守护进程就可以完成订阅工作，该守护进程监测已出版的元组并查找所需要的专题

发布/订阅的实现过程：当一个进程需要发布一个元组时,它在本地局城网上广播。在每台机器上的元组守护进程则把所有的已广播的元组复制进入其RAM。然后检查主题行看看哪些进程对它感兴趣，并给每个感兴趣的进程发送一个该元组的副本。元组也可以在广域网上或Internet上进行广播，这种做法可以通过将每个局域网中的一台机器变作信息路由器，用来收集所有已发布的元组，然后转送到其他的局域网上再次广播的方法来实现。这种转送方法也可以进行得更为聪明，即只把元组转送给至少有一个需要该元组的订阅者的远程局域网。不过要做到这一点，需要使用信息路由器交换有关订阅者的信息

这里可以实现各种语义，包括可靠发送以及保证发送，即使出现崩溃也没有关系。在后一种情形下,有必要存储原有的元组供以后需要时使用。一种存储的方法是将一个数据库系统和该系统挂钩，并让该数据库订阅所有的元组。这可以通过把数据库封装在一个适配器中实现，从而允许一个已有的数据库以发布/订阅模型工作。当元组们经过时，适配器就一一抓取它们并把它们放进数据库中

发布/订阅模型完全把生产者和消费者分隔开来，如同在Linda中一样。但是，有的时候还是有必要知道，另外还有谁对某种信息感兴趣。这种信息可以用如下的方法来收集:发布一个元组，它只询问:"谁对信息x有兴趣?"。以元组形式的响应会是:"我对x有兴趣。"

## 8.5 小结

采用多个CPU可以把计算机系统建造得更快更可靠。CPU的四种组织形式是多处理器、多计算机、虚拟机和分布式系统。其中的每一种都有其自己的特性和问题

一个多处理器包括两个或多个CPU，它们共享一个公共的RAM，通常这些CPU本身由多核组成,这些核和CPU可以通过总线、交叉开关或一个多级交换网络互连起来。各种操作系统的配置都是可能的，包括给每个CPU配一个各自的操作系统、配置一个主操作系统而其他是从属的操作系统或者是一个对称多处理器，在每个CPU上都可运行的操作系统的一个副本。在后一种情形下，需要用钡提供同步。当收有可用的锁时，一个CPU会空转或者进行上下文切换。各种调度算法都是可能的，包括分时、空间分割以及群调度

多计算机也有两个或更多的CPU,但是这些CPU有自己的私有存储器。它们没有任何公共的RAM,所以全部的通信通过消息传递完成。在有些情形下，网络接口板有自己的CPU,此时在主CPU和接口板上的CPU之间的通信必须仔细地组织,以避免竞争条件的出现.在多计算机中的用户级通信常常使用远程过程调用，但也可以使用分布式共享存储器。这里进程的负载平衡是一个问题，有多种算法用以解决该问题,包括发送者-驱动算法、接收者-驱动算法以及竞标算法等

分布式系统是一个松散耦合的系统，其中每个节点是一台完整的计算机，配有全部的外部设备以及自己的操作系统。这些系统常常分布在较大的地理区域内。在操作系统上通常设计有中间件，从而提供一个统一的层次以方便与应用程序的交互。中间件的类型包括基于文档、基于文件、基于对象以及基于协调的中间件。有关的一些例子有World Wide Web、CORBA以及Linda